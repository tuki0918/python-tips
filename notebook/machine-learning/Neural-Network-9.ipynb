{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"単純なConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "        引数のxは入力データ、tは教師ラベル\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.30016742097\n",
      "=== epoch:1, train acc:0.176, test acc:0.177 ===\n",
      "train loss:2.29807855769\n",
      "train loss:2.29477191614\n",
      "train loss:2.29052246937\n",
      "train loss:2.28025937929\n",
      "train loss:2.26892156441\n",
      "train loss:2.26028981444\n",
      "train loss:2.23998979698\n",
      "train loss:2.21982392183\n",
      "train loss:2.20680248285\n",
      "train loss:2.17829132321\n",
      "train loss:2.14403806983\n",
      "train loss:2.09249144738\n",
      "train loss:2.03610722142\n",
      "train loss:2.00506231306\n",
      "train loss:1.93660292283\n",
      "train loss:1.89501578831\n",
      "train loss:1.807156973\n",
      "train loss:1.75794147295\n",
      "train loss:1.65404737249\n",
      "train loss:1.53230842228\n",
      "train loss:1.53499625757\n",
      "train loss:1.4555003038\n",
      "train loss:1.26464069407\n",
      "train loss:1.24334178203\n",
      "train loss:1.19957897539\n",
      "train loss:1.15668322317\n",
      "train loss:1.11459998316\n",
      "train loss:1.00742892527\n",
      "train loss:0.925330877102\n",
      "train loss:0.920013381298\n",
      "train loss:0.760096238731\n",
      "train loss:0.876994704524\n",
      "train loss:0.682221045433\n",
      "train loss:0.762068704044\n",
      "train loss:0.664301051044\n",
      "train loss:0.671214433284\n",
      "train loss:0.785652894705\n",
      "train loss:0.903547990742\n",
      "train loss:0.78399186182\n",
      "train loss:0.644215581943\n",
      "train loss:0.68537598588\n",
      "train loss:0.639317441797\n",
      "train loss:0.666165468016\n",
      "train loss:0.425931008826\n",
      "train loss:0.704416404891\n",
      "train loss:0.614653765001\n",
      "train loss:0.527914055967\n",
      "train loss:0.458453351391\n",
      "train loss:0.44052036488\n",
      "train loss:0.589359425212\n",
      "train loss:0.601402914107\n",
      "train loss:0.484305617753\n",
      "train loss:0.590058397164\n",
      "train loss:0.515116150691\n",
      "train loss:0.62429076469\n",
      "train loss:0.558173595111\n",
      "train loss:0.584466992947\n",
      "train loss:0.548723166511\n",
      "train loss:0.43565158965\n",
      "train loss:0.456597788445\n",
      "train loss:0.36755541198\n",
      "train loss:0.71995190317\n",
      "train loss:0.652168508249\n",
      "train loss:0.507645858615\n",
      "train loss:0.479362995292\n",
      "train loss:0.461813995422\n",
      "train loss:0.436996928368\n",
      "train loss:0.684843396682\n",
      "train loss:0.383947964245\n",
      "train loss:0.405889043259\n",
      "train loss:0.403594367292\n",
      "train loss:0.488083861155\n",
      "train loss:0.391185006791\n",
      "train loss:0.36827294747\n",
      "train loss:0.459158094972\n",
      "train loss:0.589721307825\n",
      "train loss:0.510622043091\n",
      "train loss:0.479026240216\n",
      "train loss:0.525954250412\n",
      "train loss:0.537795889242\n",
      "train loss:0.506893568453\n",
      "train loss:0.410465233597\n",
      "train loss:0.450501014288\n",
      "train loss:0.440714791402\n",
      "train loss:0.665370616204\n",
      "train loss:0.38089400806\n",
      "train loss:0.415824581376\n",
      "train loss:0.451885221219\n",
      "train loss:0.345487936488\n",
      "train loss:0.441210395232\n",
      "train loss:0.400934107591\n",
      "train loss:0.355498806084\n",
      "train loss:0.379687878337\n",
      "train loss:0.498010881144\n",
      "train loss:0.477997468471\n",
      "train loss:0.491185814278\n",
      "train loss:0.405516755968\n",
      "train loss:0.532614376721\n",
      "train loss:0.447701696811\n",
      "train loss:0.395600428419\n",
      "train loss:0.46015190932\n",
      "train loss:0.349637803301\n",
      "train loss:0.292623525089\n",
      "train loss:0.338792258175\n",
      "train loss:0.626695761609\n",
      "train loss:0.335606722951\n",
      "train loss:0.30338143846\n",
      "train loss:0.316603470579\n",
      "train loss:0.307199582981\n",
      "train loss:0.352474780097\n",
      "train loss:0.324948530343\n",
      "train loss:0.26047409396\n",
      "train loss:0.522196415326\n",
      "train loss:0.375436571915\n",
      "train loss:0.466027116472\n",
      "train loss:0.419393708055\n",
      "train loss:0.443202258102\n",
      "train loss:0.425544345419\n",
      "train loss:0.356410279099\n",
      "train loss:0.326709432084\n",
      "train loss:0.331322865042\n",
      "train loss:0.299219951762\n",
      "train loss:0.340688550052\n",
      "train loss:0.31993402042\n",
      "train loss:0.349899120573\n",
      "train loss:0.322614664261\n",
      "train loss:0.421420375121\n",
      "train loss:0.317180985341\n",
      "train loss:0.743890369364\n",
      "train loss:0.25944294443\n",
      "train loss:0.281184043626\n",
      "train loss:0.231716795759\n",
      "train loss:0.188199385164\n",
      "train loss:0.428828549058\n",
      "train loss:0.445854008089\n",
      "train loss:0.301730662378\n",
      "train loss:0.345330330462\n",
      "train loss:0.517648795995\n",
      "train loss:0.292042293574\n",
      "train loss:0.475754296977\n",
      "train loss:0.24453377751\n",
      "train loss:0.327923477236\n",
      "train loss:0.312969330506\n",
      "train loss:0.301886881742\n",
      "train loss:0.397480316965\n",
      "train loss:0.417877527497\n",
      "train loss:0.356658446214\n",
      "train loss:0.483965565208\n",
      "train loss:0.397089133585\n",
      "train loss:0.328610867407\n",
      "train loss:0.372162905343\n",
      "train loss:0.36188364448\n",
      "train loss:0.200831172526\n",
      "train loss:0.253392761316\n",
      "train loss:0.360125928312\n",
      "train loss:0.20756901185\n",
      "train loss:0.347927013269\n",
      "train loss:0.282438860761\n",
      "train loss:0.299806013787\n",
      "train loss:0.374060199529\n",
      "train loss:0.295278854156\n",
      "train loss:0.41552228288\n",
      "train loss:0.296012374024\n",
      "train loss:0.421105590127\n",
      "train loss:0.381226326805\n",
      "train loss:0.171734003143\n",
      "train loss:0.366943498985\n",
      "train loss:0.410586313821\n",
      "train loss:0.35242730456\n",
      "train loss:0.305380693594\n",
      "train loss:0.272749707229\n",
      "train loss:0.276215744265\n",
      "train loss:0.29699328182\n",
      "train loss:0.468396840661\n",
      "train loss:0.354902671911\n",
      "train loss:0.239889035283\n",
      "train loss:0.315988087126\n",
      "train loss:0.293873922041\n",
      "train loss:0.410070798166\n",
      "train loss:0.356690334833\n",
      "train loss:0.367897818719\n",
      "train loss:0.234722824784\n",
      "train loss:0.26010622093\n",
      "train loss:0.353477334217\n",
      "train loss:0.510792838296\n",
      "train loss:0.194997725423\n",
      "train loss:0.328291469258\n",
      "train loss:0.278927299304\n",
      "train loss:0.233950356845\n",
      "train loss:0.343601230159\n",
      "train loss:0.365957415197\n",
      "train loss:0.386071200632\n",
      "train loss:0.228572408014\n",
      "train loss:0.242204143238\n",
      "train loss:0.188160548107\n",
      "train loss:0.250287462922\n",
      "train loss:0.301972885886\n",
      "train loss:0.255540160901\n",
      "train loss:0.357994983827\n",
      "train loss:0.211113778536\n",
      "train loss:0.430803689276\n",
      "train loss:0.199934635436\n",
      "train loss:0.280895225926\n",
      "train loss:0.295876060798\n",
      "train loss:0.275864101276\n",
      "train loss:0.253742845885\n",
      "train loss:0.251504228363\n",
      "train loss:0.255658654726\n",
      "train loss:0.201640431702\n",
      "train loss:0.248386216853\n",
      "train loss:0.234386720912\n",
      "train loss:0.260738805342\n",
      "train loss:0.231170420218\n",
      "train loss:0.134125747783\n",
      "train loss:0.113915307277\n",
      "train loss:0.377559950329\n",
      "train loss:0.29267862\n",
      "train loss:0.23301453029\n",
      "train loss:0.238451537237\n",
      "train loss:0.201675184884\n",
      "train loss:0.17045727861\n",
      "train loss:0.236562215378\n",
      "train loss:0.188935764724\n",
      "train loss:0.289041486514\n",
      "train loss:0.305058041244\n",
      "train loss:0.205501633937\n",
      "train loss:0.23551152569\n",
      "train loss:0.305601617221\n",
      "train loss:0.223406534101\n",
      "train loss:0.542618427658\n",
      "train loss:0.279317733419\n",
      "train loss:0.247603824972\n",
      "train loss:0.409435150647\n",
      "train loss:0.14744055051\n",
      "train loss:0.386617874871\n",
      "train loss:0.178157810697\n",
      "train loss:0.120878703899\n",
      "train loss:0.153173872951\n",
      "train loss:0.326173810864\n",
      "train loss:0.237940543235\n",
      "train loss:0.428260845622\n",
      "train loss:0.278436942739\n",
      "train loss:0.286962276733\n",
      "train loss:0.338094321292\n",
      "train loss:0.321936156949\n",
      "train loss:0.43898146366\n",
      "train loss:0.293590701529\n",
      "train loss:0.30795770509\n",
      "train loss:0.309593634629\n",
      "train loss:0.240199953423\n",
      "train loss:0.19756428844\n",
      "train loss:0.264962730779\n",
      "train loss:0.395980230147\n",
      "train loss:0.280813396961\n",
      "train loss:0.218510126744\n",
      "train loss:0.194155679211\n",
      "train loss:0.161303212419\n",
      "train loss:0.240715824754\n",
      "train loss:0.180987602688\n",
      "train loss:0.186912990295\n",
      "train loss:0.244404552816\n",
      "train loss:0.186166098527\n",
      "train loss:0.173429817129\n",
      "train loss:0.18332341843\n",
      "train loss:0.2690277384\n",
      "train loss:0.152779495275\n",
      "train loss:0.230443520202\n",
      "train loss:0.379909886589\n",
      "train loss:0.293054089752\n",
      "train loss:0.210935740232\n",
      "train loss:0.295834761325\n",
      "train loss:0.287705558199\n",
      "train loss:0.353196848604\n",
      "train loss:0.191879552455\n",
      "train loss:0.264015347884\n",
      "train loss:0.25958307606\n",
      "train loss:0.262764027328\n",
      "train loss:0.401770618005\n",
      "train loss:0.230633395418\n",
      "train loss:0.171719298047\n",
      "train loss:0.285810230962\n",
      "train loss:0.170139356874\n",
      "train loss:0.248974305166\n",
      "train loss:0.270850374629\n",
      "train loss:0.168904208966\n",
      "train loss:0.160358979469\n",
      "train loss:0.27806361881\n",
      "train loss:0.221819449146\n",
      "train loss:0.247992789914\n",
      "train loss:0.244147868284\n",
      "train loss:0.241615178064\n",
      "train loss:0.257148772517\n",
      "train loss:0.33866509046\n",
      "train loss:0.225600982274\n",
      "train loss:0.136806135296\n",
      "train loss:0.225063789907\n",
      "train loss:0.231311807459\n",
      "train loss:0.228835878986\n",
      "train loss:0.241053501836\n",
      "train loss:0.277674965043\n",
      "train loss:0.269033080489\n",
      "train loss:0.225661994043\n",
      "train loss:0.181659484627\n",
      "train loss:0.226322858762\n",
      "train loss:0.197206855866\n",
      "train loss:0.176703638756\n",
      "train loss:0.236253339065\n",
      "train loss:0.203305447595\n",
      "train loss:0.202765188552\n",
      "train loss:0.155100255848\n",
      "train loss:0.194813567384\n",
      "train loss:0.166197310665\n",
      "train loss:0.221819105151\n",
      "train loss:0.16872598428\n",
      "train loss:0.154034999534\n",
      "train loss:0.103390358574\n",
      "train loss:0.212744472086\n",
      "train loss:0.249361948618\n",
      "train loss:0.328188070793\n",
      "train loss:0.18991729964\n",
      "train loss:0.215660386821\n",
      "train loss:0.188568501604\n",
      "train loss:0.263464850747\n",
      "train loss:0.135096251831\n",
      "train loss:0.119200310723\n",
      "train loss:0.143879446027\n",
      "train loss:0.322305294432\n",
      "train loss:0.195866633088\n",
      "train loss:0.280581175446\n",
      "train loss:0.196972784234\n",
      "train loss:0.223757345352\n",
      "train loss:0.245493088826\n",
      "train loss:0.191563246588\n",
      "train loss:0.156040397517\n",
      "train loss:0.12562816913\n",
      "train loss:0.194573209672\n",
      "train loss:0.170935137049\n",
      "train loss:0.194853243888\n",
      "train loss:0.267067456525\n",
      "train loss:0.30584408705\n",
      "train loss:0.105300780093\n",
      "train loss:0.29105690037\n",
      "train loss:0.157710621027\n",
      "train loss:0.142250696059\n",
      "train loss:0.247867049296\n",
      "train loss:0.13787866209\n",
      "train loss:0.136619369825\n",
      "train loss:0.201006558104\n",
      "train loss:0.201483633992\n",
      "train loss:0.115333206629\n",
      "train loss:0.177041414257\n",
      "train loss:0.202943380778\n",
      "train loss:0.228657020427\n",
      "train loss:0.13108895959\n",
      "train loss:0.199390100075\n",
      "train loss:0.275211657659\n",
      "train loss:0.253665330405\n",
      "train loss:0.24573410029\n",
      "train loss:0.14626700496\n",
      "train loss:0.290272092646\n",
      "train loss:0.161009564596\n",
      "train loss:0.182228509387\n",
      "train loss:0.228010494051\n",
      "train loss:0.361250020346\n",
      "train loss:0.191859852003\n",
      "train loss:0.249022061803\n",
      "train loss:0.197528159714\n",
      "train loss:0.149885004454\n",
      "train loss:0.171732833806\n",
      "train loss:0.130782581278\n",
      "train loss:0.203245259268\n",
      "train loss:0.19663006855\n",
      "train loss:0.242523542269\n",
      "train loss:0.158925442956\n",
      "train loss:0.202606348667\n",
      "train loss:0.248133190946\n",
      "train loss:0.176513101197\n",
      "train loss:0.243953240313\n",
      "train loss:0.213866087853\n",
      "train loss:0.0748449901167\n",
      "train loss:0.157006967087\n",
      "train loss:0.116371770224\n",
      "train loss:0.121202478943\n",
      "train loss:0.251415406636\n",
      "train loss:0.132258004457\n",
      "train loss:0.184360770966\n",
      "train loss:0.153618099772\n",
      "train loss:0.238446518216\n",
      "train loss:0.171190919899\n",
      "train loss:0.231217881341\n",
      "train loss:0.204995671365\n",
      "train loss:0.217139201243\n",
      "train loss:0.148538382352\n",
      "train loss:0.297348165371\n",
      "train loss:0.0908487962905\n",
      "train loss:0.0951245407922\n",
      "train loss:0.124462393765\n",
      "train loss:0.159984534391\n",
      "train loss:0.175034750821\n",
      "train loss:0.141575296552\n",
      "train loss:0.151570803743\n",
      "train loss:0.158816814572\n",
      "train loss:0.208990333681\n",
      "train loss:0.121228684404\n",
      "train loss:0.113025672334\n",
      "train loss:0.123652065478\n",
      "train loss:0.319005333095\n",
      "train loss:0.11510251822\n",
      "train loss:0.194968643116\n",
      "train loss:0.0781431496531\n",
      "train loss:0.156452135435\n",
      "train loss:0.20330582949\n",
      "train loss:0.150342098029\n",
      "train loss:0.142380410539\n",
      "train loss:0.237345274564\n",
      "train loss:0.266211864383\n",
      "train loss:0.0907697110816\n",
      "train loss:0.140097877815\n",
      "train loss:0.245819596491\n",
      "train loss:0.155099774883\n",
      "train loss:0.141035373929\n",
      "train loss:0.124436743174\n",
      "train loss:0.223334984315\n",
      "train loss:0.104138945779\n",
      "train loss:0.17973213269\n",
      "train loss:0.215523701509\n",
      "train loss:0.100952940555\n",
      "train loss:0.236447016035\n",
      "train loss:0.164446593757\n",
      "train loss:0.146165465776\n",
      "train loss:0.230436924718\n",
      "train loss:0.146653790812\n",
      "train loss:0.187498081728\n",
      "train loss:0.158764465026\n",
      "train loss:0.143123845655\n",
      "train loss:0.232945961546\n",
      "train loss:0.200486761997\n",
      "train loss:0.188367346628\n",
      "train loss:0.164264077544\n",
      "train loss:0.212075810156\n",
      "train loss:0.12940755762\n",
      "train loss:0.200541740965\n",
      "train loss:0.105552980037\n",
      "train loss:0.14466320988\n",
      "train loss:0.0916463920984\n",
      "train loss:0.131007985135\n",
      "train loss:0.196720213062\n",
      "train loss:0.116627876352\n",
      "train loss:0.148397252623\n",
      "train loss:0.225312772803\n",
      "train loss:0.244513471703\n",
      "train loss:0.0886693744967\n",
      "train loss:0.103038955692\n",
      "train loss:0.214955259475\n",
      "train loss:0.129482061229\n",
      "train loss:0.144655908941\n",
      "train loss:0.0942527737679\n",
      "train loss:0.14648071024\n",
      "train loss:0.0891857664769\n",
      "train loss:0.112765013065\n",
      "train loss:0.132240352454\n",
      "train loss:0.160206234555\n",
      "train loss:0.123874428623\n",
      "train loss:0.0586051504841\n",
      "train loss:0.159470573161\n",
      "train loss:0.192262765767\n",
      "train loss:0.106003505597\n",
      "train loss:0.171379530933\n",
      "train loss:0.0904459788152\n",
      "train loss:0.127672420461\n",
      "train loss:0.203169696542\n",
      "train loss:0.13562537414\n",
      "train loss:0.185718307462\n",
      "train loss:0.392582916951\n",
      "train loss:0.192350689802\n",
      "train loss:0.222029302628\n",
      "train loss:0.139361129347\n",
      "train loss:0.130523883186\n",
      "train loss:0.268767922971\n",
      "train loss:0.24344690049\n",
      "train loss:0.0921133234703\n",
      "train loss:0.15389598626\n",
      "train loss:0.134264086016\n",
      "train loss:0.219058662653\n",
      "train loss:0.284928997184\n",
      "train loss:0.227776310864\n",
      "train loss:0.205013057105\n",
      "train loss:0.186263196769\n",
      "train loss:0.0723442793773\n",
      "train loss:0.12143987253\n",
      "train loss:0.268743383922\n",
      "train loss:0.248774970799\n",
      "train loss:0.271871775721\n",
      "train loss:0.207289096419\n",
      "train loss:0.0602026324535\n",
      "train loss:0.112568532462\n",
      "train loss:0.129707749646\n",
      "train loss:0.1761412523\n",
      "train loss:0.243001758944\n",
      "train loss:0.159708234975\n",
      "train loss:0.0720349070432\n",
      "train loss:0.128662760966\n",
      "train loss:0.141862149779\n",
      "train loss:0.190738059514\n",
      "train loss:0.240082845123\n",
      "train loss:0.198428672389\n",
      "train loss:0.200561177704\n",
      "train loss:0.179560588348\n",
      "train loss:0.157909890516\n",
      "train loss:0.116953931173\n",
      "train loss:0.152665366819\n",
      "train loss:0.161999904428\n",
      "train loss:0.168628940194\n",
      "train loss:0.118424800244\n",
      "train loss:0.121218651868\n",
      "train loss:0.195353587393\n",
      "train loss:0.161383391695\n",
      "train loss:0.177608480507\n",
      "train loss:0.325670894712\n",
      "train loss:0.119736081744\n",
      "train loss:0.120457574809\n",
      "train loss:0.0674918772845\n",
      "train loss:0.112538312392\n",
      "train loss:0.111327301489\n",
      "train loss:0.0987379056814\n",
      "train loss:0.138174553062\n",
      "train loss:0.14219297664\n",
      "train loss:0.107236369595\n",
      "train loss:0.115385715581\n",
      "train loss:0.0701712171857\n",
      "train loss:0.0858861791932\n",
      "train loss:0.149285755914\n",
      "train loss:0.0891267643429\n",
      "train loss:0.115750910944\n",
      "train loss:0.132799519321\n",
      "train loss:0.146770294882\n",
      "train loss:0.0417414043713\n",
      "train loss:0.136919992572\n",
      "train loss:0.190240519949\n",
      "train loss:0.123429678003\n",
      "train loss:0.117261094499\n",
      "train loss:0.0833570620478\n",
      "train loss:0.128123772464\n",
      "train loss:0.170737279593\n",
      "train loss:0.182377669368\n",
      "train loss:0.301271424932\n",
      "train loss:0.0725542136264\n",
      "train loss:0.0907354500595\n",
      "train loss:0.191958576504\n",
      "train loss:0.11133895513\n",
      "train loss:0.11878593713\n",
      "train loss:0.195313152559\n",
      "train loss:0.0462299621557\n",
      "train loss:0.0599170684065\n",
      "train loss:0.200610022752\n",
      "train loss:0.225035209286\n",
      "train loss:0.15277469594\n",
      "train loss:0.159465839513\n",
      "train loss:0.225925288259\n",
      "train loss:0.0828125904864\n",
      "train loss:0.189400471147\n",
      "train loss:0.117359763935\n",
      "train loss:0.0752240083328\n",
      "train loss:0.143583491662\n",
      "train loss:0.137559298351\n",
      "train loss:0.251627475951\n",
      "train loss:0.11522353563\n",
      "train loss:0.19987811355\n",
      "train loss:0.151730529031\n",
      "train loss:0.110268852402\n",
      "train loss:0.153157200204\n",
      "train loss:0.223813061336\n",
      "train loss:0.19717954052\n",
      "train loss:0.121381430639\n",
      "train loss:0.0702007942032\n",
      "train loss:0.272256047304\n",
      "train loss:0.0829668214222\n",
      "train loss:0.111687988467\n",
      "train loss:0.203212205078\n",
      "train loss:0.175305127177\n",
      "train loss:0.126474251552\n",
      "train loss:0.139447454343\n",
      "train loss:0.082368430969\n",
      "train loss:0.0838876947815\n",
      "train loss:0.190965506943\n",
      "train loss:0.132398230519\n",
      "train loss:0.178975890584\n",
      "train loss:0.102123600022\n",
      "train loss:0.0604716773183\n",
      "train loss:0.11464273995\n",
      "train loss:0.107472123357\n",
      "train loss:0.150905697535\n",
      "train loss:0.126275514439\n",
      "train loss:0.0927318423392\n",
      "train loss:0.0604005068133\n",
      "train loss:0.0902731281533\n",
      "train loss:0.107672307694\n",
      "train loss:0.181671992888\n",
      "train loss:0.133225220808\n",
      "train loss:0.0561160365294\n",
      "=== epoch:2, train acc:0.96, test acc:0.962 ===\n",
      "train loss:0.113496437211\n",
      "train loss:0.143999383077\n",
      "train loss:0.336203303797\n",
      "train loss:0.101086356493\n",
      "train loss:0.107817352652\n",
      "train loss:0.18427628255\n",
      "train loss:0.105182344939\n",
      "train loss:0.056837594756\n",
      "train loss:0.0983679854699\n",
      "train loss:0.0715444434115\n",
      "train loss:0.0966141416411\n",
      "train loss:0.160929591408\n",
      "train loss:0.0642043426593\n",
      "train loss:0.144999704671\n",
      "train loss:0.20825302199\n",
      "train loss:0.112992825004\n",
      "train loss:0.105934945807\n",
      "train loss:0.113193392177\n",
      "train loss:0.0909234994586\n",
      "train loss:0.0591983557076\n",
      "train loss:0.0527016292308\n",
      "train loss:0.0713836860523\n",
      "train loss:0.149104482276\n",
      "train loss:0.0300482953292\n",
      "train loss:0.0941798919983\n",
      "train loss:0.121079822646\n",
      "train loss:0.0731529656509\n",
      "train loss:0.0712981501688\n",
      "train loss:0.113491770828\n",
      "train loss:0.08413914008\n",
      "train loss:0.150173596408\n",
      "train loss:0.0872115887833\n",
      "train loss:0.141688869345\n",
      "train loss:0.204170929458\n",
      "train loss:0.0895338621141\n",
      "train loss:0.160409021307\n",
      "train loss:0.096129051838\n",
      "train loss:0.0575891968099\n",
      "train loss:0.0802503705274\n",
      "train loss:0.116243349612\n",
      "train loss:0.0694439458813\n",
      "train loss:0.108472803524\n",
      "train loss:0.0689342348587\n",
      "train loss:0.0818484913446\n",
      "train loss:0.092156151168\n",
      "train loss:0.0792507092577\n",
      "train loss:0.204414810154\n",
      "train loss:0.12799403139\n",
      "train loss:0.105449019463\n",
      "train loss:0.0788005802665\n",
      "train loss:0.066293357467\n",
      "train loss:0.118385185276\n",
      "train loss:0.087517846728\n",
      "train loss:0.0541653117612\n",
      "train loss:0.157035822688\n",
      "train loss:0.0765658355774\n",
      "train loss:0.11684543733\n",
      "train loss:0.150285454924\n",
      "train loss:0.197234814418\n",
      "train loss:0.210275846811\n",
      "train loss:0.0473438708\n",
      "train loss:0.148378306707\n",
      "train loss:0.0976351254756\n",
      "train loss:0.0906229310098\n",
      "train loss:0.139701739153\n",
      "train loss:0.229977812416\n",
      "train loss:0.0947803969065\n",
      "train loss:0.0719398933066\n",
      "train loss:0.0862176324099\n",
      "train loss:0.198223803339\n",
      "train loss:0.0940516851623\n",
      "train loss:0.0905539729009\n",
      "train loss:0.124404544787\n",
      "train loss:0.0868690546347\n",
      "train loss:0.185098089957\n",
      "train loss:0.0735175352275\n",
      "train loss:0.0814156252669\n",
      "train loss:0.14623064108\n",
      "train loss:0.100283473678\n",
      "train loss:0.129526152277\n",
      "train loss:0.101528969201\n",
      "train loss:0.122156729639\n",
      "train loss:0.0911017480443\n",
      "train loss:0.108240607398\n",
      "train loss:0.0749086681933\n",
      "train loss:0.0784663171349\n",
      "train loss:0.0557447547879\n",
      "train loss:0.0590852187502\n",
      "train loss:0.161997108737\n",
      "train loss:0.123502724074\n",
      "train loss:0.0344200164784\n",
      "train loss:0.0497279757315\n",
      "train loss:0.127315157048\n",
      "train loss:0.25582668616\n",
      "train loss:0.123198817735\n",
      "train loss:0.143843667265\n",
      "train loss:0.0553111696\n",
      "train loss:0.227244894356\n",
      "train loss:0.0899392768456\n",
      "train loss:0.0764845229467\n",
      "train loss:0.181284011236\n",
      "train loss:0.0829268168181\n",
      "train loss:0.139223950775\n",
      "train loss:0.0459951095416\n",
      "train loss:0.164402098889\n",
      "train loss:0.121204605146\n",
      "train loss:0.0807251582185\n",
      "train loss:0.101059087413\n",
      "train loss:0.199745306034\n",
      "train loss:0.126071323585\n",
      "train loss:0.0961727100772\n",
      "train loss:0.0700505691512\n",
      "train loss:0.122640113899\n",
      "train loss:0.0767345958622\n",
      "train loss:0.158042259141\n",
      "train loss:0.0657312858153\n",
      "train loss:0.146779922259\n",
      "train loss:0.102635254233\n",
      "train loss:0.123133363054\n",
      "train loss:0.0965134598549\n",
      "train loss:0.110201549234\n",
      "train loss:0.0959222276981\n",
      "train loss:0.123817119929\n",
      "train loss:0.0814409677581\n",
      "train loss:0.0644240827635\n",
      "train loss:0.161809340341\n",
      "train loss:0.162966017742\n",
      "train loss:0.089569562149\n",
      "train loss:0.124755671111\n",
      "train loss:0.106631797461\n",
      "train loss:0.0917237941106\n",
      "train loss:0.252666493606\n",
      "train loss:0.0609507225327\n",
      "train loss:0.126560252613\n",
      "train loss:0.11007622475\n",
      "train loss:0.189375779624\n",
      "train loss:0.10481184363\n",
      "train loss:0.0603627705513\n",
      "train loss:0.178949623965\n",
      "train loss:0.138656999504\n",
      "train loss:0.0645988609572\n",
      "train loss:0.0970268979291\n",
      "train loss:0.0626018003396\n",
      "train loss:0.0920455230174\n",
      "train loss:0.122616196961\n",
      "train loss:0.0354397993739\n",
      "train loss:0.0912397526303\n",
      "train loss:0.0994736110435\n",
      "train loss:0.0482483726459\n",
      "train loss:0.0612517561863\n",
      "train loss:0.10464720623\n",
      "train loss:0.120429439197\n",
      "train loss:0.099651814744\n",
      "train loss:0.104702674244\n",
      "train loss:0.194089105446\n",
      "train loss:0.108681485047\n",
      "train loss:0.0528609668975\n",
      "train loss:0.0801080966966\n",
      "train loss:0.121565464112\n",
      "train loss:0.148676551556\n",
      "train loss:0.147351130247\n",
      "train loss:0.047860843843\n",
      "train loss:0.0924502175946\n",
      "train loss:0.0637795635338\n",
      "train loss:0.196861135505\n",
      "train loss:0.0364449068382\n",
      "train loss:0.245647575576\n",
      "train loss:0.0666990539305\n",
      "train loss:0.0860911860254\n",
      "train loss:0.161756674659\n",
      "train loss:0.0634638588347\n",
      "train loss:0.0656423332508\n",
      "train loss:0.057061475358\n",
      "train loss:0.171098552419\n",
      "train loss:0.19776933702\n",
      "train loss:0.064796527902\n",
      "train loss:0.0544450857081\n",
      "train loss:0.139130354149\n",
      "train loss:0.0504908885888\n",
      "train loss:0.107887145146\n",
      "train loss:0.209026390576\n",
      "train loss:0.0832501515401\n",
      "train loss:0.0858223100648\n",
      "train loss:0.0659928078606\n",
      "train loss:0.0745242126709\n",
      "train loss:0.126806863797\n",
      "train loss:0.11295633526\n",
      "train loss:0.0644248036707\n",
      "train loss:0.18002937123\n",
      "train loss:0.0853785381843\n",
      "train loss:0.115474526841\n",
      "train loss:0.192023679841\n",
      "train loss:0.0862606401905\n",
      "train loss:0.0533145617692\n",
      "train loss:0.0881718639767\n",
      "train loss:0.212216046135\n",
      "train loss:0.0629404917907\n",
      "train loss:0.0622848274257\n",
      "train loss:0.086536095988\n",
      "train loss:0.126367616613\n",
      "train loss:0.188278330153\n",
      "train loss:0.115254969627\n",
      "train loss:0.103428110255\n",
      "train loss:0.133382999047\n",
      "train loss:0.103436171417\n",
      "train loss:0.0928632224345\n",
      "train loss:0.0436982609526\n",
      "train loss:0.145067011417\n",
      "train loss:0.0824872416213\n",
      "train loss:0.0844698594939\n",
      "train loss:0.117410658193\n",
      "train loss:0.0557844443622\n",
      "train loss:0.0795000767426\n",
      "train loss:0.0691729582183\n",
      "train loss:0.0970014070633\n",
      "train loss:0.118421268516\n",
      "train loss:0.104855833162\n",
      "train loss:0.0939872354099\n",
      "train loss:0.075140791124\n",
      "train loss:0.0266228469338\n",
      "train loss:0.055822947075\n",
      "train loss:0.166367398026\n",
      "train loss:0.104144254482\n",
      "train loss:0.0344818098659\n",
      "train loss:0.0843890078932\n",
      "train loss:0.13761526125\n",
      "train loss:0.108008251696\n",
      "train loss:0.0393970954053\n",
      "train loss:0.0895877121817\n",
      "train loss:0.050215663459\n",
      "train loss:0.0953973256256\n",
      "train loss:0.0786023177695\n",
      "train loss:0.214374402509\n",
      "train loss:0.0471877063341\n",
      "train loss:0.107964639385\n",
      "train loss:0.0450316091109\n",
      "train loss:0.0886284220018\n",
      "train loss:0.10225697852\n",
      "train loss:0.103876112562\n",
      "train loss:0.0522293699492\n",
      "train loss:0.141876624201\n",
      "train loss:0.0322058130884\n",
      "train loss:0.0865204685906\n",
      "train loss:0.133801044259\n",
      "train loss:0.0843879245534\n",
      "train loss:0.0812722518246\n",
      "train loss:0.0452797749547\n",
      "train loss:0.0925367286683\n",
      "train loss:0.0855282579779\n",
      "train loss:0.0692171915196\n",
      "train loss:0.0758480092072\n",
      "train loss:0.0972061953602\n",
      "train loss:0.0754705984871\n",
      "train loss:0.0937922802016\n",
      "train loss:0.111833788636\n",
      "train loss:0.0817248569976\n",
      "train loss:0.0884579300075\n",
      "train loss:0.137148292313\n",
      "train loss:0.0606523065785\n",
      "train loss:0.0353852837572\n",
      "train loss:0.0548283803993\n",
      "train loss:0.0495516410601\n",
      "train loss:0.0796288029383\n",
      "train loss:0.111573470711\n",
      "train loss:0.0705318570837\n",
      "train loss:0.240787541504\n",
      "train loss:0.104182932541\n",
      "train loss:0.114238889465\n",
      "train loss:0.034317438786\n",
      "train loss:0.026884413194\n",
      "train loss:0.103732312982\n",
      "train loss:0.093305996405\n",
      "train loss:0.173858780952\n",
      "train loss:0.0801232398844\n",
      "train loss:0.0597192817049\n",
      "train loss:0.0894590515267\n",
      "train loss:0.0591660018471\n",
      "train loss:0.0422541325604\n",
      "train loss:0.093843354429\n",
      "train loss:0.034761080052\n",
      "train loss:0.0431313884189\n",
      "train loss:0.132388833503\n",
      "train loss:0.116426909272\n",
      "train loss:0.0270629567595\n",
      "train loss:0.0735608231943\n",
      "train loss:0.120121017269\n",
      "train loss:0.024494685972\n",
      "train loss:0.101354704118\n",
      "train loss:0.10618822264\n",
      "train loss:0.0725977789756\n",
      "train loss:0.0570776569083\n",
      "train loss:0.135152708359\n",
      "train loss:0.0666904687618\n",
      "train loss:0.145317755003\n",
      "train loss:0.059004175242\n",
      "train loss:0.0991803970429\n",
      "train loss:0.05479130719\n",
      "train loss:0.104079779318\n",
      "train loss:0.0542227038427\n",
      "train loss:0.0531383595414\n",
      "train loss:0.0868948679375\n",
      "train loss:0.028362652001\n",
      "train loss:0.0830567139162\n",
      "train loss:0.197627433574\n",
      "train loss:0.053773144143\n",
      "train loss:0.130484658946\n",
      "train loss:0.048195346043\n",
      "train loss:0.0635139616013\n",
      "train loss:0.0826024121329\n",
      "train loss:0.0848014440894\n",
      "train loss:0.100794261179\n",
      "train loss:0.0494738777061\n",
      "train loss:0.0561176174992\n",
      "train loss:0.0984180061361\n",
      "train loss:0.0834610632879\n",
      "train loss:0.0788689848727\n",
      "train loss:0.0444843841528\n",
      "train loss:0.0398719814454\n",
      "train loss:0.123387217057\n",
      "train loss:0.0649244772447\n",
      "train loss:0.106823328051\n",
      "train loss:0.0593924379536\n",
      "train loss:0.230273962618\n",
      "train loss:0.0702802856271\n",
      "train loss:0.168618720804\n",
      "train loss:0.174846433738\n",
      "train loss:0.0426957893608\n",
      "train loss:0.108128701029\n",
      "train loss:0.0540385396418\n",
      "train loss:0.0730193920939\n",
      "train loss:0.162395048406\n",
      "train loss:0.0779909692959\n",
      "train loss:0.037427034012\n",
      "train loss:0.0389409432634\n",
      "train loss:0.101597422249\n",
      "train loss:0.135604179975\n",
      "train loss:0.11253912174\n",
      "train loss:0.0474814273942\n",
      "train loss:0.110410846118\n",
      "train loss:0.0596951163282\n",
      "train loss:0.0491173021912\n",
      "train loss:0.051195636604\n",
      "train loss:0.0425873692735\n",
      "train loss:0.0750708181669\n",
      "train loss:0.0564909067303\n",
      "train loss:0.0768734013491\n",
      "train loss:0.0416601079158\n",
      "train loss:0.0607732139771\n",
      "train loss:0.0763924393566\n",
      "train loss:0.101004141517\n",
      "train loss:0.0535108026861\n",
      "train loss:0.0386400852491\n",
      "train loss:0.063428424117\n",
      "train loss:0.0930086728147\n",
      "train loss:0.111090412794\n",
      "train loss:0.087452006133\n",
      "train loss:0.0623569756383\n",
      "train loss:0.0529929714142\n",
      "train loss:0.0480823742946\n",
      "train loss:0.0238420403617\n",
      "train loss:0.0983098091692\n",
      "train loss:0.0515296526646\n",
      "train loss:0.133343246548\n",
      "train loss:0.0493329716733\n",
      "train loss:0.0583466025296\n",
      "train loss:0.0664204051322\n",
      "train loss:0.0496472507224\n",
      "train loss:0.0323057375723\n",
      "train loss:0.0859994446157\n",
      "train loss:0.0945086444948\n",
      "train loss:0.146923912938\n",
      "train loss:0.0465257253127\n",
      "train loss:0.129079105554\n",
      "train loss:0.0473604255462\n",
      "train loss:0.0666445304995\n",
      "train loss:0.17121467425\n",
      "train loss:0.180461569574\n",
      "train loss:0.0951482574927\n",
      "train loss:0.13450233475\n",
      "train loss:0.0421651497326\n",
      "train loss:0.0738768392905\n",
      "train loss:0.100004986059\n",
      "train loss:0.0734550945626\n",
      "train loss:0.127544177691\n",
      "train loss:0.198854758606\n",
      "train loss:0.0947091360742\n",
      "train loss:0.0855221563259\n",
      "train loss:0.0863980511198\n",
      "train loss:0.0723176669467\n",
      "train loss:0.0355575531874\n",
      "train loss:0.128605537759\n",
      "train loss:0.0597259236609\n",
      "train loss:0.0530636733762\n",
      "train loss:0.0153868069195\n",
      "train loss:0.0183292918961\n",
      "train loss:0.0645580221074\n",
      "train loss:0.0839157620125\n",
      "train loss:0.0498758798544\n",
      "train loss:0.0369196290022\n",
      "train loss:0.108267950102\n",
      "train loss:0.0987719890265\n",
      "train loss:0.0540004108102\n",
      "train loss:0.100063682073\n",
      "train loss:0.129022288813\n",
      "train loss:0.0464496787517\n",
      "train loss:0.0695255083199\n",
      "train loss:0.0681495754366\n",
      "train loss:0.0862239528224\n",
      "train loss:0.0621751915412\n",
      "train loss:0.0683343073959\n",
      "train loss:0.0830981713806\n",
      "train loss:0.0789660178912\n",
      "train loss:0.0947637393005\n",
      "train loss:0.156462326581\n",
      "train loss:0.0504747323448\n",
      "train loss:0.065002553827\n",
      "train loss:0.0340547901278\n",
      "train loss:0.0714374646039\n",
      "train loss:0.0310183467785\n",
      "train loss:0.0320916017137\n",
      "train loss:0.0637580238648\n",
      "train loss:0.0597626951779\n",
      "train loss:0.0478996229669\n",
      "train loss:0.0609426767047\n",
      "train loss:0.0124470990236\n",
      "train loss:0.0476031910565\n",
      "train loss:0.0272838283904\n",
      "train loss:0.10240973677\n",
      "train loss:0.0520720495318\n",
      "train loss:0.0296511841026\n",
      "train loss:0.0358591209107\n",
      "train loss:0.0191898781296\n",
      "train loss:0.0599365413579\n",
      "train loss:0.0501547142805\n",
      "train loss:0.0764896876454\n",
      "train loss:0.123770450365\n",
      "train loss:0.0780176469836\n",
      "train loss:0.0703545697867\n",
      "train loss:0.0508860191185\n",
      "train loss:0.115772278939\n",
      "train loss:0.0959363467096\n",
      "train loss:0.0258875702346\n",
      "train loss:0.0510004290194\n",
      "train loss:0.0855000171282\n",
      "train loss:0.057058825914\n",
      "train loss:0.0775445879015\n",
      "train loss:0.12032258245\n",
      "train loss:0.0802168541601\n",
      "train loss:0.049884048037\n",
      "train loss:0.14183812635\n",
      "train loss:0.181676686826\n",
      "train loss:0.04585243324\n",
      "train loss:0.0893712753013\n",
      "train loss:0.0210289484219\n",
      "train loss:0.0853538003141\n",
      "train loss:0.0407963227448\n",
      "train loss:0.0420048013083\n",
      "train loss:0.0189386483555\n",
      "train loss:0.0578142167819\n",
      "train loss:0.0400367957194\n",
      "train loss:0.0493463853206\n",
      "train loss:0.0901997516681\n",
      "train loss:0.0479697652965\n",
      "train loss:0.170830505373\n",
      "train loss:0.124486926591\n",
      "train loss:0.0476033245125\n",
      "train loss:0.0472023282569\n",
      "train loss:0.0393663459948\n",
      "train loss:0.067687598186\n",
      "train loss:0.0147743071301\n",
      "train loss:0.129647025037\n",
      "train loss:0.135106789656\n",
      "train loss:0.0444777298418\n",
      "train loss:0.152311028902\n",
      "train loss:0.0250636923239\n",
      "train loss:0.109626139268\n",
      "train loss:0.118694370234\n",
      "train loss:0.053155963397\n",
      "train loss:0.0637990978953\n",
      "train loss:0.067144226272\n",
      "train loss:0.0566847208796\n",
      "train loss:0.0816638763812\n",
      "train loss:0.0462775951943\n",
      "train loss:0.0625595869509\n",
      "train loss:0.108480855836\n",
      "train loss:0.0468022488449\n",
      "train loss:0.0295887685242\n",
      "train loss:0.112620607411\n",
      "train loss:0.0411017002435\n",
      "train loss:0.0465266400755\n",
      "train loss:0.101511758498\n",
      "train loss:0.0855363984785\n",
      "train loss:0.0674357923577\n",
      "train loss:0.0769379686187\n",
      "train loss:0.0647797414188\n",
      "train loss:0.0434875935686\n",
      "train loss:0.133969478377\n",
      "train loss:0.107807657495\n",
      "train loss:0.0336345972131\n",
      "train loss:0.052320874946\n",
      "train loss:0.0511796851099\n",
      "train loss:0.035429701956\n",
      "train loss:0.119098491043\n",
      "train loss:0.0503264532588\n",
      "train loss:0.0508996866793\n",
      "train loss:0.0184890202781\n",
      "train loss:0.0206460941211\n",
      "train loss:0.0924259867097\n",
      "train loss:0.148593166075\n",
      "train loss:0.0529745995679\n",
      "train loss:0.0456835684552\n",
      "train loss:0.0564956081604\n",
      "train loss:0.103696455736\n",
      "train loss:0.0531401410161\n",
      "train loss:0.0442861157033\n",
      "train loss:0.060893320274\n",
      "train loss:0.0416204292684\n",
      "train loss:0.0700672679574\n",
      "train loss:0.0722984807155\n",
      "train loss:0.0923855980372\n",
      "train loss:0.139744097404\n",
      "train loss:0.0564255048432\n",
      "train loss:0.100731896461\n",
      "train loss:0.0276328284413\n",
      "train loss:0.0218388172843\n",
      "train loss:0.091594678617\n",
      "train loss:0.0760761199268\n",
      "train loss:0.0422161430951\n",
      "train loss:0.222867922889\n",
      "train loss:0.0696050587415\n",
      "train loss:0.0471171221641\n",
      "train loss:0.0219450692705\n",
      "train loss:0.0301131319778\n",
      "train loss:0.0856798292078\n",
      "train loss:0.067520030735\n",
      "train loss:0.112634310958\n",
      "train loss:0.102290601803\n",
      "train loss:0.0371650944878\n",
      "train loss:0.0355484260337\n",
      "train loss:0.0665853751845\n",
      "train loss:0.0613912203112\n",
      "train loss:0.0956396777871\n",
      "train loss:0.0495994099193\n",
      "train loss:0.052443186692\n",
      "train loss:0.0906559877295\n",
      "train loss:0.0246286639549\n",
      "train loss:0.112916985526\n",
      "train loss:0.041236740329\n",
      "train loss:0.0459466385268\n",
      "train loss:0.0697315452291\n",
      "train loss:0.0566647076172\n",
      "train loss:0.0934856896342\n",
      "train loss:0.07355565603\n",
      "train loss:0.0664470037118\n",
      "train loss:0.0746054930139\n",
      "train loss:0.0579269284622\n",
      "train loss:0.055674358845\n",
      "train loss:0.0545206791294\n",
      "train loss:0.0746749475933\n",
      "train loss:0.0369648447228\n",
      "train loss:0.0391536965523\n",
      "train loss:0.0349422296069\n",
      "train loss:0.0383524014708\n",
      "train loss:0.0330260503296\n",
      "train loss:0.0562318432655\n",
      "train loss:0.0541451172141\n",
      "train loss:0.0565728991272\n",
      "train loss:0.0734052466241\n",
      "train loss:0.123100664754\n",
      "train loss:0.1260941519\n",
      "train loss:0.0771821807393\n",
      "train loss:0.0475375236507\n",
      "train loss:0.0455329749201\n",
      "train loss:0.0362898497598\n",
      "train loss:0.0316854877986\n",
      "train loss:0.095286125254\n",
      "train loss:0.0808638215257\n",
      "train loss:0.0156854586915\n",
      "train loss:0.0418955576327\n",
      "train loss:0.0824593931579\n",
      "train loss:0.0642795602242\n",
      "train loss:0.0325964066939\n",
      "train loss:0.1127975247\n",
      "train loss:0.0552039184927\n",
      "train loss:0.0299511165214\n",
      "train loss:0.0256197458484\n",
      "train loss:0.0868068158596\n",
      "train loss:0.0924177574101\n",
      "train loss:0.0302777022909\n",
      "train loss:0.0657160723273\n",
      "train loss:0.109562971385\n",
      "train loss:0.0676626633779\n",
      "train loss:0.0416291323237\n",
      "train loss:0.0310497042256\n",
      "train loss:0.0564488796827\n",
      "train loss:0.0325069956295\n",
      "train loss:0.0295342031536\n",
      "train loss:0.0289698179336\n",
      "train loss:0.0265389189853\n",
      "train loss:0.0754999516755\n",
      "=== epoch:3, train acc:0.976, test acc:0.978 ===\n",
      "train loss:0.0286026877541\n",
      "train loss:0.0632375101462\n",
      "train loss:0.110679549556\n",
      "train loss:0.0469749804155\n",
      "train loss:0.0234079273257\n",
      "train loss:0.0528413415636\n",
      "train loss:0.0483740551889\n",
      "train loss:0.0450790519003\n",
      "train loss:0.118182648185\n",
      "train loss:0.0941808725321\n",
      "train loss:0.0964283738495\n",
      "train loss:0.0846129338658\n",
      "train loss:0.0367583001821\n",
      "train loss:0.0387069948365\n",
      "train loss:0.07704204369\n",
      "train loss:0.100535795813\n",
      "train loss:0.0846283007734\n",
      "train loss:0.150177180289\n",
      "train loss:0.165143958832\n",
      "train loss:0.0461041833088\n",
      "train loss:0.0463324773878\n",
      "train loss:0.0671443145126\n",
      "train loss:0.0621456164898\n",
      "train loss:0.063445803941\n",
      "train loss:0.0600489867418\n",
      "train loss:0.057994784214\n",
      "train loss:0.104256125477\n",
      "train loss:0.0183432310021\n",
      "train loss:0.0502346677405\n",
      "train loss:0.0261970067917\n",
      "train loss:0.0436729706632\n",
      "train loss:0.0436052538238\n",
      "train loss:0.0628216098861\n",
      "train loss:0.038294112392\n",
      "train loss:0.11915561848\n",
      "train loss:0.0728483441385\n",
      "train loss:0.0386364901768\n",
      "train loss:0.0251977181598\n",
      "train loss:0.0605121400584\n",
      "train loss:0.0782442541147\n",
      "train loss:0.0842816731442\n",
      "train loss:0.158152910596\n",
      "train loss:0.0595542641479\n",
      "train loss:0.0372476637114\n",
      "train loss:0.0538594096187\n",
      "train loss:0.0228492071542\n",
      "train loss:0.0258748651409\n",
      "train loss:0.156350641662\n",
      "train loss:0.113347083301\n",
      "train loss:0.031251907211\n",
      "train loss:0.0493005358759\n",
      "train loss:0.0526783161266\n",
      "train loss:0.0824880543429\n",
      "train loss:0.0314260104491\n",
      "train loss:0.0429944351575\n",
      "train loss:0.021109295166\n",
      "train loss:0.036001580073\n",
      "train loss:0.124847112005\n",
      "train loss:0.0536346875731\n",
      "train loss:0.0242770601266\n",
      "train loss:0.0180474381108\n",
      "train loss:0.180949330434\n",
      "train loss:0.0913728468108\n",
      "train loss:0.0690969916341\n",
      "train loss:0.0161557921248\n",
      "train loss:0.0830632938286\n",
      "train loss:0.049293592809\n",
      "train loss:0.0301821273825\n",
      "train loss:0.1490455335\n",
      "train loss:0.0308172382697\n",
      "train loss:0.0568061818798\n",
      "train loss:0.0512686702018\n",
      "train loss:0.0419960674187\n",
      "train loss:0.0637797905451\n",
      "train loss:0.0449460573478\n",
      "train loss:0.0944908986333\n",
      "train loss:0.0957692605361\n",
      "train loss:0.071528455304\n",
      "train loss:0.128015868549\n",
      "train loss:0.0783304849108\n",
      "train loss:0.0424810043069\n",
      "train loss:0.0607763856421\n",
      "train loss:0.0418522321468\n",
      "train loss:0.0448731136944\n",
      "train loss:0.0215615520912\n",
      "train loss:0.0506043412007\n",
      "train loss:0.0660955247703\n",
      "train loss:0.0615284765133\n",
      "train loss:0.0476669412048\n",
      "train loss:0.0476119670053\n",
      "train loss:0.0225971644434\n",
      "train loss:0.0266807493429\n",
      "train loss:0.0995463661593\n",
      "train loss:0.0271051184154\n",
      "train loss:0.0487227322917\n",
      "train loss:0.0506537292117\n",
      "train loss:0.0710319863616\n",
      "train loss:0.0662837419968\n",
      "train loss:0.0278758534633\n",
      "train loss:0.0181413645061\n",
      "train loss:0.0863838658434\n",
      "train loss:0.0688328227688\n",
      "train loss:0.0425327348447\n",
      "train loss:0.017228616583\n",
      "train loss:0.0385673214173\n",
      "train loss:0.0422051896035\n",
      "train loss:0.102342953306\n",
      "train loss:0.0483189675385\n",
      "train loss:0.0411889538268\n",
      "train loss:0.0200614442451\n",
      "train loss:0.0463449803933\n",
      "train loss:0.0353553197906\n",
      "train loss:0.0724616365446\n",
      "train loss:0.0652746861109\n",
      "train loss:0.153271989823\n",
      "train loss:0.0556359702399\n",
      "train loss:0.0239793999637\n",
      "train loss:0.0487470500788\n",
      "train loss:0.0887924819835\n",
      "train loss:0.0259236778938\n",
      "train loss:0.0571684279163\n",
      "train loss:0.0468135290996\n",
      "train loss:0.10061104758\n",
      "train loss:0.120364604836\n",
      "train loss:0.0248923975776\n",
      "train loss:0.0370940090541\n",
      "train loss:0.0651078044994\n",
      "train loss:0.0256092584995\n",
      "train loss:0.0482087793268\n",
      "train loss:0.0284820876525\n",
      "train loss:0.0720208353658\n",
      "train loss:0.133208654234\n",
      "train loss:0.0252538531194\n",
      "train loss:0.0647094881496\n",
      "train loss:0.0261019502121\n",
      "train loss:0.0242065432718\n",
      "train loss:0.0812339774624\n",
      "train loss:0.0532628394409\n",
      "train loss:0.0412243401437\n",
      "train loss:0.0319520324753\n",
      "train loss:0.0555354028077\n",
      "train loss:0.0418640366328\n",
      "train loss:0.0192152266412\n",
      "train loss:0.0460529434091\n",
      "train loss:0.0989275406855\n",
      "train loss:0.0527672973992\n",
      "train loss:0.0396953244533\n",
      "train loss:0.0602805138559\n",
      "train loss:0.0137410982952\n",
      "train loss:0.053169718406\n",
      "train loss:0.0427498684755\n",
      "train loss:0.0337532135122\n",
      "train loss:0.0186129904729\n",
      "train loss:0.0641204540234\n",
      "train loss:0.0255158754778\n",
      "train loss:0.00926901979267\n",
      "train loss:0.0980619500991\n",
      "train loss:0.0238511658729\n",
      "train loss:0.0731583516125\n",
      "train loss:0.0357370107533\n",
      "train loss:0.0342483339782\n",
      "train loss:0.0507656135246\n",
      "train loss:0.0670982672907\n",
      "train loss:0.0157430149169\n",
      "train loss:0.0175075392241\n",
      "train loss:0.032286188374\n",
      "train loss:0.209261630056\n",
      "train loss:0.0541424009691\n",
      "train loss:0.0210852332546\n",
      "train loss:0.0429462517955\n",
      "train loss:0.0524515747499\n",
      "train loss:0.038585906488\n",
      "train loss:0.100381475331\n",
      "train loss:0.105965123216\n",
      "train loss:0.0585018624066\n",
      "train loss:0.0584916107904\n",
      "train loss:0.0221782054142\n",
      "train loss:0.0851247907935\n",
      "train loss:0.0786914329113\n",
      "train loss:0.0290616271726\n",
      "train loss:0.0400840722515\n",
      "train loss:0.0220664123301\n",
      "train loss:0.0276688258614\n",
      "train loss:0.0789951354112\n",
      "train loss:0.0148001462592\n",
      "train loss:0.10154564524\n",
      "train loss:0.0588183109199\n",
      "train loss:0.0801684321727\n",
      "train loss:0.0764171503374\n",
      "train loss:0.0219193030997\n",
      "train loss:0.0334203312411\n",
      "train loss:0.0630914598187\n",
      "train loss:0.0759758096631\n",
      "train loss:0.0786082652342\n",
      "train loss:0.0649130132297\n",
      "train loss:0.0565349689332\n",
      "train loss:0.0232499459409\n",
      "train loss:0.012235029585\n",
      "train loss:0.173047547805\n",
      "train loss:0.0523985233976\n",
      "train loss:0.0693919664993\n",
      "train loss:0.0271588061115\n",
      "train loss:0.044697081903\n",
      "train loss:0.109487190292\n",
      "train loss:0.11859748657\n",
      "train loss:0.0451779032468\n",
      "train loss:0.0203261006138\n",
      "train loss:0.0201999064876\n",
      "train loss:0.0289716748478\n",
      "train loss:0.0741460781032\n",
      "train loss:0.0676097697189\n",
      "train loss:0.013675878593\n",
      "train loss:0.0373647356594\n",
      "train loss:0.0215841972401\n",
      "train loss:0.057084427514\n",
      "train loss:0.0393892392653\n",
      "train loss:0.110169729709\n",
      "train loss:0.0740729701461\n",
      "train loss:0.0224946577881\n",
      "train loss:0.0412331882139\n",
      "train loss:0.0239507281643\n",
      "train loss:0.045296949326\n",
      "train loss:0.0361410937033\n",
      "train loss:0.0480096869545\n",
      "train loss:0.0296623004338\n",
      "train loss:0.0634743434104\n",
      "train loss:0.0819442065458\n",
      "train loss:0.0829873557693\n",
      "train loss:0.0361340911066\n",
      "train loss:0.0640930658587\n",
      "train loss:0.0556314425511\n",
      "train loss:0.136946682563\n",
      "train loss:0.0785119026582\n",
      "train loss:0.118768561049\n",
      "train loss:0.0367592296341\n",
      "train loss:0.133429560498\n",
      "train loss:0.0354439555437\n",
      "train loss:0.0401330365897\n",
      "train loss:0.0533913196266\n",
      "train loss:0.108126276138\n",
      "train loss:0.0474413124614\n",
      "train loss:0.0757486481431\n",
      "train loss:0.046068724973\n",
      "train loss:0.0306988700516\n",
      "train loss:0.0373198809341\n",
      "train loss:0.00486451459467\n",
      "train loss:0.0282724119424\n",
      "train loss:0.0711736812917\n",
      "train loss:0.0578287081473\n",
      "train loss:0.0226347902985\n",
      "train loss:0.025084751552\n",
      "train loss:0.0474505362978\n",
      "train loss:0.0377886484087\n",
      "train loss:0.0251528390189\n",
      "train loss:0.0179655991653\n",
      "train loss:0.0348829876739\n",
      "train loss:0.047111012053\n",
      "train loss:0.0876736291533\n",
      "train loss:0.108991415601\n",
      "train loss:0.0443453203732\n",
      "train loss:0.111245928209\n",
      "train loss:0.106668715677\n",
      "train loss:0.102088791155\n",
      "train loss:0.188218928544\n",
      "train loss:0.0399336494695\n",
      "train loss:0.0290629559358\n",
      "train loss:0.120278213597\n",
      "train loss:0.0585888689463\n",
      "train loss:0.075187781392\n",
      "train loss:0.0292305539821\n",
      "train loss:0.112292232933\n",
      "train loss:0.0433403895471\n",
      "train loss:0.0170272034373\n",
      "train loss:0.0628315487724\n",
      "train loss:0.0140391213972\n",
      "train loss:0.0443825997539\n",
      "train loss:0.0280818813188\n",
      "train loss:0.018665753939\n",
      "train loss:0.0244112012619\n",
      "train loss:0.0469119496204\n",
      "train loss:0.0483839000513\n",
      "train loss:0.0547824919764\n",
      "train loss:0.0393147563019\n",
      "train loss:0.0339106825212\n",
      "train loss:0.0180842627823\n",
      "train loss:0.124966816044\n",
      "train loss:0.0561158553404\n",
      "train loss:0.0361698010932\n",
      "train loss:0.0806486526951\n",
      "train loss:0.0845440602148\n",
      "train loss:0.0575175774985\n",
      "train loss:0.0580059782542\n",
      "train loss:0.0528202221702\n",
      "train loss:0.112983000942\n",
      "train loss:0.0402535315441\n",
      "train loss:0.0204320621948\n",
      "train loss:0.033148692637\n",
      "train loss:0.128884512899\n",
      "train loss:0.0850237926282\n",
      "train loss:0.0627963726897\n",
      "train loss:0.0301460613328\n",
      "train loss:0.0177758502641\n",
      "train loss:0.0303064515011\n",
      "train loss:0.0528654748062\n",
      "train loss:0.0819542141343\n",
      "train loss:0.0399361574665\n",
      "train loss:0.109432028037\n",
      "train loss:0.0723701328031\n",
      "train loss:0.0411577545359\n",
      "train loss:0.045525871096\n",
      "train loss:0.0138047828974\n",
      "train loss:0.0336891694989\n",
      "train loss:0.0364982188053\n",
      "train loss:0.0466005920802\n",
      "train loss:0.0239719022182\n",
      "train loss:0.0837998129321\n",
      "train loss:0.116020534968\n",
      "train loss:0.0450130222417\n",
      "train loss:0.0706275097602\n",
      "train loss:0.022960137877\n",
      "train loss:0.0401837403106\n",
      "train loss:0.147088092574\n",
      "train loss:0.050767364395\n",
      "train loss:0.0384040621167\n",
      "train loss:0.0585160823801\n",
      "train loss:0.0693469708456\n",
      "train loss:0.058511040858\n",
      "train loss:0.0236909910137\n",
      "train loss:0.0246072532135\n",
      "train loss:0.0364489483872\n",
      "train loss:0.0365293742658\n",
      "train loss:0.0471458759395\n",
      "train loss:0.0415339738163\n",
      "train loss:0.0490826476512\n",
      "train loss:0.0547358084903\n",
      "train loss:0.0246225963986\n",
      "train loss:0.0576125314341\n",
      "train loss:0.0202618308123\n",
      "train loss:0.0816805577663\n",
      "train loss:0.0800758956506\n",
      "train loss:0.0491628397709\n",
      "train loss:0.142439794385\n",
      "train loss:0.064403386926\n",
      "train loss:0.0398855070006\n",
      "train loss:0.0374729983563\n",
      "train loss:0.105574672852\n",
      "train loss:0.0181184878458\n",
      "train loss:0.0758280426051\n",
      "train loss:0.0106407894084\n",
      "train loss:0.063255406308\n",
      "train loss:0.0490757412283\n",
      "train loss:0.0209309547139\n",
      "train loss:0.058098240774\n",
      "train loss:0.0765361285578\n",
      "train loss:0.0406754691467\n",
      "train loss:0.0214163495021\n",
      "train loss:0.067879801219\n",
      "train loss:0.0149592806005\n",
      "train loss:0.0523396973872\n",
      "train loss:0.0877899664846\n",
      "train loss:0.0315354478728\n",
      "train loss:0.0292861685466\n",
      "train loss:0.0399160413685\n",
      "train loss:0.0221020423771\n",
      "train loss:0.0220506353281\n",
      "train loss:0.0303654608362\n",
      "train loss:0.0456472768116\n",
      "train loss:0.0935610308159\n",
      "train loss:0.0415584586473\n",
      "train loss:0.0510988844829\n",
      "train loss:0.106296248584\n",
      "train loss:0.0513151680211\n",
      "train loss:0.0304675212428\n",
      "train loss:0.00849159560773\n",
      "train loss:0.0466256095529\n",
      "train loss:0.0233025559534\n",
      "train loss:0.0296180088591\n",
      "train loss:0.111206965142\n",
      "train loss:0.0336877674138\n",
      "train loss:0.0314179277063\n",
      "train loss:0.0152319610416\n",
      "train loss:0.0206501159093\n",
      "train loss:0.0514809689218\n",
      "train loss:0.052711156741\n",
      "train loss:0.00951707003705\n",
      "train loss:0.0161602184376\n",
      "train loss:0.0418201975244\n",
      "train loss:0.0413693317056\n",
      "train loss:0.0385697719497\n",
      "train loss:0.0302083900656\n",
      "train loss:0.0131829958577\n",
      "train loss:0.130968011641\n",
      "train loss:0.0484742373008\n",
      "train loss:0.0262027346865\n",
      "train loss:0.0562336259832\n",
      "train loss:0.0311747573959\n",
      "train loss:0.0814592346578\n",
      "train loss:0.0606242377042\n",
      "train loss:0.0341171178471\n",
      "train loss:0.0450326105228\n",
      "train loss:0.0348100760693\n",
      "train loss:0.0258139797926\n",
      "train loss:0.0480723910552\n",
      "train loss:0.0467484113809\n",
      "train loss:0.0291204265242\n",
      "train loss:0.0531903307613\n",
      "train loss:0.0810449745464\n",
      "train loss:0.0186893612503\n",
      "train loss:0.00829911962627\n",
      "train loss:0.0243419767245\n",
      "train loss:0.050670238834\n",
      "train loss:0.0292799509506\n",
      "train loss:0.0998717369121\n",
      "train loss:0.030966313309\n",
      "train loss:0.0558173774867\n",
      "train loss:0.015787523517\n",
      "train loss:0.0520258256762\n",
      "train loss:0.0278134468217\n",
      "train loss:0.0155571244742\n",
      "train loss:0.0281177925686\n",
      "train loss:0.0846117167999\n",
      "train loss:0.0114297399471\n",
      "train loss:0.0225185006385\n",
      "train loss:0.0735633488195\n",
      "train loss:0.0555482866654\n",
      "train loss:0.0272503165874\n",
      "train loss:0.0612255653892\n",
      "train loss:0.0890915645432\n",
      "train loss:0.0262401824442\n",
      "train loss:0.0211172469817\n",
      "train loss:0.0488363606525\n",
      "train loss:0.0332595368016\n",
      "train loss:0.0916685820199\n",
      "train loss:0.0332346264412\n",
      "train loss:0.0462109941017\n",
      "train loss:0.0375676543448\n",
      "train loss:0.0373633857136\n",
      "train loss:0.0558819060645\n",
      "train loss:0.0330340136171\n",
      "train loss:0.0195360972449\n",
      "train loss:0.0398376889183\n",
      "train loss:0.0747696372979\n",
      "train loss:0.0280805002899\n",
      "train loss:0.0362297688223\n",
      "train loss:0.0407111967101\n",
      "train loss:0.015399467313\n",
      "train loss:0.0461371284885\n",
      "train loss:0.0261491972919\n",
      "train loss:0.0219765789165\n",
      "train loss:0.0162259495925\n",
      "train loss:0.0200533115344\n",
      "train loss:0.030143490578\n",
      "train loss:0.0967027879522\n",
      "train loss:0.0276380868353\n",
      "train loss:0.0938841136827\n",
      "train loss:0.109813515477\n",
      "train loss:0.0209697947875\n",
      "train loss:0.0448566603663\n",
      "train loss:0.0812451681545\n",
      "train loss:0.0442497803914\n",
      "train loss:0.172881852938\n",
      "train loss:0.0963082830503\n",
      "train loss:0.0407031085245\n",
      "train loss:0.0303651625299\n",
      "train loss:0.0418251089362\n",
      "train loss:0.0327271124772\n",
      "train loss:0.0561199750852\n",
      "train loss:0.0833994790413\n",
      "train loss:0.044630931335\n",
      "train loss:0.0166943431183\n",
      "train loss:0.0441626165487\n",
      "train loss:0.014167980408\n",
      "train loss:0.040175450345\n",
      "train loss:0.0446518413391\n",
      "train loss:0.0367130559009\n",
      "train loss:0.0301216958132\n",
      "train loss:0.0662145351106\n",
      "train loss:0.109777497286\n",
      "train loss:0.0669834508961\n",
      "train loss:0.0128808170121\n",
      "train loss:0.115009180466\n",
      "train loss:0.0400158869215\n",
      "train loss:0.0309126691402\n",
      "train loss:0.0651646001812\n",
      "train loss:0.0523294643535\n",
      "train loss:0.0190641839283\n",
      "train loss:0.0292889639019\n",
      "train loss:0.0199633240831\n",
      "train loss:0.0282292614986\n",
      "train loss:0.0848180749748\n",
      "train loss:0.166150478837\n",
      "train loss:0.0977177073981\n",
      "train loss:0.0383769075381\n",
      "train loss:0.0481766778004\n",
      "train loss:0.0387745443286\n",
      "train loss:0.0657529805031\n",
      "train loss:0.0317562550977\n",
      "train loss:0.0796525017729\n",
      "train loss:0.142045725063\n",
      "train loss:0.0431511487013\n",
      "train loss:0.0615231109089\n",
      "train loss:0.0661513271098\n",
      "train loss:0.0122149537929\n",
      "train loss:0.0233383666721\n",
      "train loss:0.0272327442469\n",
      "train loss:0.0204793687166\n",
      "train loss:0.0245800185629\n",
      "train loss:0.0246997443899\n",
      "train loss:0.0217861318469\n",
      "train loss:0.0668166558174\n",
      "train loss:0.0271980707892\n",
      "train loss:0.0261480150641\n",
      "train loss:0.0894546110788\n",
      "train loss:0.0564479333311\n",
      "train loss:0.109764833368\n",
      "train loss:0.0143384205309\n",
      "train loss:0.019919363492\n",
      "train loss:0.017368458873\n",
      "train loss:0.00646401296667\n",
      "train loss:0.0410508738752\n",
      "train loss:0.0291099948562\n",
      "train loss:0.0309451451793\n",
      "train loss:0.0267311382463\n",
      "train loss:0.0114068408084\n",
      "train loss:0.0832534409961\n",
      "train loss:0.0433284686121\n",
      "train loss:0.0149980306109\n",
      "train loss:0.0203020679837\n",
      "train loss:0.0317966563929\n",
      "train loss:0.057003678066\n",
      "train loss:0.0153641137532\n",
      "train loss:0.0609472654145\n",
      "train loss:0.0757899055016\n",
      "train loss:0.027608318657\n",
      "train loss:0.0384738541117\n",
      "train loss:0.0778153581333\n",
      "train loss:0.062459074805\n",
      "train loss:0.021005166577\n",
      "train loss:0.0655604441636\n",
      "train loss:0.0204150258721\n",
      "train loss:0.0424588471548\n",
      "train loss:0.0371068932726\n",
      "train loss:0.020877652185\n",
      "train loss:0.0237953232375\n",
      "train loss:0.0137705743524\n",
      "train loss:0.029616984369\n",
      "train loss:0.0381572856965\n",
      "train loss:0.0283417179757\n",
      "train loss:0.00753376634462\n",
      "train loss:0.0852351964139\n",
      "train loss:0.0772684617262\n",
      "train loss:0.129404448015\n",
      "train loss:0.0331275007489\n",
      "train loss:0.011622488597\n",
      "train loss:0.0298385949296\n",
      "train loss:0.0410183980986\n",
      "train loss:0.0270339934269\n",
      "train loss:0.0319649654326\n",
      "train loss:0.0340512248432\n",
      "train loss:0.0858701834026\n",
      "train loss:0.0300590501657\n",
      "train loss:0.0762030786352\n",
      "train loss:0.0152817520177\n",
      "train loss:0.0347595352169\n",
      "train loss:0.031237731214\n",
      "train loss:0.0420300721683\n",
      "train loss:0.0460248247743\n",
      "train loss:0.0549389042205\n",
      "train loss:0.0874367902395\n",
      "train loss:0.0429917149134\n",
      "train loss:0.0120553114524\n",
      "train loss:0.0847172106353\n",
      "train loss:0.0369714777501\n",
      "train loss:0.0313239626573\n",
      "train loss:0.0453205612445\n",
      "train loss:0.091836493934\n",
      "train loss:0.0118917456139\n",
      "train loss:0.0119965790193\n",
      "train loss:0.0276327882913\n",
      "train loss:0.0226097195222\n",
      "train loss:0.0609167727407\n",
      "train loss:0.0121977205795\n",
      "train loss:0.0184303042963\n",
      "train loss:0.0289274853799\n",
      "train loss:0.0562881494219\n",
      "train loss:0.0684811881295\n",
      "train loss:0.0575881664666\n",
      "train loss:0.0306669503509\n",
      "train loss:0.0258226337405\n",
      "train loss:0.0294202620391\n",
      "train loss:0.0519236851041\n",
      "train loss:0.0324535619676\n",
      "train loss:0.0879829841298\n",
      "train loss:0.0100449351785\n",
      "train loss:0.0151688772581\n",
      "train loss:0.0487845401194\n",
      "train loss:0.0129232974076\n",
      "train loss:0.0596210359133\n",
      "train loss:0.0242877304134\n",
      "train loss:0.0184452491241\n",
      "=== epoch:4, train acc:0.981, test acc:0.981 ===\n",
      "train loss:0.111344944291\n",
      "train loss:0.0782618116161\n",
      "train loss:0.0146391476726\n",
      "train loss:0.03656610194\n",
      "train loss:0.0648727355064\n",
      "train loss:0.0385165956642\n",
      "train loss:0.0492154456599\n",
      "train loss:0.0119623527347\n",
      "train loss:0.036210211656\n",
      "train loss:0.100438546193\n",
      "train loss:0.0205574780458\n",
      "train loss:0.0779188682393\n",
      "train loss:0.0543422151284\n",
      "train loss:0.0429968078606\n",
      "train loss:0.0449524678933\n",
      "train loss:0.0515622342072\n",
      "train loss:0.0936472837551\n",
      "train loss:0.025507178811\n",
      "train loss:0.0214562721902\n",
      "train loss:0.0107903777522\n",
      "train loss:0.0130477337351\n",
      "train loss:0.10661086811\n",
      "train loss:0.0362475847425\n",
      "train loss:0.0183840570756\n",
      "train loss:0.0253423754197\n",
      "train loss:0.0584320274412\n",
      "train loss:0.029091887345\n",
      "train loss:0.0266403821094\n",
      "train loss:0.0529167424836\n",
      "train loss:0.0956868963508\n",
      "train loss:0.0367152425777\n",
      "train loss:0.0208159964882\n",
      "train loss:0.0148202966307\n",
      "train loss:0.0739732265573\n",
      "train loss:0.0499206600831\n",
      "train loss:0.0570992312689\n",
      "train loss:0.025757610631\n",
      "train loss:0.0987106374343\n",
      "train loss:0.0509151248376\n",
      "train loss:0.0304824108346\n",
      "train loss:0.0582391701641\n",
      "train loss:0.020751001212\n",
      "train loss:0.0243706659597\n",
      "train loss:0.0244448648584\n",
      "train loss:0.0390805541962\n",
      "train loss:0.0723523589239\n",
      "train loss:0.0935365342021\n",
      "train loss:0.00673422073653\n",
      "train loss:0.023643684316\n",
      "train loss:0.0390971680316\n",
      "train loss:0.0408056050589\n",
      "train loss:0.0544373523878\n",
      "train loss:0.0361203168169\n",
      "train loss:0.0194610859493\n",
      "train loss:0.0724366443365\n",
      "train loss:0.0318901120773\n",
      "train loss:0.0904859169091\n",
      "train loss:0.0247478174294\n",
      "train loss:0.0234966129259\n",
      "train loss:0.0486448940497\n",
      "train loss:0.0661199419016\n",
      "train loss:0.0341616124296\n",
      "train loss:0.025049237972\n",
      "train loss:0.00726141319761\n",
      "train loss:0.0486603701831\n",
      "train loss:0.0421721494097\n",
      "train loss:0.0467496721872\n",
      "train loss:0.0262173694\n",
      "train loss:0.074299129769\n",
      "train loss:0.0429903237946\n",
      "train loss:0.0568962677857\n",
      "train loss:0.0341981238682\n",
      "train loss:0.0234621556546\n",
      "train loss:0.0581324723281\n",
      "train loss:0.0151321979716\n",
      "train loss:0.0737870237005\n",
      "train loss:0.0318045072314\n",
      "train loss:0.0395169580555\n",
      "train loss:0.0285962301283\n",
      "train loss:0.0407417802213\n",
      "train loss:0.0282468203441\n",
      "train loss:0.0325496194417\n",
      "train loss:0.0154118187381\n",
      "train loss:0.010062964323\n",
      "train loss:0.0113832342765\n",
      "train loss:0.046349344605\n",
      "train loss:0.0529332393665\n",
      "train loss:0.038802498877\n",
      "train loss:0.0276832636864\n",
      "train loss:0.0276346598444\n",
      "train loss:0.0467880603741\n",
      "train loss:0.0161332963705\n",
      "train loss:0.0466098707574\n",
      "train loss:0.0481572804764\n",
      "train loss:0.0179334381466\n",
      "train loss:0.025512582399\n",
      "train loss:0.0524042695949\n",
      "train loss:0.0133885142989\n",
      "train loss:0.0248290831394\n",
      "train loss:0.0894820688641\n",
      "train loss:0.0490884991273\n",
      "train loss:0.0804234745012\n",
      "train loss:0.0191466647699\n",
      "train loss:0.0274494671158\n",
      "train loss:0.0253116832329\n",
      "train loss:0.0145074490138\n",
      "train loss:0.0222797392583\n",
      "train loss:0.0768239769809\n",
      "train loss:0.0460832131147\n",
      "train loss:0.043060392349\n",
      "train loss:0.0123631745562\n",
      "train loss:0.0245141390915\n",
      "train loss:0.00960896855243\n",
      "train loss:0.045680511255\n",
      "train loss:0.0444638339793\n",
      "train loss:0.092214184622\n",
      "train loss:0.0181996800762\n",
      "train loss:0.0146426694275\n",
      "train loss:0.023930567215\n",
      "train loss:0.0656868855209\n",
      "train loss:0.013473571131\n",
      "train loss:0.0080205621269\n",
      "train loss:0.0378016691325\n",
      "train loss:0.0228702115773\n",
      "train loss:0.0298452018031\n",
      "train loss:0.0360637854488\n",
      "train loss:0.0294506158745\n",
      "train loss:0.0682103670538\n",
      "train loss:0.0158649062014\n",
      "train loss:0.115885354557\n",
      "train loss:0.046874130238\n",
      "train loss:0.0131666516474\n",
      "train loss:0.0335803087086\n",
      "train loss:0.044714764132\n",
      "train loss:0.0686159473096\n",
      "train loss:0.00388847187448\n",
      "train loss:0.0444061945819\n",
      "train loss:0.0680541752276\n",
      "train loss:0.0399746716054\n",
      "train loss:0.0468464934168\n",
      "train loss:0.0372747851082\n",
      "train loss:0.0643810726136\n",
      "train loss:0.0433386131937\n",
      "train loss:0.0135266169702\n",
      "train loss:0.0242187155822\n",
      "train loss:0.0201089861879\n",
      "train loss:0.0849091181023\n",
      "train loss:0.049215475935\n",
      "train loss:0.0172770921241\n",
      "train loss:0.0179917249035\n",
      "train loss:0.0753696068819\n",
      "train loss:0.0600918254076\n",
      "train loss:0.0337259929882\n",
      "train loss:0.0510685741537\n",
      "train loss:0.0105749187481\n",
      "train loss:0.0345136901319\n",
      "train loss:0.0807855245801\n",
      "train loss:0.0448974751431\n",
      "train loss:0.0109157111655\n",
      "train loss:0.0232221390677\n",
      "train loss:0.0298954966405\n",
      "train loss:0.0499054843077\n",
      "train loss:0.0426630269923\n",
      "train loss:0.0172833212624\n",
      "train loss:0.0421164748881\n",
      "train loss:0.0165454991483\n",
      "train loss:0.0542133804644\n",
      "train loss:0.0350416158323\n",
      "train loss:0.019633111872\n",
      "train loss:0.105031909709\n",
      "train loss:0.0697651966205\n",
      "train loss:0.0517058738694\n",
      "train loss:0.0888466194203\n",
      "train loss:0.0102130860939\n",
      "train loss:0.0198539016152\n",
      "train loss:0.0138307500853\n",
      "train loss:0.0790988500925\n",
      "train loss:0.015671361251\n",
      "train loss:0.0595100547354\n",
      "train loss:0.0189469396944\n",
      "train loss:0.0191316119994\n",
      "train loss:0.0197080494868\n",
      "train loss:0.0555905587098\n",
      "train loss:0.0138112417318\n",
      "train loss:0.0301426586199\n",
      "train loss:0.0502909605998\n",
      "train loss:0.0110087378694\n",
      "train loss:0.0857732230265\n",
      "train loss:0.00588999763149\n",
      "train loss:0.00808468326985\n",
      "train loss:0.00980174109019\n",
      "train loss:0.139552047782\n",
      "train loss:0.0124755874616\n",
      "train loss:0.0191617754268\n",
      "train loss:0.039143116254\n",
      "train loss:0.0270730920473\n",
      "train loss:0.0154161329343\n",
      "train loss:0.0492110298318\n",
      "train loss:0.0159353916695\n",
      "train loss:0.0321124334474\n",
      "train loss:0.144415392967\n",
      "train loss:0.0191137644927\n",
      "train loss:0.0253408192788\n",
      "train loss:0.0209667548079\n",
      "train loss:0.0290038790801\n",
      "train loss:0.0142212268895\n",
      "train loss:0.0203599849875\n",
      "train loss:0.00698522209226\n",
      "train loss:0.0542942376164\n",
      "train loss:0.061631148942\n",
      "train loss:0.133505070025\n",
      "train loss:0.0623641182318\n",
      "train loss:0.0138296474949\n",
      "train loss:0.0926950498867\n",
      "train loss:0.100356404819\n",
      "train loss:0.0575301683028\n",
      "train loss:0.015117271037\n",
      "train loss:0.0192836664642\n",
      "train loss:0.0322558434271\n",
      "train loss:0.0285982066727\n",
      "train loss:0.0205594010904\n",
      "train loss:0.0728897732133\n",
      "train loss:0.0242060962354\n",
      "train loss:0.0675481869987\n",
      "train loss:0.0819236446655\n",
      "train loss:0.0513907279225\n",
      "train loss:0.0556310290632\n",
      "train loss:0.026972426452\n",
      "train loss:0.0382671274839\n",
      "train loss:0.0502601584368\n",
      "train loss:0.0809377691056\n",
      "train loss:0.0273380581708\n",
      "train loss:0.0929855391003\n",
      "train loss:0.0638485121854\n",
      "train loss:0.0605621972584\n",
      "train loss:0.0661408048832\n",
      "train loss:0.0273170702685\n",
      "train loss:0.042564287229\n",
      "train loss:0.021378895836\n",
      "train loss:0.013723059603\n",
      "train loss:0.033088217606\n",
      "train loss:0.0118337674292\n",
      "train loss:0.0918101943212\n",
      "train loss:0.0891283398726\n",
      "train loss:0.0486825383611\n",
      "train loss:0.0439014720963\n",
      "train loss:0.0308871795554\n",
      "train loss:0.0108070199117\n",
      "train loss:0.0162938568217\n",
      "train loss:0.0226936057477\n",
      "train loss:0.105311829821\n",
      "train loss:0.0269959010676\n",
      "train loss:0.00966561873816\n",
      "train loss:0.0394632628541\n",
      "train loss:0.0228974830317\n",
      "train loss:0.0414810733124\n",
      "train loss:0.00505212402073\n",
      "train loss:0.0169884374372\n",
      "train loss:0.0593471261493\n",
      "train loss:0.0130192277275\n",
      "train loss:0.0175194237884\n",
      "train loss:0.0360180821541\n",
      "train loss:0.051487616062\n",
      "train loss:0.0675945245236\n",
      "train loss:0.0317222746526\n",
      "train loss:0.00695887399739\n",
      "train loss:0.0660485287591\n",
      "train loss:0.0526326979847\n",
      "train loss:0.0567182925917\n",
      "train loss:0.0241383120795\n",
      "train loss:0.058022065285\n",
      "train loss:0.0207655185774\n",
      "train loss:0.0132051753509\n",
      "train loss:0.0318578214585\n",
      "train loss:0.0109892486807\n",
      "train loss:0.023058339337\n",
      "train loss:0.0349661342858\n",
      "train loss:0.0805157505583\n",
      "train loss:0.0390754904543\n",
      "train loss:0.00949117853147\n",
      "train loss:0.0144655876558\n",
      "train loss:0.0438946521026\n",
      "train loss:0.0133875668614\n",
      "train loss:0.102850902695\n",
      "train loss:0.0170000227971\n",
      "train loss:0.048615717272\n",
      "train loss:0.0190427010456\n",
      "train loss:0.0303097393631\n",
      "train loss:0.0204797567747\n",
      "train loss:0.0480904656384\n",
      "train loss:0.017112025144\n",
      "train loss:0.00538398976234\n",
      "train loss:0.0177634019169\n",
      "train loss:0.0682932612227\n",
      "train loss:0.0709343067273\n",
      "train loss:0.0324142356075\n",
      "train loss:0.0411778069159\n",
      "train loss:0.0393246839986\n",
      "train loss:0.0610497208109\n",
      "train loss:0.025022031099\n",
      "train loss:0.0398149004547\n",
      "train loss:0.0382602903856\n",
      "train loss:0.0827577787886\n",
      "train loss:0.0776823914166\n",
      "train loss:0.0617116149188\n",
      "train loss:0.0739013673903\n",
      "train loss:0.0175315385281\n",
      "train loss:0.0507685180975\n",
      "train loss:0.189292296712\n",
      "train loss:0.020104225352\n",
      "train loss:0.069511780797\n",
      "train loss:0.0561716258008\n",
      "train loss:0.0969706407775\n",
      "train loss:0.0717880362213\n",
      "train loss:0.0358055523816\n",
      "train loss:0.0166887809156\n",
      "train loss:0.0872250412844\n",
      "train loss:0.0164609876039\n",
      "train loss:0.0419277285616\n",
      "train loss:0.022585289457\n",
      "train loss:0.0373747765051\n",
      "train loss:0.0115220997671\n",
      "train loss:0.0696976914942\n",
      "train loss:0.104188031809\n",
      "train loss:0.0371949738957\n",
      "train loss:0.0205147449209\n",
      "train loss:0.00713821572658\n",
      "train loss:0.0593743456092\n",
      "train loss:0.0408145444386\n",
      "train loss:0.0598404783458\n",
      "train loss:0.0576548705831\n",
      "train loss:0.0173320317059\n",
      "train loss:0.0390270403363\n",
      "train loss:0.0271593039434\n",
      "train loss:0.0102673894557\n",
      "train loss:0.0482944992949\n",
      "train loss:0.0190625206988\n",
      "train loss:0.0270325667921\n",
      "train loss:0.00587083381331\n",
      "train loss:0.0349297009631\n",
      "train loss:0.08058423105\n",
      "train loss:0.037840993208\n",
      "train loss:0.0260125123284\n",
      "train loss:0.0448930622632\n",
      "train loss:0.0117558704407\n",
      "train loss:0.0370836869261\n",
      "train loss:0.0261627462928\n",
      "train loss:0.0506573484462\n",
      "train loss:0.0458861469297\n",
      "train loss:0.0199463907432\n",
      "train loss:0.0284155455459\n",
      "train loss:0.122186318378\n",
      "train loss:0.0247169291128\n",
      "train loss:0.0355736766251\n",
      "train loss:0.0660376881834\n",
      "train loss:0.0242118754362\n",
      "train loss:0.0289660606432\n",
      "train loss:0.00915752981613\n",
      "train loss:0.0422546320565\n",
      "train loss:0.0226371913332\n",
      "train loss:0.0442469920725\n",
      "train loss:0.0551859336665\n",
      "train loss:0.0389399300101\n",
      "train loss:0.0275245234339\n",
      "train loss:0.044728829192\n",
      "train loss:0.0680052273977\n",
      "train loss:0.0984161312769\n",
      "train loss:0.00633003087984\n",
      "train loss:0.0118259484015\n",
      "train loss:0.0681162548377\n",
      "train loss:0.0134735764155\n",
      "train loss:0.0256053897043\n",
      "train loss:0.0176201557046\n",
      "train loss:0.0267497922597\n",
      "train loss:0.0475790810945\n",
      "train loss:0.0254786625949\n",
      "train loss:0.00997030228315\n",
      "train loss:0.0416369368757\n",
      "train loss:0.0363997838182\n",
      "train loss:0.0218473313622\n",
      "train loss:0.00972143521927\n",
      "train loss:0.0281621602568\n",
      "train loss:0.0415410038059\n",
      "train loss:0.0901301498067\n",
      "train loss:0.0355338719203\n",
      "train loss:0.167986605564\n",
      "train loss:0.0296527797472\n",
      "train loss:0.0182521148511\n",
      "train loss:0.00460043714823\n",
      "train loss:0.0183960846462\n",
      "train loss:0.053502249934\n",
      "train loss:0.00910683891454\n",
      "train loss:0.0182263445935\n",
      "train loss:0.00635498777828\n",
      "train loss:0.0210716695042\n",
      "train loss:0.0259950067877\n",
      "train loss:0.0115178393031\n",
      "train loss:0.021319975725\n",
      "train loss:0.0854835702939\n",
      "train loss:0.0669927121565\n",
      "train loss:0.0414010619836\n",
      "train loss:0.00802112748125\n",
      "train loss:0.0570633929446\n",
      "train loss:0.00899670229346\n",
      "train loss:0.0783660651174\n",
      "train loss:0.0316194639124\n",
      "train loss:0.0291638390941\n",
      "train loss:0.0282273862865\n",
      "train loss:0.0312576701669\n",
      "train loss:0.027498753319\n",
      "train loss:0.0179588490799\n",
      "train loss:0.0677787252855\n",
      "train loss:0.0123699718552\n",
      "train loss:0.0298409251192\n",
      "train loss:0.0273446895881\n",
      "train loss:0.118473122387\n",
      "train loss:0.0180061325969\n",
      "train loss:0.0775037692855\n",
      "train loss:0.0881554222578\n",
      "train loss:0.0792738365695\n",
      "train loss:0.026068872728\n",
      "train loss:0.049585348864\n",
      "train loss:0.0427921691926\n",
      "train loss:0.0207733216969\n",
      "train loss:0.0186020617743\n",
      "train loss:0.00902479487025\n",
      "train loss:0.0353722867898\n",
      "train loss:0.00576182951503\n",
      "train loss:0.0260950010481\n",
      "train loss:0.025814733129\n",
      "train loss:0.0124645280804\n",
      "train loss:0.0327515984595\n",
      "train loss:0.0373815018222\n",
      "train loss:0.0635776457285\n",
      "train loss:0.0260499454581\n",
      "train loss:0.0660732934042\n",
      "train loss:0.0482950479944\n",
      "train loss:0.069834291054\n",
      "train loss:0.0489059290132\n",
      "train loss:0.0513162670814\n",
      "train loss:0.0433046479598\n",
      "train loss:0.00987472894913\n",
      "train loss:0.017958886374\n",
      "train loss:0.0328476415293\n",
      "train loss:0.0716366088054\n",
      "train loss:0.0382459942754\n",
      "train loss:0.0117857672697\n",
      "train loss:0.0139331765431\n",
      "train loss:0.0393425750568\n",
      "train loss:0.0134016695184\n",
      "train loss:0.0237369387991\n",
      "train loss:0.0123254323641\n",
      "train loss:0.0197507429162\n",
      "train loss:0.00901422062304\n",
      "train loss:0.0198832917483\n",
      "train loss:0.0299345712732\n",
      "train loss:0.0190246605505\n",
      "train loss:0.0033607800946\n",
      "train loss:0.0121585698942\n",
      "train loss:0.0202860568281\n",
      "train loss:0.0178568633034\n",
      "train loss:0.0970522739072\n",
      "train loss:0.0460688915263\n",
      "train loss:0.0241539928725\n",
      "train loss:0.0292418338428\n",
      "train loss:0.0237950712361\n",
      "train loss:0.00877434760889\n",
      "train loss:0.0257930190912\n",
      "train loss:0.0204254629397\n",
      "train loss:0.0133881695603\n",
      "train loss:0.0120642279962\n",
      "train loss:0.0173681115167\n",
      "train loss:0.0174246708589\n",
      "train loss:0.0169677856106\n",
      "train loss:0.0457273370941\n",
      "train loss:0.0395698042865\n",
      "train loss:0.00688617248023\n",
      "train loss:0.0278557074349\n",
      "train loss:0.013082816199\n",
      "train loss:0.00904210590527\n",
      "train loss:0.0258134565793\n",
      "train loss:0.0470900238101\n",
      "train loss:0.0218747010796\n",
      "train loss:0.0621420000978\n",
      "train loss:0.0192959281586\n",
      "train loss:0.017202952346\n",
      "train loss:0.0232728898626\n",
      "train loss:0.0118557907984\n",
      "train loss:0.00470032981091\n",
      "train loss:0.0153703949291\n",
      "train loss:0.0506242917914\n",
      "train loss:0.0552180837985\n",
      "train loss:0.102512226406\n",
      "train loss:0.0372136715913\n",
      "train loss:0.00940250810836\n",
      "train loss:0.117543819715\n",
      "train loss:0.0320182957706\n",
      "train loss:0.0874167168044\n",
      "train loss:0.0207733830255\n",
      "train loss:0.0794874399392\n",
      "train loss:0.0369695859678\n",
      "train loss:0.00731700738139\n",
      "train loss:0.0139569181166\n",
      "train loss:0.0419117869385\n",
      "train loss:0.0386095783277\n",
      "train loss:0.00947789368633\n",
      "train loss:0.0426055363123\n",
      "train loss:0.00990088826365\n",
      "train loss:0.051685932436\n",
      "train loss:0.0519664526597\n",
      "train loss:0.00880666576432\n",
      "train loss:0.0149173719662\n",
      "train loss:0.011847656684\n",
      "train loss:0.0461876541933\n",
      "train loss:0.0861625767158\n",
      "train loss:0.0446385342534\n",
      "train loss:0.0228689956828\n",
      "train loss:0.015716185893\n",
      "train loss:0.0437219916559\n",
      "train loss:0.0406025658152\n",
      "train loss:0.021753775791\n",
      "train loss:0.0314051091809\n",
      "train loss:0.0066400924443\n",
      "train loss:0.0338977630536\n",
      "train loss:0.0345806417005\n",
      "train loss:0.0214405084923\n",
      "train loss:0.0158946210938\n",
      "train loss:0.0159253523004\n",
      "train loss:0.0396159460216\n",
      "train loss:0.0470724194765\n",
      "train loss:0.104326345583\n",
      "train loss:0.0387576281375\n",
      "train loss:0.0175103005191\n",
      "train loss:0.0128563754594\n",
      "train loss:0.0200745793916\n",
      "train loss:0.0225144094841\n",
      "train loss:0.0512830136998\n",
      "train loss:0.0720101850441\n",
      "train loss:0.034951113487\n",
      "train loss:0.102128051014\n",
      "train loss:0.0125182125945\n",
      "train loss:0.0212114695466\n",
      "train loss:0.00799797010668\n",
      "train loss:0.0306595699268\n",
      "train loss:0.0435364734327\n",
      "train loss:0.0379208026053\n",
      "train loss:0.0194452511526\n",
      "train loss:0.0683127258169\n",
      "train loss:0.0453569550468\n",
      "train loss:0.00732919049716\n",
      "train loss:0.0240221248922\n",
      "train loss:0.0347846848856\n",
      "train loss:0.0074426033622\n",
      "train loss:0.0482960262607\n",
      "train loss:0.00713507431947\n",
      "train loss:0.00497058122111\n",
      "train loss:0.0095206440217\n",
      "train loss:0.0382849703815\n",
      "train loss:0.0222096987404\n",
      "train loss:0.0329560094865\n",
      "train loss:0.0141273897959\n",
      "train loss:0.0475666645963\n",
      "train loss:0.0134718079389\n",
      "train loss:0.0369828389442\n",
      "train loss:0.0162137356112\n",
      "train loss:0.039964360906\n",
      "train loss:0.00980195453328\n",
      "train loss:0.0235661256936\n",
      "train loss:0.0512982549434\n",
      "train loss:0.00807262884807\n",
      "train loss:0.0368427787444\n",
      "train loss:0.0137320123271\n",
      "train loss:0.017501675555\n",
      "train loss:0.0585074457751\n",
      "train loss:0.0419670587468\n",
      "train loss:0.0124537533011\n",
      "train loss:0.0376599823331\n",
      "train loss:0.0205890690853\n",
      "train loss:0.0111462875288\n",
      "train loss:0.0101183846953\n",
      "train loss:0.0538887565206\n",
      "train loss:0.0165946512893\n",
      "train loss:0.0106814790981\n",
      "train loss:0.0517553012738\n",
      "train loss:0.0204316965058\n",
      "train loss:0.055986640775\n",
      "train loss:0.01774973443\n",
      "train loss:0.0157068401134\n",
      "train loss:0.0107363125621\n",
      "train loss:0.010578958869\n",
      "train loss:0.0103844888207\n",
      "train loss:0.0293273896341\n",
      "train loss:0.0231695712768\n",
      "train loss:0.0119788379588\n",
      "train loss:0.0996804427124\n",
      "train loss:0.00661463959225\n",
      "train loss:0.0606120611852\n",
      "train loss:0.0229212247309\n",
      "train loss:0.0451089826642\n",
      "train loss:0.0235266344699\n",
      "=== epoch:5, train acc:0.983, test acc:0.98 ===\n",
      "train loss:0.0155505962648\n",
      "train loss:0.0340615487127\n",
      "train loss:0.0218484603143\n",
      "train loss:0.0422894840907\n",
      "train loss:0.0128408732058\n",
      "train loss:0.00488773866952\n",
      "train loss:0.0376551982831\n",
      "train loss:0.0541088995529\n",
      "train loss:0.0320556558727\n",
      "train loss:0.0133893956415\n",
      "train loss:0.00850042400833\n",
      "train loss:0.011285695728\n",
      "train loss:0.0380864335796\n",
      "train loss:0.0192972159837\n",
      "train loss:0.0613760870392\n",
      "train loss:0.0167699436506\n",
      "train loss:0.0336593755336\n",
      "train loss:0.023541336506\n",
      "train loss:0.0996761122391\n",
      "train loss:0.0530431774383\n",
      "train loss:0.100442923818\n",
      "train loss:0.0080880039929\n",
      "train loss:0.0413172372918\n",
      "train loss:0.0144528274252\n",
      "train loss:0.0217915108206\n",
      "train loss:0.0689823878731\n",
      "train loss:0.0485602245794\n",
      "train loss:0.0322503603857\n",
      "train loss:0.0290954957987\n",
      "train loss:0.0223172332323\n",
      "train loss:0.0296403678231\n",
      "train loss:0.00908504203449\n",
      "train loss:0.0319240737489\n",
      "train loss:0.0285969837535\n",
      "train loss:0.12624599483\n",
      "train loss:0.0428403888705\n",
      "train loss:0.0138266147616\n",
      "train loss:0.0290908135904\n",
      "train loss:0.0234201580385\n",
      "train loss:0.00629378475952\n",
      "train loss:0.010610963901\n",
      "train loss:0.0227533095552\n",
      "train loss:0.0281589599946\n",
      "train loss:0.0137184112732\n",
      "train loss:0.11547194488\n",
      "train loss:0.00489887001509\n",
      "train loss:0.0941806740718\n",
      "train loss:0.0256685814629\n",
      "train loss:0.0167995497197\n",
      "train loss:0.0220041026308\n",
      "train loss:0.0110634196714\n",
      "train loss:0.00811803274215\n",
      "train loss:0.0378842409397\n",
      "train loss:0.0374250688787\n",
      "train loss:0.0187366360767\n",
      "train loss:0.0348750449966\n",
      "train loss:0.0295576308445\n",
      "train loss:0.0183056196156\n",
      "train loss:0.0251142088231\n",
      "train loss:0.0801184651772\n",
      "train loss:0.014640954459\n",
      "train loss:0.0346042661767\n",
      "train loss:0.0849060069846\n",
      "train loss:0.02855447778\n",
      "train loss:0.0216120551002\n",
      "train loss:0.0379859060666\n",
      "train loss:0.0163408621881\n",
      "train loss:0.0375065995483\n",
      "train loss:0.00622975355583\n",
      "train loss:0.0373876002687\n",
      "train loss:0.0278529771675\n",
      "train loss:0.0505527624566\n",
      "train loss:0.0901116501546\n",
      "train loss:0.0265756197941\n",
      "train loss:0.129183920446\n",
      "train loss:0.0053876466119\n",
      "train loss:0.0403367357077\n",
      "train loss:0.0133744800002\n",
      "train loss:0.0696720509805\n",
      "train loss:0.0131299730901\n",
      "train loss:0.0208275414543\n",
      "train loss:0.0458505849987\n",
      "train loss:0.0212933508167\n",
      "train loss:0.070755424969\n",
      "train loss:0.0618682647827\n",
      "train loss:0.0591482992837\n",
      "train loss:0.00337813532852\n",
      "train loss:0.0214057680998\n",
      "train loss:0.053946698155\n",
      "train loss:0.0358520424164\n",
      "train loss:0.0277703959153\n",
      "train loss:0.0468106809834\n",
      "train loss:0.0319118901352\n",
      "train loss:0.0187629201547\n",
      "train loss:0.0799308191516\n",
      "train loss:0.00804011216698\n",
      "train loss:0.0979639282213\n",
      "train loss:0.0474473741179\n",
      "train loss:0.0253480687262\n",
      "train loss:0.0928648949357\n",
      "train loss:0.0627074161046\n",
      "train loss:0.0463909450578\n",
      "train loss:0.09052694923\n",
      "train loss:0.0408370753776\n",
      "train loss:0.0482389581449\n",
      "train loss:0.0250345937771\n",
      "train loss:0.0203867964579\n",
      "train loss:0.01998746561\n",
      "train loss:0.0103008447887\n",
      "train loss:0.02409355012\n",
      "train loss:0.00556154858231\n",
      "train loss:0.03857271672\n",
      "train loss:0.0334433943605\n",
      "train loss:0.0196857127313\n",
      "train loss:0.0424597786797\n",
      "train loss:0.0331387933738\n",
      "train loss:0.0249242996132\n",
      "train loss:0.00789931392982\n",
      "train loss:0.0199020837617\n",
      "train loss:0.0397011901571\n",
      "train loss:0.0362318357949\n",
      "train loss:0.01795728991\n",
      "train loss:0.0215963786364\n",
      "train loss:0.0618859819731\n",
      "train loss:0.00865750204471\n",
      "train loss:0.0296620451252\n",
      "train loss:0.0242608673514\n",
      "train loss:0.0626198229937\n",
      "train loss:0.00603739320881\n",
      "train loss:0.0357744783078\n",
      "train loss:0.0195608997258\n",
      "train loss:0.00588633901199\n",
      "train loss:0.0574557746186\n",
      "train loss:0.00812716347185\n",
      "train loss:0.0563543790307\n",
      "train loss:0.0508924497899\n",
      "train loss:0.0143069698879\n",
      "train loss:0.026217151719\n",
      "train loss:0.0168821908348\n",
      "train loss:0.0191567497901\n",
      "train loss:0.034357413579\n",
      "train loss:0.0293680979088\n",
      "train loss:0.0153253363342\n",
      "train loss:0.031535265818\n",
      "train loss:0.0209491966635\n",
      "train loss:0.0762203389412\n",
      "train loss:0.0243815587352\n",
      "train loss:0.0233341710918\n",
      "train loss:0.0432365508461\n",
      "train loss:0.0286460655313\n",
      "train loss:0.0325405919375\n",
      "train loss:0.0257406315018\n",
      "train loss:0.167833980383\n",
      "train loss:0.0439360766731\n",
      "train loss:0.00440683016207\n",
      "train loss:0.0719600481782\n",
      "train loss:0.00233657851573\n",
      "train loss:0.0796355527631\n",
      "train loss:0.0431075265365\n",
      "train loss:0.0235080747891\n",
      "train loss:0.0265125304588\n",
      "train loss:0.023583975205\n",
      "train loss:0.263814402967\n",
      "train loss:0.0130882901267\n",
      "train loss:0.0152605867589\n",
      "train loss:0.0914201243783\n",
      "train loss:0.0178597865617\n",
      "train loss:0.035507196381\n",
      "train loss:0.115851373628\n",
      "train loss:0.0354854331167\n",
      "train loss:0.0191159303266\n",
      "train loss:0.0100624486877\n",
      "train loss:0.0263126122139\n",
      "train loss:0.0176687516913\n",
      "train loss:0.0562974855027\n",
      "train loss:0.0476124209163\n",
      "train loss:0.0322132907933\n",
      "train loss:0.00949393528213\n",
      "train loss:0.0234302771602\n",
      "train loss:0.0636545871656\n",
      "train loss:0.013885717252\n",
      "train loss:0.0342764257679\n",
      "train loss:0.0205313541283\n",
      "train loss:0.0490880292301\n",
      "train loss:0.00796346497974\n",
      "train loss:0.0051979744151\n",
      "train loss:0.0342304113458\n",
      "train loss:0.0524368370294\n",
      "train loss:0.0200603331762\n",
      "train loss:0.0100806733642\n",
      "train loss:0.0661708415396\n",
      "train loss:0.0312328311503\n",
      "train loss:0.0330439044668\n",
      "train loss:0.0298691043564\n",
      "train loss:0.0955649433683\n",
      "train loss:0.0701177370694\n",
      "train loss:0.00776595300714\n",
      "train loss:0.0466075551886\n",
      "train loss:0.0393669608218\n",
      "train loss:0.0717633919546\n",
      "train loss:0.0102725559541\n",
      "train loss:0.0247529119141\n",
      "train loss:0.064830765161\n",
      "train loss:0.0384900340708\n",
      "train loss:0.0149492680614\n",
      "train loss:0.0146046670205\n",
      "train loss:0.0414778128484\n",
      "train loss:0.0353619172848\n",
      "train loss:0.00946119702143\n",
      "train loss:0.0329001282471\n",
      "train loss:0.0199410266636\n",
      "train loss:0.0358830601603\n",
      "train loss:0.0476482414675\n",
      "train loss:0.0217090911381\n",
      "train loss:0.0132037444226\n",
      "train loss:0.101022573761\n",
      "train loss:0.0153928539694\n",
      "train loss:0.0503485085728\n",
      "train loss:0.010665414627\n",
      "train loss:0.00639582811661\n",
      "train loss:0.0484573763107\n",
      "train loss:0.020057699023\n",
      "train loss:0.0118255122575\n",
      "train loss:0.0416222490681\n",
      "train loss:0.0454923588747\n",
      "train loss:0.0148873171724\n",
      "train loss:0.0179942627805\n",
      "train loss:0.0106479612029\n",
      "train loss:0.0420848123017\n",
      "train loss:0.0504393880429\n",
      "train loss:0.0365468472233\n",
      "train loss:0.0234163402132\n",
      "train loss:0.0125280445364\n",
      "train loss:0.0348225528995\n",
      "train loss:0.013567831444\n",
      "train loss:0.0389164959777\n",
      "train loss:0.0606004451679\n",
      "train loss:0.0643627519808\n",
      "train loss:0.00861123251512\n",
      "train loss:0.0149949951207\n",
      "train loss:0.0294637977444\n",
      "train loss:0.0915549343283\n",
      "train loss:0.0338917829457\n",
      "train loss:0.0111170745361\n",
      "train loss:0.010336376687\n",
      "train loss:0.0276703860184\n",
      "train loss:0.0447465619722\n",
      "train loss:0.011237440465\n",
      "train loss:0.0303288138045\n",
      "train loss:0.0198815769006\n",
      "train loss:0.0199858599306\n",
      "train loss:0.0189517843534\n",
      "train loss:0.00932458331685\n",
      "train loss:0.010193549892\n",
      "train loss:0.0260842856685\n",
      "train loss:0.0171916752915\n",
      "train loss:0.018567558467\n",
      "train loss:0.077409523724\n",
      "train loss:0.0069317824918\n",
      "train loss:0.0397781615176\n",
      "train loss:0.0924966092618\n",
      "train loss:0.0194124434621\n",
      "train loss:0.00523140144465\n",
      "train loss:0.0138223739488\n",
      "train loss:0.0520624359358\n",
      "train loss:0.0448781546123\n",
      "train loss:0.00437714619262\n",
      "train loss:0.0201566761586\n",
      "train loss:0.0372302609818\n",
      "train loss:0.0252381636609\n",
      "train loss:0.0104466196325\n",
      "train loss:0.0224673673233\n",
      "train loss:0.00949719065402\n",
      "train loss:0.00721926834462\n",
      "train loss:0.012217523555\n",
      "train loss:0.0378675442164\n",
      "train loss:0.0184298453196\n",
      "train loss:0.0342927180433\n",
      "train loss:0.0274782964665\n",
      "train loss:0.0133292202709\n",
      "train loss:0.00658896293591\n",
      "train loss:0.00645415220375\n",
      "train loss:0.00368708789\n",
      "train loss:0.0293551855945\n",
      "train loss:0.0105778685683\n",
      "train loss:0.021790233884\n",
      "train loss:0.0501419549313\n",
      "train loss:0.0271504592296\n",
      "train loss:0.0137694305901\n",
      "train loss:0.0114873463899\n",
      "train loss:0.0101948666477\n",
      "train loss:0.0185371802573\n",
      "train loss:0.035268511559\n",
      "train loss:0.0709283559871\n",
      "train loss:0.0468599388312\n",
      "train loss:0.0643091916469\n",
      "train loss:0.0416030609018\n",
      "train loss:0.0601657533173\n",
      "train loss:0.0494922768336\n",
      "train loss:0.0148562014583\n",
      "train loss:0.0260511764546\n",
      "train loss:0.0135080538072\n",
      "train loss:0.0196159027497\n",
      "train loss:0.0346618339228\n",
      "train loss:0.0151063511445\n",
      "train loss:0.0171803269461\n",
      "train loss:0.0150879613641\n",
      "train loss:0.0230151328461\n",
      "train loss:0.0482950629906\n",
      "train loss:0.0106688200201\n",
      "train loss:0.0275055421253\n",
      "train loss:0.0283746682244\n",
      "train loss:0.0165384380658\n",
      "train loss:0.0540064159169\n",
      "train loss:0.00572929492422\n",
      "train loss:0.0551908218547\n",
      "train loss:0.0281307815067\n",
      "train loss:0.00795007223076\n",
      "train loss:0.00428163005493\n",
      "train loss:0.0277026900422\n",
      "train loss:0.0195089242572\n",
      "train loss:0.011830980937\n",
      "train loss:0.017114452252\n",
      "train loss:0.0430351916229\n",
      "train loss:0.0186235656952\n",
      "train loss:0.0207181304801\n",
      "train loss:0.0053934675358\n",
      "train loss:0.021070618511\n",
      "train loss:0.0154228089229\n",
      "train loss:0.00742974321044\n",
      "train loss:0.0213759977233\n",
      "train loss:0.0261457317493\n",
      "train loss:0.0317203304865\n",
      "train loss:0.0650593796549\n",
      "train loss:0.0250020529712\n",
      "train loss:0.0295604601559\n",
      "train loss:0.140737285857\n",
      "train loss:0.0493530815225\n",
      "train loss:0.0159507165276\n",
      "train loss:0.00962469786238\n",
      "train loss:0.00901344247489\n",
      "train loss:0.0305617845378\n",
      "train loss:0.0206341402309\n",
      "train loss:0.0123747349745\n",
      "train loss:0.0153511818053\n",
      "train loss:0.0125472716328\n",
      "train loss:0.00808275970393\n",
      "train loss:0.021714049724\n",
      "train loss:0.035280397866\n",
      "train loss:0.0113231111739\n",
      "train loss:0.0256632628164\n",
      "train loss:0.0143901062697\n",
      "train loss:0.00644348108769\n",
      "train loss:0.0502155350609\n",
      "train loss:0.0144706895892\n",
      "train loss:0.055956025014\n",
      "train loss:0.0295035264633\n",
      "train loss:0.132068593175\n",
      "train loss:0.0127863219229\n",
      "train loss:0.0215360527256\n",
      "train loss:0.0204378979948\n",
      "train loss:0.00798288766134\n",
      "train loss:0.0367117778575\n",
      "train loss:0.00719968904747\n",
      "train loss:0.0131437775699\n",
      "train loss:0.00878821729329\n",
      "train loss:0.222182916667\n",
      "train loss:0.0813768733408\n",
      "train loss:0.0182293491815\n",
      "train loss:0.0207562832383\n",
      "train loss:0.0150207610279\n",
      "train loss:0.041372274158\n",
      "train loss:0.00897921231459\n",
      "train loss:0.0681615022396\n",
      "train loss:0.0304328578175\n",
      "train loss:0.0244877554762\n",
      "train loss:0.0125259659406\n",
      "train loss:0.0166512540634\n",
      "train loss:0.0395862723504\n",
      "train loss:0.0443955565221\n",
      "train loss:0.026515461834\n",
      "train loss:0.024327531675\n",
      "train loss:0.0121110052056\n",
      "train loss:0.0178287173479\n",
      "train loss:0.0126347034977\n",
      "train loss:0.0129612195268\n",
      "train loss:0.039682303059\n",
      "train loss:0.00696263294117\n",
      "train loss:0.0469768947125\n",
      "train loss:0.0146307782216\n",
      "train loss:0.0184164540179\n",
      "train loss:0.0346919708421\n",
      "train loss:0.015927507422\n",
      "train loss:0.0308347044532\n",
      "train loss:0.0515052504618\n",
      "train loss:0.0702633393331\n",
      "train loss:0.0192573936838\n",
      "train loss:0.0165440031099\n",
      "train loss:0.0412738026928\n",
      "train loss:0.122695308962\n",
      "train loss:0.00818552730886\n",
      "train loss:0.0202221770926\n",
      "train loss:0.0313009180941\n",
      "train loss:0.0165822131417\n",
      "train loss:0.0168270600305\n",
      "train loss:0.0371672305507\n",
      "train loss:0.0465676268694\n",
      "train loss:0.0170111540194\n",
      "train loss:0.0149157780839\n",
      "train loss:0.0493807066026\n",
      "train loss:0.0222214339258\n",
      "train loss:0.0153803553291\n",
      "train loss:0.0107909428807\n",
      "train loss:0.0189237376291\n",
      "train loss:0.0225144180586\n",
      "train loss:0.00770696531594\n",
      "train loss:0.029781390322\n",
      "train loss:0.0379206905287\n",
      "train loss:0.128998025646\n",
      "train loss:0.0113965628969\n",
      "train loss:0.00929408600293\n",
      "train loss:0.0370884848839\n",
      "train loss:0.0282653483307\n",
      "train loss:0.00793270746515\n",
      "train loss:0.069563417829\n",
      "train loss:0.0135069134753\n",
      "train loss:0.00638449145673\n",
      "train loss:0.0667714350406\n",
      "train loss:0.0244408131341\n",
      "train loss:0.0334321484584\n",
      "train loss:0.0384541835447\n",
      "train loss:0.0136299376102\n",
      "train loss:0.0832627509293\n",
      "train loss:0.021779936266\n",
      "train loss:0.0112799680721\n",
      "train loss:0.0318563335546\n",
      "train loss:0.0161137618824\n",
      "train loss:0.0351193162711\n",
      "train loss:0.131648260516\n",
      "train loss:0.00984774381413\n",
      "train loss:0.0346311077354\n",
      "train loss:0.0215370809181\n",
      "train loss:0.0324842343754\n",
      "train loss:0.00386927439\n",
      "train loss:0.0406338983266\n",
      "train loss:0.00815238098278\n",
      "train loss:0.0173896871989\n",
      "train loss:0.0110398447676\n",
      "train loss:0.036970969049\n",
      "train loss:0.0209686501291\n",
      "train loss:0.0294612110505\n",
      "train loss:0.0259610751331\n",
      "train loss:0.0125434027834\n",
      "train loss:0.0372648787122\n",
      "train loss:0.0352996874033\n",
      "train loss:0.0364061134597\n",
      "train loss:0.0303480191644\n",
      "train loss:0.0194393745659\n",
      "train loss:0.107828336078\n",
      "train loss:0.0140134745313\n",
      "train loss:0.0244127828605\n",
      "train loss:0.0192737750095\n",
      "train loss:0.0357417621377\n",
      "train loss:0.0286011456113\n",
      "train loss:0.00975848080324\n",
      "train loss:0.019407435338\n",
      "train loss:0.021369486325\n",
      "train loss:0.0278631099729\n",
      "train loss:0.0422626622863\n",
      "train loss:0.0248207818283\n",
      "train loss:0.025548081885\n",
      "train loss:0.0206393808112\n",
      "train loss:0.00837339352197\n",
      "train loss:0.0454870742912\n",
      "train loss:0.00740799710351\n",
      "train loss:0.0337987950704\n",
      "train loss:0.0154722471234\n",
      "train loss:0.0141570304424\n",
      "train loss:0.0104807543781\n",
      "train loss:0.00354700790756\n",
      "train loss:0.030422791961\n",
      "train loss:0.013807953988\n",
      "train loss:0.012479546409\n",
      "train loss:0.090954796963\n",
      "train loss:0.00653506580041\n",
      "train loss:0.0257762865035\n",
      "train loss:0.0140110505485\n",
      "train loss:0.00559443882822\n",
      "train loss:0.00422880412238\n",
      "train loss:0.00674006336498\n",
      "train loss:0.0511464196243\n",
      "train loss:0.0522009748423\n",
      "train loss:0.00454098026644\n",
      "train loss:0.0267546755714\n",
      "train loss:0.0160888130366\n",
      "train loss:0.00747863914717\n",
      "train loss:0.0272397226923\n",
      "train loss:0.0511366182229\n",
      "train loss:0.00898824836503\n",
      "train loss:0.029472996666\n",
      "train loss:0.00980175813814\n",
      "train loss:0.0101150269074\n",
      "train loss:0.00652796914574\n",
      "train loss:0.0546578828287\n",
      "train loss:0.0759112902151\n",
      "train loss:0.0507044937747\n",
      "train loss:0.00849052180225\n",
      "train loss:0.102462259473\n",
      "train loss:0.0347601531396\n",
      "train loss:0.0509942352445\n",
      "train loss:0.00634175663751\n",
      "train loss:0.0294597739658\n",
      "train loss:0.0113338156985\n",
      "train loss:0.0101190980197\n",
      "train loss:0.00691629067077\n",
      "train loss:0.0134521838558\n",
      "train loss:0.0104518647624\n",
      "train loss:0.0165224423653\n",
      "train loss:0.0198985500705\n",
      "train loss:0.0114733019246\n",
      "train loss:0.00925891144046\n",
      "train loss:0.0197564767459\n",
      "train loss:0.0138238149698\n",
      "train loss:0.0270817743504\n",
      "train loss:0.0117544144702\n",
      "train loss:0.0112235889243\n",
      "train loss:0.00663021046762\n",
      "train loss:0.00903588462927\n",
      "train loss:0.0225196560487\n",
      "train loss:0.0368536426424\n",
      "train loss:0.026477022036\n",
      "train loss:0.0265303853095\n",
      "train loss:0.00972565828845\n",
      "train loss:0.00710846257558\n",
      "train loss:0.0583611607431\n",
      "train loss:0.0303695179171\n",
      "train loss:0.00840831720344\n",
      "train loss:0.0285455804989\n",
      "train loss:0.020651699543\n",
      "train loss:0.0238783239787\n",
      "train loss:0.0535442339813\n",
      "train loss:0.0108207892409\n",
      "train loss:0.0096725046015\n",
      "train loss:0.00323834384204\n",
      "train loss:0.00884501964882\n",
      "train loss:0.0300450989654\n",
      "train loss:0.0247923486569\n",
      "train loss:0.0697178408443\n",
      "train loss:0.0298520740444\n",
      "train loss:0.0164775466119\n",
      "train loss:0.00741994989947\n",
      "train loss:0.0132213235961\n",
      "train loss:0.00548796673749\n",
      "train loss:0.0372571086926\n",
      "train loss:0.0111343100128\n",
      "train loss:0.00830529976805\n",
      "train loss:0.0278453749189\n",
      "train loss:0.00401144535123\n",
      "train loss:0.00960854785801\n",
      "train loss:0.0203675284631\n",
      "train loss:0.0464885141902\n",
      "train loss:0.0116070068656\n",
      "train loss:0.0226469368168\n",
      "train loss:0.0120134398427\n",
      "train loss:0.0321107012593\n",
      "train loss:0.0119686661396\n",
      "train loss:0.0525047095016\n",
      "train loss:0.0617163835637\n",
      "train loss:0.0173247792765\n",
      "train loss:0.0224453995979\n",
      "train loss:0.137557831378\n",
      "train loss:0.00790914638021\n",
      "train loss:0.0500613140008\n",
      "train loss:0.0088193194669\n",
      "train loss:0.0317749507545\n",
      "train loss:0.0363579735306\n",
      "train loss:0.0305483269955\n",
      "train loss:0.0105203624359\n",
      "train loss:0.00817226130543\n",
      "train loss:0.0437969802085\n",
      "train loss:0.0104996402845\n",
      "train loss:0.0467657245324\n",
      "train loss:0.018787862237\n",
      "train loss:0.00715007055676\n",
      "train loss:0.0121935986746\n",
      "train loss:0.02172517941\n",
      "train loss:0.00524416262147\n",
      "train loss:0.111884434627\n",
      "train loss:0.0485385216352\n",
      "train loss:0.0457435373444\n",
      "train loss:0.0148095407271\n",
      "train loss:0.0612162356153\n",
      "train loss:0.022183786753\n",
      "train loss:0.0202815109657\n",
      "train loss:0.020290924453\n",
      "train loss:0.0194106512553\n",
      "train loss:0.00652190615559\n",
      "train loss:0.0194099269439\n",
      "train loss:0.0238947632201\n",
      "train loss:0.0519378701025\n",
      "=== epoch:6, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.00939142383033\n",
      "train loss:0.0427583138903\n",
      "train loss:0.016730490258\n",
      "train loss:0.0167900864654\n",
      "train loss:0.0423274112994\n",
      "train loss:0.0114210517491\n",
      "train loss:0.0300925257508\n",
      "train loss:0.00380711986496\n",
      "train loss:0.0802456452362\n",
      "train loss:0.00939249768484\n",
      "train loss:0.0396229895157\n",
      "train loss:0.0101484203098\n",
      "train loss:0.0105928816521\n",
      "train loss:0.0344691286753\n",
      "train loss:0.011525531\n",
      "train loss:0.0308108058078\n",
      "train loss:0.0346077981326\n",
      "train loss:0.00587418102475\n",
      "train loss:0.0322070912178\n",
      "train loss:0.00551038857088\n",
      "train loss:0.0367465045943\n",
      "train loss:0.0129292407717\n",
      "train loss:0.0435857016717\n",
      "train loss:0.0175136289506\n",
      "train loss:0.0069435309863\n",
      "train loss:0.0434029352566\n",
      "train loss:0.0495104760118\n",
      "train loss:0.0262420150948\n",
      "train loss:0.0429857164467\n",
      "train loss:0.00732279507025\n",
      "train loss:0.0231401892256\n",
      "train loss:0.0159840385581\n",
      "train loss:0.0481729989237\n",
      "train loss:0.00979075161563\n",
      "train loss:0.0123861885489\n",
      "train loss:0.0191303338709\n",
      "train loss:0.0189402562945\n",
      "train loss:0.0132360005353\n",
      "train loss:0.00503492719256\n",
      "train loss:0.0093874435761\n",
      "train loss:0.0156049492804\n",
      "train loss:0.0157432232709\n",
      "train loss:0.00963809775468\n",
      "train loss:0.0253715948494\n",
      "train loss:0.0156011866265\n",
      "train loss:0.00947050890584\n",
      "train loss:0.0123071752699\n",
      "train loss:0.026692781326\n",
      "train loss:0.0249707278834\n",
      "train loss:0.0123978352842\n",
      "train loss:0.0414902298316\n",
      "train loss:0.00453051456856\n",
      "train loss:0.0117213342943\n",
      "train loss:0.0774553406147\n",
      "train loss:0.0215223441559\n",
      "train loss:0.0227424217543\n",
      "train loss:0.0825163780764\n",
      "train loss:0.00323110947451\n",
      "train loss:0.0237159874962\n",
      "train loss:0.00660952393245\n",
      "train loss:0.0161484528475\n",
      "train loss:0.0147393247473\n",
      "train loss:0.0114025487263\n",
      "train loss:0.00856933324335\n",
      "train loss:0.00214291157901\n",
      "train loss:0.0201438947913\n",
      "train loss:0.00696651839116\n",
      "train loss:0.0253497949774\n",
      "train loss:0.00964350271298\n",
      "train loss:0.0115402844034\n",
      "train loss:0.015922839634\n",
      "train loss:0.00877516769958\n",
      "train loss:0.0192403782301\n",
      "train loss:0.0261310308396\n",
      "train loss:0.0223645781557\n",
      "train loss:0.0166287358439\n",
      "train loss:0.0602930066237\n",
      "train loss:0.0198057569994\n",
      "train loss:0.0104229502378\n",
      "train loss:0.0111487593196\n",
      "train loss:0.0820926923231\n",
      "train loss:0.0297964599609\n",
      "train loss:0.0120684375274\n",
      "train loss:0.00290031710304\n",
      "train loss:0.00785535694774\n",
      "train loss:0.0190845328583\n",
      "train loss:0.00764891120781\n",
      "train loss:0.0343641756679\n",
      "train loss:0.0218632628873\n",
      "train loss:0.0614945695714\n",
      "train loss:0.0193415131917\n",
      "train loss:0.0292431024614\n",
      "train loss:0.00503388528739\n",
      "train loss:0.00580009478093\n",
      "train loss:0.00802844016203\n",
      "train loss:0.0186959711759\n",
      "train loss:0.00394010725188\n",
      "train loss:0.120218094195\n",
      "train loss:0.00683209669398\n",
      "train loss:0.0106734153487\n",
      "train loss:0.0207437181206\n",
      "train loss:0.00415215204738\n",
      "train loss:0.0606047183609\n",
      "train loss:0.00900863277699\n",
      "train loss:0.05986645376\n",
      "train loss:0.0679631603354\n",
      "train loss:0.00746996457521\n",
      "train loss:0.0434625106096\n",
      "train loss:0.00689191572746\n",
      "train loss:0.0483998280293\n",
      "train loss:0.00212499390396\n",
      "train loss:0.00941473659832\n",
      "train loss:0.0259097894598\n",
      "train loss:0.00921075243198\n",
      "train loss:0.0117815338071\n",
      "train loss:0.017079636636\n",
      "train loss:0.0451173308404\n",
      "train loss:0.0727793649348\n",
      "train loss:0.0185474608894\n",
      "train loss:0.00695528692663\n",
      "train loss:0.00659844265242\n",
      "train loss:0.0110235873476\n",
      "train loss:0.0501157664129\n",
      "train loss:0.0340430977667\n",
      "train loss:0.0140187348171\n",
      "train loss:0.0131914929871\n",
      "train loss:0.0144169794523\n",
      "train loss:0.0348330686805\n",
      "train loss:0.0112419345264\n",
      "train loss:0.0133609830839\n",
      "train loss:0.0110556164959\n",
      "train loss:0.0165456783859\n",
      "train loss:0.0140417480566\n",
      "train loss:0.00754715075419\n",
      "train loss:0.031428567429\n",
      "train loss:0.00707924807664\n",
      "train loss:0.0121831042981\n",
      "train loss:0.0218209590929\n",
      "train loss:0.0168527214037\n",
      "train loss:0.00521207207507\n",
      "train loss:0.0478952387791\n",
      "train loss:0.00982013778487\n",
      "train loss:0.0369642833776\n",
      "train loss:0.0300455122742\n",
      "train loss:0.0247117225577\n",
      "train loss:0.0179810727365\n",
      "train loss:0.00711260003032\n",
      "train loss:0.021377939497\n",
      "train loss:0.0211819398629\n",
      "train loss:0.0248091075023\n",
      "train loss:0.00531475551352\n",
      "train loss:0.0195741187106\n",
      "train loss:0.0153174341847\n",
      "train loss:0.00767588802866\n",
      "train loss:0.0243222940152\n",
      "train loss:0.0291486109561\n",
      "train loss:0.00607989408649\n",
      "train loss:0.0358140543895\n",
      "train loss:0.00694064425067\n",
      "train loss:0.0164971183106\n",
      "train loss:0.00217877113665\n",
      "train loss:0.0118081283504\n",
      "train loss:0.00459830916515\n",
      "train loss:0.0502622256954\n",
      "train loss:0.0665591617661\n",
      "train loss:0.0067960099917\n",
      "train loss:0.0370585589756\n",
      "train loss:0.0176063495992\n",
      "train loss:0.0256930065665\n",
      "train loss:0.0184526950488\n",
      "train loss:0.0193718001502\n",
      "train loss:0.0632354217988\n",
      "train loss:0.009198765023\n",
      "train loss:0.0160471755447\n",
      "train loss:0.0172736210112\n",
      "train loss:0.0287301427866\n",
      "train loss:0.0110052009625\n",
      "train loss:0.0657926709668\n",
      "train loss:0.027411536846\n",
      "train loss:0.0281892489027\n",
      "train loss:0.0556875692615\n",
      "train loss:0.0280297749008\n",
      "train loss:0.0191266842013\n",
      "train loss:0.0299806492065\n",
      "train loss:0.116238326377\n",
      "train loss:0.0146285502785\n",
      "train loss:0.0148403051168\n",
      "train loss:0.0275304283341\n",
      "train loss:0.0141267236164\n",
      "train loss:0.0248698661733\n",
      "train loss:0.0221089845232\n",
      "train loss:0.0303022663062\n",
      "train loss:0.00892136240551\n",
      "train loss:0.0314539636543\n",
      "train loss:0.011482377149\n",
      "train loss:0.016899199246\n",
      "train loss:0.0198650388875\n",
      "train loss:0.0127661612129\n",
      "train loss:0.00348601429263\n",
      "train loss:0.0178189774858\n",
      "train loss:0.022579107374\n",
      "train loss:0.0065436543127\n",
      "train loss:0.0179478478786\n",
      "train loss:0.0193061885247\n",
      "train loss:0.0705346791276\n",
      "train loss:0.00522599788276\n",
      "train loss:0.00848964399929\n",
      "train loss:0.0337943096101\n",
      "train loss:0.0366040915833\n",
      "train loss:0.029538623956\n",
      "train loss:0.0149504287228\n",
      "train loss:0.00818534267741\n",
      "train loss:0.0214240452793\n",
      "train loss:0.0154912297323\n",
      "train loss:0.0112152029799\n",
      "train loss:0.0247741430292\n",
      "train loss:0.0628592544913\n",
      "train loss:0.00975495450229\n",
      "train loss:0.0481652407278\n",
      "train loss:0.0185775323497\n",
      "train loss:0.0698515548302\n",
      "train loss:0.14193246834\n",
      "train loss:0.0634137382716\n",
      "train loss:0.041083117915\n",
      "train loss:0.0178011405897\n",
      "train loss:0.0887880975703\n",
      "train loss:0.0627973818833\n",
      "train loss:0.0303440235003\n",
      "train loss:0.106438321629\n",
      "train loss:0.024241574666\n",
      "train loss:0.0255053996379\n",
      "train loss:0.0137625493271\n",
      "train loss:0.0966031202652\n",
      "train loss:0.0144489112329\n",
      "train loss:0.0490916473615\n",
      "train loss:0.0259272037581\n",
      "train loss:0.055404205404\n",
      "train loss:0.0190386438127\n",
      "train loss:0.00455296546159\n",
      "train loss:0.00901958380521\n",
      "train loss:0.0133666575926\n",
      "train loss:0.0151554718073\n",
      "train loss:0.0299382152258\n",
      "train loss:0.0269135320481\n",
      "train loss:0.0386845781999\n",
      "train loss:0.0645140820702\n",
      "train loss:0.00325297478808\n",
      "train loss:0.0399222859569\n",
      "train loss:0.0254611711194\n",
      "train loss:0.0417528452797\n",
      "train loss:0.0286415069978\n",
      "train loss:0.00579296672972\n",
      "train loss:0.0431602618757\n",
      "train loss:0.0116143231504\n",
      "train loss:0.023069159111\n",
      "train loss:0.03099359128\n",
      "train loss:0.0263103513547\n",
      "train loss:0.030297392036\n",
      "train loss:0.0112152226958\n",
      "train loss:0.00695257727122\n",
      "train loss:0.0413308592628\n",
      "train loss:0.0267495136061\n",
      "train loss:0.013091010425\n",
      "train loss:0.0109916868648\n",
      "train loss:0.0236431596584\n",
      "train loss:0.0125006704049\n",
      "train loss:0.0100649905832\n",
      "train loss:0.0214842904319\n",
      "train loss:0.00732096073893\n",
      "train loss:0.00853232595658\n",
      "train loss:0.024187983869\n",
      "train loss:0.0210458045894\n",
      "train loss:0.0457590738047\n",
      "train loss:0.0322978139677\n",
      "train loss:0.0103830822165\n",
      "train loss:0.0295323261622\n",
      "train loss:0.0622393228435\n",
      "train loss:0.00353691087157\n",
      "train loss:0.00615513826335\n",
      "train loss:0.0283915848313\n",
      "train loss:0.00624478587309\n",
      "train loss:0.0193149416752\n",
      "train loss:0.0609076623498\n",
      "train loss:0.00953047221161\n",
      "train loss:0.040659697872\n",
      "train loss:0.00862564872941\n",
      "train loss:0.0345164070029\n",
      "train loss:0.0299713714933\n",
      "train loss:0.026302681611\n",
      "train loss:0.0138329142087\n",
      "train loss:0.014670486432\n",
      "train loss:0.0216270892939\n",
      "train loss:0.0297383614989\n",
      "train loss:0.00860443093347\n",
      "train loss:0.00377109375806\n",
      "train loss:0.00697338680536\n",
      "train loss:0.0162250519395\n",
      "train loss:0.012856421545\n",
      "train loss:0.0275734511699\n",
      "train loss:0.00734316583377\n",
      "train loss:0.00561152576969\n",
      "train loss:0.0448086730063\n",
      "train loss:0.00295572163752\n",
      "train loss:0.0260793595862\n",
      "train loss:0.00450897900077\n",
      "train loss:0.0107740943651\n",
      "train loss:0.00281552866897\n",
      "train loss:0.0544126864921\n",
      "train loss:0.0441056237873\n",
      "train loss:0.00733099487904\n",
      "train loss:0.0214381614998\n",
      "train loss:0.00607981711272\n",
      "train loss:0.0209814933237\n",
      "train loss:0.0211265270378\n",
      "train loss:0.0170073330744\n",
      "train loss:0.00900049756842\n",
      "train loss:0.0267383863562\n",
      "train loss:0.0170473150606\n",
      "train loss:0.00793109843182\n",
      "train loss:0.0102351070226\n",
      "train loss:0.00437017463686\n",
      "train loss:0.0151656866632\n",
      "train loss:0.0796236431323\n",
      "train loss:0.0515947103008\n",
      "train loss:0.0141179561104\n",
      "train loss:0.0335535084211\n",
      "train loss:0.00690155794839\n",
      "train loss:0.0333921729442\n",
      "train loss:0.0329364832392\n",
      "train loss:0.0257198041568\n",
      "train loss:0.013245226821\n",
      "train loss:0.00218149376195\n",
      "train loss:0.0049665906781\n",
      "train loss:0.240082882795\n",
      "train loss:0.00752113436715\n",
      "train loss:0.0178883967887\n",
      "train loss:0.0386830785184\n",
      "train loss:0.00523893583089\n",
      "train loss:0.0778386047503\n",
      "train loss:0.0612861514247\n",
      "train loss:0.0311274659923\n",
      "train loss:0.04322666365\n",
      "train loss:0.0210004960985\n",
      "train loss:0.0111680721127\n",
      "train loss:0.00958308166866\n",
      "train loss:0.0137689411184\n",
      "train loss:0.0158995774277\n",
      "train loss:0.0322011396604\n",
      "train loss:0.0160957223575\n",
      "train loss:0.0143208211958\n",
      "train loss:0.0217724248665\n",
      "train loss:0.0137336358514\n",
      "train loss:0.0162029396617\n",
      "train loss:0.00770628972385\n",
      "train loss:0.0188558362423\n",
      "train loss:0.0216455827483\n",
      "train loss:0.0119543292155\n",
      "train loss:0.0373522321782\n",
      "train loss:0.0204742232958\n",
      "train loss:0.0138277135057\n",
      "train loss:0.0116247935724\n",
      "train loss:0.00908971370081\n",
      "train loss:0.0219318830342\n",
      "train loss:0.0226779226729\n",
      "train loss:0.0256183418109\n",
      "train loss:0.0376128844236\n",
      "train loss:0.0155909605663\n",
      "train loss:0.0220992657246\n",
      "train loss:0.010737188407\n",
      "train loss:0.00920688514165\n",
      "train loss:0.00908849042342\n",
      "train loss:0.00638145527095\n",
      "train loss:0.00832017442321\n",
      "train loss:0.00059597800248\n",
      "train loss:0.00787499603682\n",
      "train loss:0.0104549732949\n",
      "train loss:0.0365291206696\n",
      "train loss:0.0618860980379\n",
      "train loss:0.0178891198048\n",
      "train loss:0.029293539936\n",
      "train loss:0.0188938616732\n",
      "train loss:0.0190714824964\n",
      "train loss:0.0125348218645\n",
      "train loss:0.0115611262584\n",
      "train loss:0.0106136914164\n",
      "train loss:0.0172184899585\n",
      "train loss:0.0306553235598\n",
      "train loss:0.0682462705406\n",
      "train loss:0.0526613629206\n",
      "train loss:0.0416438372949\n",
      "train loss:0.00501899190076\n",
      "train loss:0.0203602710068\n",
      "train loss:0.0392186442952\n",
      "train loss:0.0629612671041\n",
      "train loss:0.0110112844786\n",
      "train loss:0.0131367485379\n",
      "train loss:0.0140508384856\n",
      "train loss:0.0033463581645\n",
      "train loss:0.0109095943923\n",
      "train loss:0.00871415288339\n",
      "train loss:0.0323067217215\n",
      "train loss:0.00482595797349\n",
      "train loss:0.0121483462754\n",
      "train loss:0.0286659980676\n",
      "train loss:0.00568931128401\n",
      "train loss:0.0107857396936\n",
      "train loss:0.0175172539805\n",
      "train loss:0.014487069787\n",
      "train loss:0.0141010054856\n",
      "train loss:0.0200545441666\n",
      "train loss:0.0229504437479\n",
      "train loss:0.00909395837668\n",
      "train loss:0.0946861845654\n",
      "train loss:0.0166641483102\n",
      "train loss:0.0074221727489\n",
      "train loss:0.01378315999\n",
      "train loss:0.0102542371665\n",
      "train loss:0.083025376033\n",
      "train loss:0.011783944409\n",
      "train loss:0.00800039097727\n",
      "train loss:0.0105861240658\n",
      "train loss:0.010532098686\n",
      "train loss:0.0494127495402\n",
      "train loss:0.0553608160766\n",
      "train loss:0.0645551366029\n",
      "train loss:0.0136277210822\n",
      "train loss:0.00686438580526\n",
      "train loss:0.0183393225144\n",
      "train loss:0.0064452416021\n",
      "train loss:0.00415494314686\n",
      "train loss:0.00993131822759\n",
      "train loss:0.00329196017793\n",
      "train loss:0.038345751632\n",
      "train loss:0.0081102255558\n",
      "train loss:0.0327481555353\n",
      "train loss:0.00178406851293\n",
      "train loss:0.0651515800778\n",
      "train loss:0.0388503271898\n",
      "train loss:0.0373903313752\n",
      "train loss:0.0160388391349\n",
      "train loss:0.00474422474388\n",
      "train loss:0.00486226133432\n",
      "train loss:0.00797230676967\n",
      "train loss:0.0257358054198\n",
      "train loss:0.0113055342415\n",
      "train loss:0.00759069773071\n",
      "train loss:0.00420969509054\n",
      "train loss:0.0356209860098\n",
      "train loss:0.0105542947925\n",
      "train loss:0.030908009436\n",
      "train loss:0.0121404409591\n",
      "train loss:0.0330454039799\n",
      "train loss:0.0129887492647\n",
      "train loss:0.0256494249525\n",
      "train loss:0.0215121009738\n",
      "train loss:0.00939251642565\n",
      "train loss:0.0247277792437\n",
      "train loss:0.0133128792766\n",
      "train loss:0.0283391839\n",
      "train loss:0.00766797102852\n",
      "train loss:0.0670706077906\n",
      "train loss:0.0104291093852\n",
      "train loss:0.00165094679896\n",
      "train loss:0.0161645080463\n",
      "train loss:0.0105733942337\n",
      "train loss:0.0511149351273\n",
      "train loss:0.011756642068\n",
      "train loss:0.0145009840047\n",
      "train loss:0.00918496546809\n",
      "train loss:0.010919515031\n",
      "train loss:0.0124612634281\n",
      "train loss:0.0181097685706\n",
      "train loss:0.0426258739248\n",
      "train loss:0.0788954859918\n",
      "train loss:0.0245438828572\n",
      "train loss:0.00887734593901\n",
      "train loss:0.0188361891338\n",
      "train loss:0.106408356649\n",
      "train loss:0.0149925751109\n",
      "train loss:0.0124296771653\n",
      "train loss:0.0185909281534\n",
      "train loss:0.00725016650941\n",
      "train loss:0.0639457536138\n",
      "train loss:0.0177743580654\n",
      "train loss:0.00226523887976\n",
      "train loss:0.00541749747113\n",
      "train loss:0.0167958056663\n",
      "train loss:0.00535590829913\n",
      "train loss:0.00902628985791\n",
      "train loss:0.0177781522186\n",
      "train loss:0.0162310096215\n",
      "train loss:0.0124520112337\n",
      "train loss:0.018005541305\n",
      "train loss:0.0322574686838\n",
      "train loss:0.063861006331\n",
      "train loss:0.0184043733515\n",
      "train loss:0.0105993089771\n",
      "train loss:0.0283612225542\n",
      "train loss:0.0178426064192\n",
      "train loss:0.00172489160275\n",
      "train loss:0.0118997645889\n",
      "train loss:0.0345523137289\n",
      "train loss:0.0187540639343\n",
      "train loss:0.00504730498071\n",
      "train loss:0.0183754529247\n",
      "train loss:0.0244270076845\n",
      "train loss:0.0362162641074\n",
      "train loss:0.0672567708435\n",
      "train loss:0.0146185218185\n",
      "train loss:0.0140918628599\n",
      "train loss:0.00511299882505\n",
      "train loss:0.013383861458\n",
      "train loss:0.00876531836855\n",
      "train loss:0.0289078684166\n",
      "train loss:0.00600868467079\n",
      "train loss:0.0129246531619\n",
      "train loss:0.0307010507999\n",
      "train loss:0.0153927083911\n",
      "train loss:0.0224760817019\n",
      "train loss:0.0154541959808\n",
      "train loss:0.00727266659284\n",
      "train loss:0.00622289838636\n",
      "train loss:0.00736692314127\n",
      "train loss:0.00944750452857\n",
      "train loss:0.0107244473257\n",
      "train loss:0.0634296599267\n",
      "train loss:0.0344451153396\n",
      "train loss:0.00529370889492\n",
      "train loss:0.0210763347963\n",
      "train loss:0.0202462033729\n",
      "train loss:0.0104780133214\n",
      "train loss:0.00540507510996\n",
      "train loss:0.0065806754492\n",
      "train loss:0.00364190511912\n",
      "train loss:0.0105461609971\n",
      "train loss:0.0116476312948\n",
      "train loss:0.00733592286902\n",
      "train loss:0.0133795015779\n",
      "train loss:0.0253651012616\n",
      "train loss:0.0183991188899\n",
      "train loss:0.0236594374771\n",
      "train loss:0.0141514411962\n",
      "train loss:0.00760996895599\n",
      "train loss:0.00282961001235\n",
      "train loss:0.0156362702161\n",
      "train loss:0.0172830268157\n",
      "train loss:0.0111019883841\n",
      "train loss:0.0270362466471\n",
      "train loss:0.0258188048639\n",
      "train loss:0.0151730447545\n",
      "train loss:0.00184275430093\n",
      "train loss:0.0263251852068\n",
      "train loss:0.0101304484089\n",
      "train loss:0.00996916585868\n",
      "train loss:0.0133264594831\n",
      "train loss:0.0211077386587\n",
      "train loss:0.0177205122576\n",
      "train loss:0.00898845447751\n",
      "train loss:0.0339276693272\n",
      "train loss:0.022746740216\n",
      "train loss:0.0415905188725\n",
      "train loss:0.0375870709868\n",
      "train loss:0.0167732295349\n",
      "train loss:0.00346485699728\n",
      "train loss:0.00485982230175\n",
      "train loss:0.00421310186774\n",
      "train loss:0.00841854981414\n",
      "train loss:0.00622527324555\n",
      "train loss:0.00970691083953\n",
      "train loss:0.0191372787613\n",
      "train loss:0.0246862106314\n",
      "train loss:0.0291602333749\n",
      "train loss:0.0772576449672\n",
      "train loss:0.00440942437161\n",
      "train loss:0.0127087180535\n",
      "train loss:0.00803781220272\n",
      "train loss:0.0108513153636\n",
      "train loss:0.0165318423604\n",
      "train loss:0.0393067975205\n",
      "train loss:0.0143779983646\n",
      "train loss:0.0433753027645\n",
      "train loss:0.0101411951252\n",
      "train loss:0.00597376196203\n",
      "train loss:0.029510325946\n",
      "train loss:0.00661721304728\n",
      "train loss:0.0133850374938\n",
      "train loss:0.0126715731259\n",
      "train loss:0.00674699300289\n",
      "train loss:0.0126069073629\n",
      "train loss:0.0110586237579\n",
      "train loss:0.0135237707301\n",
      "train loss:0.00702252379495\n",
      "train loss:0.00630500129476\n",
      "train loss:0.0229620713539\n",
      "train loss:0.0060552036398\n",
      "train loss:0.02349264065\n",
      "train loss:0.0261325117584\n",
      "train loss:0.0212298363224\n",
      "train loss:0.020059809456\n",
      "train loss:0.007905904495\n",
      "=== epoch:7, train acc:0.992, test acc:0.982 ===\n",
      "train loss:0.0265223221771\n",
      "train loss:0.0242297917442\n",
      "train loss:0.010380648881\n",
      "train loss:0.0313248265912\n",
      "train loss:0.0145746561465\n",
      "train loss:0.0194322718053\n",
      "train loss:0.0437962467648\n",
      "train loss:0.0115194931663\n",
      "train loss:0.00936113729028\n",
      "train loss:0.0126179455216\n",
      "train loss:0.0231394512576\n",
      "train loss:0.0747916917057\n",
      "train loss:0.0100549713176\n",
      "train loss:0.0259554277963\n",
      "train loss:0.0174731618667\n",
      "train loss:0.0079282919754\n",
      "train loss:0.0285833501398\n",
      "train loss:0.00340467471408\n",
      "train loss:0.0172457200753\n",
      "train loss:0.0243446223268\n",
      "train loss:0.0114376826424\n",
      "train loss:0.00798348053252\n",
      "train loss:0.0115419513457\n",
      "train loss:0.0266563100229\n",
      "train loss:0.01839870713\n",
      "train loss:0.0108088027197\n",
      "train loss:0.0071204430922\n",
      "train loss:0.00411365681882\n",
      "train loss:0.0502121951815\n",
      "train loss:0.0619028936567\n",
      "train loss:0.0196211665125\n",
      "train loss:0.0051073547137\n",
      "train loss:0.0458887339345\n",
      "train loss:0.0166259078821\n",
      "train loss:0.0113154604759\n",
      "train loss:0.00735352093622\n",
      "train loss:0.0108780519646\n",
      "train loss:0.0073135055229\n",
      "train loss:0.0122551466319\n",
      "train loss:0.0135353069296\n",
      "train loss:0.00981043492822\n",
      "train loss:0.00736380233964\n",
      "train loss:0.0108161742202\n",
      "train loss:0.00797857532343\n",
      "train loss:0.00643845929744\n",
      "train loss:0.0224456968955\n",
      "train loss:0.00471895284222\n",
      "train loss:0.002630127567\n",
      "train loss:0.00760239222251\n",
      "train loss:0.0104562359468\n",
      "train loss:0.0425549012149\n",
      "train loss:0.035714324249\n",
      "train loss:0.00463790769315\n",
      "train loss:0.0184832648741\n",
      "train loss:0.00182605595962\n",
      "train loss:0.0318803199421\n",
      "train loss:0.0207027930425\n",
      "train loss:0.0191684487371\n",
      "train loss:0.00507844084831\n",
      "train loss:0.020354062601\n",
      "train loss:0.00599349656968\n",
      "train loss:0.0176847045184\n",
      "train loss:0.00276916925848\n",
      "train loss:0.0181038325875\n",
      "train loss:0.0135957094853\n",
      "train loss:0.056509132794\n",
      "train loss:0.00491569498941\n",
      "train loss:0.0110787236918\n",
      "train loss:0.0254619305583\n",
      "train loss:0.00453640609631\n",
      "train loss:0.010274154375\n",
      "train loss:0.0163677367061\n",
      "train loss:0.00461916266889\n",
      "train loss:0.00789961114862\n",
      "train loss:0.0396322032906\n",
      "train loss:0.0242732626094\n",
      "train loss:0.0125855507056\n",
      "train loss:0.0155458960256\n",
      "train loss:0.0219955157456\n",
      "train loss:0.0684612330287\n",
      "train loss:0.0336110647619\n",
      "train loss:0.00931086159142\n",
      "train loss:0.00615993345988\n",
      "train loss:0.00991670499824\n",
      "train loss:0.00823507920734\n",
      "train loss:0.00292418487887\n",
      "train loss:0.0516110640415\n",
      "train loss:0.0173217115602\n",
      "train loss:0.00663264738728\n",
      "train loss:0.0128147252962\n",
      "train loss:0.00613487008721\n",
      "train loss:0.0225818513344\n",
      "train loss:0.0139231422482\n",
      "train loss:0.0165874202806\n",
      "train loss:0.0162623055312\n",
      "train loss:0.0174458805976\n",
      "train loss:0.0114064228951\n",
      "train loss:0.0273784911662\n",
      "train loss:0.00682664533307\n",
      "train loss:0.0104775934623\n",
      "train loss:0.0275415281996\n",
      "train loss:0.0546149588629\n",
      "train loss:0.00219216117306\n",
      "train loss:0.0196226588799\n",
      "train loss:0.0161799099568\n",
      "train loss:0.0224597492089\n",
      "train loss:0.00500051106844\n",
      "train loss:0.0217030175311\n",
      "train loss:0.00847232934911\n",
      "train loss:0.0145987094938\n",
      "train loss:0.0189078113622\n",
      "train loss:0.126984946614\n",
      "train loss:0.00809705703194\n",
      "train loss:0.112673582809\n",
      "train loss:0.043587597744\n",
      "train loss:0.0520398904503\n",
      "train loss:0.0196456289864\n",
      "train loss:0.0222325354379\n",
      "train loss:0.0078671392996\n",
      "train loss:0.0465613240053\n",
      "train loss:0.0465436184745\n",
      "train loss:0.0139716493195\n",
      "train loss:0.00641290891934\n",
      "train loss:0.0305923532425\n",
      "train loss:0.00272922950063\n",
      "train loss:0.0195981750487\n",
      "train loss:0.022277209997\n",
      "train loss:0.0131741455564\n",
      "train loss:0.0358122614329\n",
      "train loss:0.0100442803451\n",
      "train loss:0.00997671336863\n",
      "train loss:0.01687437283\n",
      "train loss:0.0167704450562\n",
      "train loss:0.0209988776164\n",
      "train loss:0.00767931427635\n",
      "train loss:0.0186977619131\n",
      "train loss:0.0127534798299\n",
      "train loss:0.0197112089741\n",
      "train loss:0.0103529971799\n",
      "train loss:0.0105610431167\n",
      "train loss:0.00792225294674\n",
      "train loss:0.0163191135036\n",
      "train loss:0.00270121127198\n",
      "train loss:0.0105422288267\n",
      "train loss:0.0201897538331\n",
      "train loss:0.0125206207647\n",
      "train loss:0.018230731759\n",
      "train loss:0.0150960427343\n",
      "train loss:0.0247056846357\n",
      "train loss:0.00855573439425\n",
      "train loss:0.0456418770795\n",
      "train loss:0.00314269553517\n",
      "train loss:0.0219949285097\n",
      "train loss:0.00618183171576\n",
      "train loss:0.00811631724053\n",
      "train loss:0.0320024708004\n",
      "train loss:0.0116633653561\n",
      "train loss:0.0143912698545\n",
      "train loss:0.00323358711297\n",
      "train loss:0.00814693875632\n",
      "train loss:0.00981159734199\n",
      "train loss:0.0158330008821\n",
      "train loss:0.00343169532521\n",
      "train loss:0.0249916120853\n",
      "train loss:0.0181671204101\n",
      "train loss:0.0187043066446\n",
      "train loss:0.00974728187742\n",
      "train loss:0.0207111128615\n",
      "train loss:0.0160347431479\n",
      "train loss:0.0257699177955\n",
      "train loss:0.0178203884609\n",
      "train loss:0.0087261267747\n",
      "train loss:0.0402539262171\n",
      "train loss:0.0217541779018\n",
      "train loss:0.0115469475393\n",
      "train loss:0.0165871847549\n",
      "train loss:0.0110842039121\n",
      "train loss:0.0372753323778\n",
      "train loss:0.0078782926605\n",
      "train loss:0.0183720460129\n",
      "train loss:0.0179041585089\n",
      "train loss:0.00255810440053\n",
      "train loss:0.0167629773712\n",
      "train loss:0.0255791560869\n",
      "train loss:0.0169884560988\n",
      "train loss:0.0131489872553\n",
      "train loss:0.0301963478229\n",
      "train loss:0.0170965455506\n",
      "train loss:0.00897432029454\n",
      "train loss:0.00723975796932\n",
      "train loss:0.0169215627522\n",
      "train loss:0.0132422817678\n",
      "train loss:0.0209062505911\n",
      "train loss:0.0178607157734\n",
      "train loss:0.020111599737\n",
      "train loss:0.0362358950809\n",
      "train loss:0.00337594292279\n",
      "train loss:0.0600185169928\n",
      "train loss:0.0194855527571\n",
      "train loss:0.0265893774713\n",
      "train loss:0.0115289067865\n",
      "train loss:0.00495535745698\n",
      "train loss:0.0280154068648\n",
      "train loss:0.0123972380392\n",
      "train loss:0.0185814995864\n",
      "train loss:0.0285748464068\n",
      "train loss:0.00487304542149\n",
      "train loss:0.0381473477907\n",
      "train loss:0.0158247018493\n",
      "train loss:0.0202040954909\n",
      "train loss:0.0151318235098\n",
      "train loss:0.0127582241142\n",
      "train loss:0.0253263240519\n",
      "train loss:0.0207796048427\n",
      "train loss:0.0308840431679\n",
      "train loss:0.0161419637194\n",
      "train loss:0.0266934452533\n",
      "train loss:0.00510973917718\n",
      "train loss:0.0135787571467\n",
      "train loss:0.0222108009208\n",
      "train loss:0.0793035966071\n",
      "train loss:0.0058618187878\n",
      "train loss:0.00815540917096\n",
      "train loss:0.00669249319755\n",
      "train loss:0.0121943827531\n",
      "train loss:0.0210633926243\n",
      "train loss:0.015890991588\n",
      "train loss:0.0166834187085\n",
      "train loss:0.0157660672487\n",
      "train loss:0.0139904379912\n",
      "train loss:0.0177712403738\n",
      "train loss:0.00607556132454\n",
      "train loss:0.0255700440449\n",
      "train loss:0.0371573183052\n",
      "train loss:0.0125381874886\n",
      "train loss:0.0118095939791\n",
      "train loss:0.023290009323\n",
      "train loss:0.0109088593863\n",
      "train loss:0.010805369056\n",
      "train loss:0.00883804205947\n",
      "train loss:0.0131354212838\n",
      "train loss:0.00269294528288\n",
      "train loss:0.00347213748562\n",
      "train loss:0.0265133634503\n",
      "train loss:0.00621941968325\n",
      "train loss:0.00584409440822\n",
      "train loss:0.0186131532472\n",
      "train loss:0.00663643560323\n",
      "train loss:0.0131752932238\n",
      "train loss:0.0021148788066\n",
      "train loss:0.0294529905785\n",
      "train loss:0.00979688136227\n",
      "train loss:0.0278416949514\n",
      "train loss:0.0251294764322\n",
      "train loss:0.00346113241162\n",
      "train loss:0.00924743649619\n",
      "train loss:0.0927751759212\n",
      "train loss:0.0409483282773\n",
      "train loss:0.00808437731923\n",
      "train loss:0.0202005586817\n",
      "train loss:0.00926596599269\n",
      "train loss:0.0120196884899\n",
      "train loss:0.00688947048812\n",
      "train loss:0.0575740467778\n",
      "train loss:0.00864521859031\n",
      "train loss:0.00612883422631\n",
      "train loss:0.00906106091156\n",
      "train loss:0.00954285435999\n",
      "train loss:0.0110761582175\n",
      "train loss:0.00142127596998\n",
      "train loss:0.0120619677351\n",
      "train loss:0.0591835662126\n",
      "train loss:0.0125341795081\n",
      "train loss:0.0113527602031\n",
      "train loss:0.00320868350686\n",
      "train loss:0.0670004847837\n",
      "train loss:0.0195398834574\n",
      "train loss:0.0589878230416\n",
      "train loss:0.0193257497408\n",
      "train loss:0.0202616439154\n",
      "train loss:0.0187797539425\n",
      "train loss:0.0127410448014\n",
      "train loss:0.0132013242523\n",
      "train loss:0.0022684122329\n",
      "train loss:0.0157497443025\n",
      "train loss:0.0372217949553\n",
      "train loss:0.0096499856639\n",
      "train loss:0.0105846343137\n",
      "train loss:0.00982950322316\n",
      "train loss:0.00483904668164\n",
      "train loss:0.00762852266883\n",
      "train loss:0.0324284994477\n",
      "train loss:0.0140457311516\n",
      "train loss:0.0168289041528\n",
      "train loss:0.00867359721317\n",
      "train loss:0.0408558262369\n",
      "train loss:0.0782693682033\n",
      "train loss:0.00910057970598\n",
      "train loss:0.0264902050051\n",
      "train loss:0.0183802849895\n",
      "train loss:0.0302063937141\n",
      "train loss:0.0234605974094\n",
      "train loss:0.0506747153844\n",
      "train loss:0.00434640675925\n",
      "train loss:0.00950131585368\n",
      "train loss:0.0182228219488\n",
      "train loss:0.0422648045908\n",
      "train loss:0.0118389505166\n",
      "train loss:0.04306505757\n",
      "train loss:0.00250415159363\n",
      "train loss:0.00752128311098\n",
      "train loss:0.0274170362625\n",
      "train loss:0.0615277225863\n",
      "train loss:0.0309219993045\n",
      "train loss:0.0525419694985\n",
      "train loss:0.00776362949504\n",
      "train loss:0.0405190218741\n",
      "train loss:0.0128362013207\n",
      "train loss:0.0116447373047\n",
      "train loss:0.0109862442911\n",
      "train loss:0.00463548992109\n",
      "train loss:0.0107362327327\n",
      "train loss:0.0123383949717\n",
      "train loss:0.00990369338222\n",
      "train loss:0.0135009189663\n",
      "train loss:0.0371840856516\n",
      "train loss:0.00411380446313\n",
      "train loss:0.0404438103342\n",
      "train loss:0.0410196902132\n",
      "train loss:0.0372165474861\n",
      "train loss:0.0204382916548\n",
      "train loss:0.030967770481\n",
      "train loss:0.0253630133126\n",
      "train loss:0.00944235844986\n",
      "train loss:0.0178186334462\n",
      "train loss:0.00652233983435\n",
      "train loss:0.00419817323975\n",
      "train loss:0.00917839759165\n",
      "train loss:0.00949784217687\n",
      "train loss:0.0254646455968\n",
      "train loss:0.0197166687895\n",
      "train loss:0.0177331123273\n",
      "train loss:0.0449455382469\n",
      "train loss:0.00725945827074\n",
      "train loss:0.0188486220968\n",
      "train loss:0.0105448338531\n",
      "train loss:0.0202315600356\n",
      "train loss:0.0162653118303\n",
      "train loss:0.0142775141482\n",
      "train loss:0.0374594534023\n",
      "train loss:0.0234870682935\n",
      "train loss:0.0151093398457\n",
      "train loss:0.0239472996381\n",
      "train loss:0.0181703874855\n",
      "train loss:0.0114795106595\n",
      "train loss:0.0540515115468\n",
      "train loss:0.00705192242929\n",
      "train loss:0.0189054860489\n",
      "train loss:0.0265350422947\n",
      "train loss:0.00574726715141\n",
      "train loss:0.0398134981043\n",
      "train loss:0.0014863260482\n",
      "train loss:0.0138865844505\n",
      "train loss:0.0181116139332\n",
      "train loss:0.0295178469539\n",
      "train loss:0.0185603699191\n",
      "train loss:0.0260626885668\n",
      "train loss:0.00156629286112\n",
      "train loss:0.00777159406489\n",
      "train loss:0.00579966711239\n",
      "train loss:0.00208822875939\n",
      "train loss:0.0159466830974\n",
      "train loss:0.00533244661293\n",
      "train loss:0.00766474976046\n",
      "train loss:0.0036713431648\n",
      "train loss:0.0254640412621\n",
      "train loss:0.0176919679435\n",
      "train loss:0.00374031458328\n",
      "train loss:0.0422163549859\n",
      "train loss:0.0410717216431\n",
      "train loss:0.0170118061357\n",
      "train loss:0.00978287043656\n",
      "train loss:0.0346551059649\n",
      "train loss:0.00982176121805\n",
      "train loss:0.00340965809002\n",
      "train loss:0.00485626164509\n",
      "train loss:0.0113691610351\n",
      "train loss:0.0137862568591\n",
      "train loss:0.0127002122286\n",
      "train loss:0.0249755907428\n",
      "train loss:0.0145933056968\n",
      "train loss:0.00718329069645\n",
      "train loss:0.0763464347595\n",
      "train loss:0.016570525969\n",
      "train loss:0.0229978082444\n",
      "train loss:0.00670698769062\n",
      "train loss:0.0122979701819\n",
      "train loss:0.0203426865738\n",
      "train loss:0.0236149096684\n",
      "train loss:0.00403355268788\n",
      "train loss:0.00180183176463\n",
      "train loss:0.0285372051893\n",
      "train loss:0.00375598884481\n",
      "train loss:0.021492469663\n",
      "train loss:0.0113799357061\n",
      "train loss:0.0744712168787\n",
      "train loss:0.017385858212\n",
      "train loss:0.0369254586658\n",
      "train loss:0.0042160666277\n",
      "train loss:0.00497810797092\n",
      "train loss:0.0165179801348\n",
      "train loss:0.00233422626951\n",
      "train loss:0.010701446636\n",
      "train loss:0.0165624153095\n",
      "train loss:0.00673485296358\n",
      "train loss:0.0273322239324\n",
      "train loss:0.000587718325201\n",
      "train loss:0.00507247416019\n",
      "train loss:0.00355314618292\n",
      "train loss:0.00244723761792\n",
      "train loss:0.0135784155891\n",
      "train loss:0.00603945360374\n",
      "train loss:0.0445906243137\n",
      "train loss:0.00343060424093\n",
      "train loss:0.0221192704003\n",
      "train loss:0.0204905185579\n",
      "train loss:0.0071010860333\n",
      "train loss:0.00402051679644\n",
      "train loss:0.0659726880077\n",
      "train loss:0.00343694182218\n",
      "train loss:0.0270069393569\n",
      "train loss:0.0119146396803\n",
      "train loss:0.00885880695682\n",
      "train loss:0.00692426781358\n",
      "train loss:0.0242751279175\n",
      "train loss:0.00655109886299\n",
      "train loss:0.00888502622762\n",
      "train loss:0.0512118103093\n",
      "train loss:0.0534750831002\n",
      "train loss:0.039023734894\n",
      "train loss:0.0119771307808\n",
      "train loss:0.0197510227891\n",
      "train loss:0.0165330798532\n",
      "train loss:0.0188474001414\n",
      "train loss:0.0117192928978\n",
      "train loss:0.0279418971172\n",
      "train loss:0.0144194670541\n",
      "train loss:0.00933820148798\n",
      "train loss:0.0450714409203\n",
      "train loss:0.0206992330595\n",
      "train loss:0.0909455205857\n",
      "train loss:0.0017671909981\n",
      "train loss:0.0203455567683\n",
      "train loss:0.0164893808671\n",
      "train loss:0.0111764789981\n",
      "train loss:0.0155137694004\n",
      "train loss:0.0136379114868\n",
      "train loss:0.0057041604859\n",
      "train loss:0.00614073890553\n",
      "train loss:0.00444535631191\n",
      "train loss:0.0497917273015\n",
      "train loss:0.00607135281656\n",
      "train loss:0.0104354793476\n",
      "train loss:0.0181696761349\n",
      "train loss:0.0378044669388\n",
      "train loss:0.0204993105239\n",
      "train loss:0.000923943097806\n",
      "train loss:0.00338566355967\n",
      "train loss:0.00944016850945\n",
      "train loss:0.0707278268915\n",
      "train loss:0.00867026460801\n",
      "train loss:0.0375511927357\n",
      "train loss:0.018578528748\n",
      "train loss:0.00468237183192\n",
      "train loss:0.0450172254061\n",
      "train loss:0.0158769862066\n",
      "train loss:0.0145776255703\n",
      "train loss:0.0115114067384\n",
      "train loss:0.00799760876452\n",
      "train loss:0.0235124914047\n",
      "train loss:0.009292454597\n",
      "train loss:0.0143055175488\n",
      "train loss:0.00849476947909\n",
      "train loss:0.0222531388971\n",
      "train loss:0.0268082489573\n",
      "train loss:0.00558995628697\n",
      "train loss:0.0115392594332\n",
      "train loss:0.00514982968816\n",
      "train loss:0.0183153712965\n",
      "train loss:0.020181009472\n",
      "train loss:0.00480697044644\n",
      "train loss:0.010260800346\n",
      "train loss:0.0164395241153\n",
      "train loss:0.0507005376505\n",
      "train loss:0.0153757611276\n",
      "train loss:0.0103959623683\n",
      "train loss:0.00710378177208\n",
      "train loss:0.047845859443\n",
      "train loss:0.00273337981761\n",
      "train loss:0.00398486593319\n",
      "train loss:0.00706815890941\n",
      "train loss:0.00967820424026\n",
      "train loss:0.00207084384354\n",
      "train loss:0.0797185430564\n",
      "train loss:0.00319906670865\n",
      "train loss:0.0144158235545\n",
      "train loss:0.0828447574266\n",
      "train loss:0.00665918529083\n",
      "train loss:0.0126556445383\n",
      "train loss:0.0177185691519\n",
      "train loss:0.0342345625818\n",
      "train loss:0.0273496946848\n",
      "train loss:0.0102150749437\n",
      "train loss:0.0392213606047\n",
      "train loss:0.0452645950181\n",
      "train loss:0.00575835491405\n",
      "train loss:0.00545514135928\n",
      "train loss:0.00600393488757\n",
      "train loss:0.0106588658603\n",
      "train loss:0.00439044297589\n",
      "train loss:0.0459055323048\n",
      "train loss:0.00749735537968\n",
      "train loss:0.0278686199008\n",
      "train loss:0.0193362943437\n",
      "train loss:0.00809328228328\n",
      "train loss:0.00579157655024\n",
      "train loss:0.01579320355\n",
      "train loss:0.0217227601861\n",
      "train loss:0.042107695219\n",
      "train loss:0.00587879737414\n",
      "train loss:0.0038056523596\n",
      "train loss:0.0474278020338\n",
      "train loss:0.00674420572107\n",
      "train loss:0.00135462265872\n",
      "train loss:0.0340046765067\n",
      "train loss:0.0399590923738\n",
      "train loss:0.006503623624\n",
      "train loss:0.0131339976002\n",
      "train loss:0.0170543656689\n",
      "train loss:0.00964545703186\n",
      "train loss:0.00307607261526\n",
      "train loss:0.00284612800719\n",
      "train loss:0.00187642388975\n",
      "train loss:0.00396963857342\n",
      "train loss:0.00701828520105\n",
      "train loss:0.026781121372\n",
      "train loss:0.0104219588746\n",
      "train loss:0.0171279204258\n",
      "train loss:0.00942362978448\n",
      "train loss:0.00778186488249\n",
      "train loss:0.00742547618406\n",
      "train loss:0.048269265924\n",
      "train loss:0.0113522949616\n",
      "train loss:0.0131037134028\n",
      "train loss:0.00899373441198\n",
      "train loss:0.0155394937936\n",
      "train loss:0.0116748395797\n",
      "train loss:0.00999324797201\n",
      "train loss:0.00205935550084\n",
      "train loss:0.00910518174137\n",
      "train loss:0.0159569416331\n",
      "train loss:0.0229928966583\n",
      "train loss:0.0471551096527\n",
      "train loss:0.0233443452307\n",
      "train loss:0.00303076930911\n",
      "train loss:0.00526357343963\n",
      "train loss:0.00145957877692\n",
      "train loss:0.010180765729\n",
      "train loss:0.00597426290757\n",
      "train loss:0.00961017204683\n",
      "train loss:0.0115695471484\n",
      "train loss:0.00837391480083\n",
      "train loss:0.0266825945814\n",
      "train loss:0.0413631135664\n",
      "train loss:0.00711064655262\n",
      "train loss:0.0637678246791\n",
      "train loss:0.0230471931711\n",
      "train loss:0.0286010704858\n",
      "train loss:0.0167459111491\n",
      "train loss:0.00274535508161\n",
      "train loss:0.00196172678422\n",
      "train loss:0.00298095189332\n",
      "train loss:0.00530089194115\n",
      "train loss:0.00648632435734\n",
      "train loss:0.0013244485003\n",
      "train loss:0.00609982027729\n",
      "train loss:0.0203205674679\n",
      "train loss:0.00502349980673\n",
      "train loss:0.0125166181655\n",
      "train loss:0.00087086103986\n",
      "train loss:0.0191810077026\n",
      "train loss:0.00364379215949\n",
      "train loss:0.0105549321695\n",
      "train loss:0.00381998704199\n",
      "train loss:0.00351707032699\n",
      "train loss:0.0316459813409\n",
      "train loss:0.045242349085\n",
      "train loss:0.00634815009965\n",
      "train loss:0.0114798689967\n",
      "train loss:0.00451116718366\n",
      "=== epoch:8, train acc:0.993, test acc:0.984 ===\n",
      "train loss:0.0248215176047\n",
      "train loss:0.0636923333081\n",
      "train loss:0.00642881383604\n",
      "train loss:0.0123773504382\n",
      "train loss:0.0439668502914\n",
      "train loss:0.00687859316172\n",
      "train loss:0.0118885871702\n",
      "train loss:0.0236673334642\n",
      "train loss:0.0107624163011\n",
      "train loss:0.00725701452884\n",
      "train loss:0.0233830898342\n",
      "train loss:0.00185695724443\n",
      "train loss:0.00588450980902\n",
      "train loss:0.0108469244866\n",
      "train loss:0.00401622210333\n",
      "train loss:0.0160977169964\n",
      "train loss:0.11182304329\n",
      "train loss:0.00549133494535\n",
      "train loss:0.0135974393395\n",
      "train loss:0.0126534290518\n",
      "train loss:0.00128971738389\n",
      "train loss:0.0148110575358\n",
      "train loss:0.0414806485605\n",
      "train loss:0.0147228173052\n",
      "train loss:0.00804137776642\n",
      "train loss:0.0159903528051\n",
      "train loss:0.0272686078908\n",
      "train loss:0.0108973058773\n",
      "train loss:0.00673185059588\n",
      "train loss:0.0377076941796\n",
      "train loss:0.00769544942121\n",
      "train loss:0.0175456068914\n",
      "train loss:0.00685762863397\n",
      "train loss:0.0103616299054\n",
      "train loss:0.00698477784674\n",
      "train loss:0.0113091727951\n",
      "train loss:0.00442570563077\n",
      "train loss:0.0488937129812\n",
      "train loss:0.00373861555605\n",
      "train loss:0.0170246077425\n",
      "train loss:0.00380485913812\n",
      "train loss:0.0101163495207\n",
      "train loss:0.0102573111911\n",
      "train loss:0.00999535322242\n",
      "train loss:0.0069913518456\n",
      "train loss:0.0322748314967\n",
      "train loss:0.00602192453025\n",
      "train loss:0.0196193264934\n",
      "train loss:0.00968485010318\n",
      "train loss:0.0142195122157\n",
      "train loss:0.00172540153968\n",
      "train loss:0.0137333341423\n",
      "train loss:0.00257046552782\n",
      "train loss:0.032973668747\n",
      "train loss:0.0461488812943\n",
      "train loss:0.00894027538173\n",
      "train loss:0.0139271443435\n",
      "train loss:0.00404839698678\n",
      "train loss:0.0163958049063\n",
      "train loss:0.00220112785022\n",
      "train loss:0.00556471145544\n",
      "train loss:0.0026109814654\n",
      "train loss:0.0617788197068\n",
      "train loss:0.0111599944943\n",
      "train loss:0.00880620864176\n",
      "train loss:0.0117172663793\n",
      "train loss:0.00955734336558\n",
      "train loss:0.0110965168972\n",
      "train loss:0.0751519244502\n",
      "train loss:0.0106593722736\n",
      "train loss:0.0472144253268\n",
      "train loss:0.0158767851397\n",
      "train loss:0.0160461858871\n",
      "train loss:0.00401969152265\n",
      "train loss:0.0123555186428\n",
      "train loss:0.0128711976291\n",
      "train loss:0.0144782216723\n",
      "train loss:0.0224910849132\n",
      "train loss:0.0116758789421\n",
      "train loss:0.0130532443419\n",
      "train loss:0.205094909247\n",
      "train loss:0.00915079907197\n",
      "train loss:0.00888118888766\n",
      "train loss:0.00836199123752\n",
      "train loss:0.0140585019496\n",
      "train loss:0.0117368000901\n",
      "train loss:0.0169776758681\n",
      "train loss:0.0240913004312\n",
      "train loss:0.00290864066294\n",
      "train loss:0.00719538660656\n",
      "train loss:0.0427968100075\n",
      "train loss:0.0134717705292\n",
      "train loss:0.0114091345273\n",
      "train loss:0.00941962247287\n",
      "train loss:0.00391867680894\n",
      "train loss:0.00277055517785\n",
      "train loss:0.0133809402844\n",
      "train loss:0.00650835624857\n",
      "train loss:0.018746635622\n",
      "train loss:0.00370599256194\n",
      "train loss:0.030550411375\n",
      "train loss:0.00501732680875\n",
      "train loss:0.0232292337346\n",
      "train loss:0.0131997294981\n",
      "train loss:0.0118996801389\n",
      "train loss:0.0102271738278\n",
      "train loss:0.0105746455169\n",
      "train loss:0.00342018750276\n",
      "train loss:0.0168545812903\n",
      "train loss:0.0092820131381\n",
      "train loss:0.0014465576789\n",
      "train loss:0.00205722911354\n",
      "train loss:0.00920659125852\n",
      "train loss:0.013471400488\n",
      "train loss:0.016597687132\n",
      "train loss:0.0226832710554\n",
      "train loss:0.0286488503899\n",
      "train loss:0.00451913001188\n",
      "train loss:0.015797840757\n",
      "train loss:0.0705916040178\n",
      "train loss:0.0043391327109\n",
      "train loss:0.0181704820157\n",
      "train loss:0.031156920161\n",
      "train loss:0.0561235452824\n",
      "train loss:0.0159258641218\n",
      "train loss:0.00909993661219\n",
      "train loss:0.0101046066636\n",
      "train loss:0.0314229073786\n",
      "train loss:0.010502865787\n",
      "train loss:0.00377368042133\n",
      "train loss:0.00382620620359\n",
      "train loss:0.0215722595701\n",
      "train loss:0.0135649334032\n",
      "train loss:0.0138328249418\n",
      "train loss:0.0259219094116\n",
      "train loss:0.00702554825445\n",
      "train loss:0.00351228127047\n",
      "train loss:0.00633290760506\n",
      "train loss:0.00880604033378\n",
      "train loss:0.00436516575685\n",
      "train loss:0.0275734732767\n",
      "train loss:0.00978329483608\n",
      "train loss:0.0126959982327\n",
      "train loss:0.019352446113\n",
      "train loss:0.00314527992929\n",
      "train loss:0.0148300036723\n",
      "train loss:0.00218063583647\n",
      "train loss:0.00581141683414\n",
      "train loss:0.0116750909196\n",
      "train loss:0.00810443483911\n",
      "train loss:0.00336644393246\n",
      "train loss:0.0113813923012\n",
      "train loss:0.0138191649797\n",
      "train loss:0.00769419641229\n",
      "train loss:0.000812527538055\n",
      "train loss:0.00485552256678\n",
      "train loss:0.0174521494927\n",
      "train loss:0.00629147696873\n",
      "train loss:0.00533106399286\n",
      "train loss:0.091953674225\n",
      "train loss:0.0063514535363\n",
      "train loss:0.0137715620068\n",
      "train loss:0.00652663302099\n",
      "train loss:0.0119530939259\n",
      "train loss:0.00441750955578\n",
      "train loss:0.00696858015847\n",
      "train loss:0.00898679818509\n",
      "train loss:0.00523366840912\n",
      "train loss:0.0480739051286\n",
      "train loss:0.0115635180184\n",
      "train loss:0.00826777696487\n",
      "train loss:0.00859186526576\n",
      "train loss:0.0148761795412\n",
      "train loss:0.0153210725483\n",
      "train loss:0.00414076817552\n",
      "train loss:0.00660999406625\n",
      "train loss:0.00216189423574\n",
      "train loss:0.0389371316072\n",
      "train loss:0.0402954251573\n",
      "train loss:0.00487381070806\n",
      "train loss:0.00660884814773\n",
      "train loss:0.0256128721192\n",
      "train loss:0.0228200548154\n",
      "train loss:0.012007992092\n",
      "train loss:0.0140095778386\n",
      "train loss:0.0236163177413\n",
      "train loss:0.00836160806806\n",
      "train loss:0.0412684638191\n",
      "train loss:0.00871543381832\n",
      "train loss:0.00337270204768\n",
      "train loss:0.0116717179538\n",
      "train loss:0.0130797066154\n",
      "train loss:0.0322941457927\n",
      "train loss:0.0184679919545\n",
      "train loss:0.0137720660236\n",
      "train loss:0.0091032103573\n",
      "train loss:0.0125819225326\n",
      "train loss:0.0301567677917\n",
      "train loss:0.00507975173829\n",
      "train loss:0.00676523354946\n",
      "train loss:0.0212650861071\n",
      "train loss:0.00680931513952\n",
      "train loss:0.0192010367171\n",
      "train loss:0.00149459619925\n",
      "train loss:0.0258787048785\n",
      "train loss:0.0041170974174\n",
      "train loss:0.00912196090025\n",
      "train loss:0.0057170042506\n",
      "train loss:0.022997396914\n",
      "train loss:0.011669136213\n",
      "train loss:0.00441902448092\n",
      "train loss:0.00916059941071\n",
      "train loss:0.0115279663913\n",
      "train loss:0.0176067686066\n",
      "train loss:0.0108166436838\n",
      "train loss:0.00978424070885\n",
      "train loss:0.0131964255785\n",
      "train loss:0.0204970905011\n",
      "train loss:0.0135749560467\n",
      "train loss:0.0417665561814\n",
      "train loss:0.0107657637957\n",
      "train loss:0.00235915640166\n",
      "train loss:0.00168759398257\n",
      "train loss:0.0118455523668\n",
      "train loss:0.00344597069585\n",
      "train loss:0.00412884187294\n",
      "train loss:0.00279076347068\n",
      "train loss:0.0234628358079\n",
      "train loss:0.00672972818502\n",
      "train loss:0.021013306312\n",
      "train loss:0.0990645605656\n",
      "train loss:0.0044552094931\n",
      "train loss:0.0277792416871\n",
      "train loss:0.00668985639925\n",
      "train loss:0.0495341966978\n",
      "train loss:0.00936461740189\n",
      "train loss:0.00467891049898\n",
      "train loss:0.0200293598898\n",
      "train loss:0.0185419084817\n",
      "train loss:0.0483507052935\n",
      "train loss:0.0144448108141\n",
      "train loss:0.0179476573175\n",
      "train loss:0.00406975343915\n",
      "train loss:0.0059905442064\n",
      "train loss:0.0385713432776\n",
      "train loss:0.0111076305256\n",
      "train loss:0.12223318333\n",
      "train loss:0.0350516417516\n",
      "train loss:0.0134036983746\n",
      "train loss:0.0217575565959\n",
      "train loss:0.00491342112905\n",
      "train loss:0.011071287072\n",
      "train loss:0.0326026667174\n",
      "train loss:0.0283260000592\n",
      "train loss:0.00532346980108\n",
      "train loss:0.0126986728324\n",
      "train loss:0.00639773335976\n",
      "train loss:0.00740776545784\n",
      "train loss:0.0997164693901\n",
      "train loss:0.00243799074843\n",
      "train loss:0.00965347655463\n",
      "train loss:0.00190534787236\n",
      "train loss:0.0346641944377\n",
      "train loss:0.00990825057173\n",
      "train loss:0.0350736880602\n",
      "train loss:0.017428070327\n",
      "train loss:0.00542898907398\n",
      "train loss:0.00367710986641\n",
      "train loss:0.0467151248919\n",
      "train loss:0.00430179376376\n",
      "train loss:0.00829769479522\n",
      "train loss:0.0110296272244\n",
      "train loss:0.0137876445767\n",
      "train loss:0.00475050551356\n",
      "train loss:0.0579172865922\n",
      "train loss:0.0440203179156\n",
      "train loss:0.00702346624519\n",
      "train loss:0.00229443451788\n",
      "train loss:0.00144105077294\n",
      "train loss:0.010454006327\n",
      "train loss:0.0138207305167\n",
      "train loss:0.0181447301215\n",
      "train loss:0.00655409571796\n",
      "train loss:0.0312662733291\n",
      "train loss:0.0166289555201\n",
      "train loss:0.0571495294441\n",
      "train loss:0.0234053561452\n",
      "train loss:0.00928403054437\n",
      "train loss:0.0152204481777\n",
      "train loss:0.00340523506058\n",
      "train loss:0.0197674413508\n",
      "train loss:0.0126362396957\n",
      "train loss:0.00425848251106\n",
      "train loss:0.00432518672169\n",
      "train loss:0.0111189186821\n",
      "train loss:0.00316806733468\n",
      "train loss:0.0118385275096\n",
      "train loss:0.00450696014368\n",
      "train loss:0.0110599026357\n",
      "train loss:0.00659242171095\n",
      "train loss:0.0335968761967\n",
      "train loss:0.00518592587496\n",
      "train loss:0.00947280537421\n",
      "train loss:0.00655395053925\n",
      "train loss:0.00748645405922\n",
      "train loss:0.00571806027395\n",
      "train loss:0.0373583660662\n",
      "train loss:0.0204446705863\n",
      "train loss:0.00613237899329\n",
      "train loss:0.00970372941381\n",
      "train loss:0.0206334161012\n",
      "train loss:0.00659432122692\n",
      "train loss:0.00575898419434\n",
      "train loss:0.00994593198453\n",
      "train loss:0.00567071623766\n",
      "train loss:0.00356041829654\n",
      "train loss:0.00831164405543\n",
      "train loss:0.0408676268521\n",
      "train loss:0.00202370605326\n",
      "train loss:0.00596915270336\n",
      "train loss:0.0130651888039\n",
      "train loss:0.0284850557765\n",
      "train loss:0.0280704515571\n",
      "train loss:0.00395181110085\n",
      "train loss:0.00193225137534\n",
      "train loss:0.00778424160088\n",
      "train loss:0.0168881816263\n",
      "train loss:0.00866962892513\n",
      "train loss:0.0046905538261\n",
      "train loss:0.0109868946363\n",
      "train loss:0.00811323242264\n",
      "train loss:0.00714772586584\n",
      "train loss:0.00618845930147\n",
      "train loss:0.027878390397\n",
      "train loss:0.00255396640294\n",
      "train loss:0.00639812032908\n",
      "train loss:0.0161700161534\n",
      "train loss:0.0390432028009\n",
      "train loss:0.0252950012042\n",
      "train loss:0.00338656912153\n",
      "train loss:0.00588192945819\n",
      "train loss:0.00574414738324\n",
      "train loss:0.00569703076348\n",
      "train loss:0.00337146708268\n",
      "train loss:0.0437590328048\n",
      "train loss:0.00681862007088\n",
      "train loss:0.000879441659364\n",
      "train loss:0.0778496186238\n",
      "train loss:0.00842486614907\n",
      "train loss:0.0152911130281\n",
      "train loss:0.00477794281418\n",
      "train loss:0.0675861347529\n",
      "train loss:0.00175834727426\n",
      "train loss:0.0177065890295\n",
      "train loss:0.00988762272032\n",
      "train loss:0.00384675632722\n",
      "train loss:0.00223091055709\n",
      "train loss:0.00550477719399\n",
      "train loss:0.0132158397164\n",
      "train loss:0.0193694990736\n",
      "train loss:0.00154683988229\n",
      "train loss:0.0163297286875\n",
      "train loss:0.000694041398772\n",
      "train loss:0.00888326173878\n",
      "train loss:0.0143800417753\n",
      "train loss:0.0163196729439\n",
      "train loss:0.016173003463\n",
      "train loss:0.0138319014139\n",
      "train loss:0.0161754171843\n",
      "train loss:0.011568385427\n",
      "train loss:0.0183928163618\n",
      "train loss:0.0137679502275\n",
      "train loss:0.0353213634708\n",
      "train loss:0.00864813668931\n",
      "train loss:0.00500897978936\n",
      "train loss:0.02927199934\n",
      "train loss:0.00809317195861\n",
      "train loss:0.00608573173783\n",
      "train loss:0.0196737984276\n",
      "train loss:0.0291288056685\n",
      "train loss:0.0633699663493\n",
      "train loss:0.00443091118536\n",
      "train loss:0.00431298532202\n",
      "train loss:0.0129823115479\n",
      "train loss:0.00518813831958\n",
      "train loss:0.00641738286002\n",
      "train loss:0.0198316497167\n",
      "train loss:0.0042293055923\n",
      "train loss:0.0132726838664\n",
      "train loss:0.00684651974974\n",
      "train loss:0.00928691983426\n",
      "train loss:0.00301261899648\n",
      "train loss:0.0258877259173\n",
      "train loss:0.00960359347933\n",
      "train loss:0.00478543763517\n",
      "train loss:0.0277870589228\n",
      "train loss:0.0034448426314\n",
      "train loss:0.0344814754097\n",
      "train loss:0.0105936162433\n",
      "train loss:0.0016294020247\n",
      "train loss:0.0107652309961\n",
      "train loss:0.011737346467\n",
      "train loss:0.0291503142614\n",
      "train loss:0.00222404626101\n",
      "train loss:0.00487278213799\n",
      "train loss:0.00476222032436\n",
      "train loss:0.0271115451729\n",
      "train loss:0.00680574281188\n",
      "train loss:0.00630881236192\n",
      "train loss:0.00919629700701\n",
      "train loss:0.0154954897597\n",
      "train loss:0.0164956275064\n",
      "train loss:0.0028434406332\n",
      "train loss:0.0213190554024\n",
      "train loss:0.00285336545737\n",
      "train loss:0.00956974846102\n",
      "train loss:0.0178256095112\n",
      "train loss:0.0149094490937\n",
      "train loss:0.00619603710155\n",
      "train loss:0.00848157694633\n",
      "train loss:0.020641342164\n",
      "train loss:0.00494197999024\n",
      "train loss:0.000677464384346\n",
      "train loss:0.0147509908782\n",
      "train loss:0.0201740909293\n",
      "train loss:0.00280579369759\n",
      "train loss:0.00381180788485\n",
      "train loss:0.00322730790054\n",
      "train loss:0.0121947119961\n",
      "train loss:0.0126005997273\n",
      "train loss:0.00804440806103\n",
      "train loss:0.022929134626\n",
      "train loss:0.00444169849533\n",
      "train loss:0.0728450864326\n",
      "train loss:0.00965574001338\n",
      "train loss:0.00723504568331\n",
      "train loss:0.0159964339555\n",
      "train loss:0.0062416166412\n",
      "train loss:0.00394944185748\n",
      "train loss:0.00259338094116\n",
      "train loss:0.00182753845178\n",
      "train loss:0.0029460549757\n",
      "train loss:0.00788466406099\n",
      "train loss:0.00913514252461\n",
      "train loss:0.00910769189695\n",
      "train loss:0.00569544696112\n",
      "train loss:0.0101859800189\n",
      "train loss:0.0315185741536\n",
      "train loss:0.00908264268396\n",
      "train loss:0.00286234959023\n",
      "train loss:0.00467628704965\n",
      "train loss:0.00865035859542\n",
      "train loss:0.0227825277631\n",
      "train loss:0.011824716468\n",
      "train loss:0.00682193174561\n",
      "train loss:0.0228246666485\n",
      "train loss:0.00875809350151\n",
      "train loss:0.0189602332299\n",
      "train loss:0.00804230692901\n",
      "train loss:0.00132764750877\n",
      "train loss:0.00461726551509\n",
      "train loss:0.0103589002667\n",
      "train loss:0.0244334931549\n",
      "train loss:0.00221929899682\n",
      "train loss:0.0201117713311\n",
      "train loss:0.00700710586522\n",
      "train loss:0.00800534501773\n",
      "train loss:0.00743659999463\n",
      "train loss:0.00711850161776\n",
      "train loss:0.0455874560474\n",
      "train loss:0.00327013937431\n",
      "train loss:0.00949839064817\n",
      "train loss:0.0051577413074\n",
      "train loss:0.0318638385557\n",
      "train loss:0.00839789560484\n",
      "train loss:0.00532335723769\n",
      "train loss:0.00731821189828\n",
      "train loss:0.00193420671143\n",
      "train loss:0.00314544195481\n",
      "train loss:0.0105724152651\n",
      "train loss:0.0138495061691\n",
      "train loss:0.00789924982634\n",
      "train loss:0.0043689628989\n",
      "train loss:0.00793994564254\n",
      "train loss:0.00540491285314\n",
      "train loss:0.000397002203053\n",
      "train loss:0.0046219233044\n",
      "train loss:0.0196604657907\n",
      "train loss:0.01031467517\n",
      "train loss:0.029050744328\n",
      "train loss:0.00715853368284\n",
      "train loss:0.0304881984899\n",
      "train loss:0.00450745628333\n",
      "train loss:0.00185392378673\n",
      "train loss:0.00380726765565\n",
      "train loss:0.017168808456\n",
      "train loss:0.0392963824734\n",
      "train loss:0.0207323416677\n",
      "train loss:0.0441873638843\n",
      "train loss:0.00502043213126\n",
      "train loss:0.0335338788186\n",
      "train loss:0.00695264557173\n",
      "train loss:0.00797699757776\n",
      "train loss:0.00627851899902\n",
      "train loss:0.00777250450214\n",
      "train loss:0.001657058597\n",
      "train loss:0.00874297553954\n",
      "train loss:0.0145058594767\n",
      "train loss:0.00299541869637\n",
      "train loss:0.00964277823944\n",
      "train loss:0.00241702355569\n",
      "train loss:0.0844060725825\n",
      "train loss:0.00279209153232\n",
      "train loss:0.00512888765107\n",
      "train loss:0.00857206358903\n",
      "train loss:0.0142331422715\n",
      "train loss:0.0165328176292\n",
      "train loss:0.000941953990255\n",
      "train loss:0.0153954630082\n",
      "train loss:0.000975441827529\n",
      "train loss:0.0129901996764\n",
      "train loss:0.0155005994342\n",
      "train loss:0.0111115910713\n",
      "train loss:0.023119483633\n",
      "train loss:0.0120451446404\n",
      "train loss:0.00305044737898\n",
      "train loss:0.00439341909303\n",
      "train loss:0.0320722382877\n",
      "train loss:0.00187387139722\n",
      "train loss:0.0069642834328\n",
      "train loss:0.0171055004452\n",
      "train loss:0.00369642818252\n",
      "train loss:0.00851793516112\n",
      "train loss:0.0121794456231\n",
      "train loss:0.0148982936433\n",
      "train loss:0.00170943311986\n",
      "train loss:0.00650048564932\n",
      "train loss:0.012143850936\n",
      "train loss:0.00828311058513\n",
      "train loss:0.0143011616271\n",
      "train loss:0.00523838563984\n",
      "train loss:0.0300767261505\n",
      "train loss:0.0334435097614\n",
      "train loss:0.00580644247098\n",
      "train loss:0.0097689908128\n",
      "train loss:0.0485626288006\n",
      "train loss:0.0117945311274\n",
      "train loss:0.020748270323\n",
      "train loss:0.0162300898556\n",
      "train loss:0.00330475127025\n",
      "train loss:0.00713287103497\n",
      "train loss:0.0109599460321\n",
      "train loss:0.0211683059332\n",
      "train loss:0.0377409685253\n",
      "train loss:0.00446872441632\n",
      "train loss:0.0513509118418\n",
      "train loss:0.0033694516804\n",
      "train loss:0.0121919978163\n",
      "train loss:0.00839214733658\n",
      "train loss:0.0218125086184\n",
      "train loss:0.0065485409797\n",
      "train loss:0.00390026742427\n",
      "train loss:0.00949199472062\n",
      "train loss:0.00953027989514\n",
      "train loss:0.0154172714725\n",
      "train loss:0.00165706681615\n",
      "train loss:0.00324070253566\n",
      "train loss:0.0047724584407\n",
      "train loss:0.0025627880074\n",
      "train loss:0.0451212839794\n",
      "train loss:0.0139222404699\n",
      "train loss:0.0292871575886\n",
      "train loss:0.0319616651645\n",
      "train loss:0.0018715428802\n",
      "train loss:0.0253846320098\n",
      "train loss:0.00655717843811\n",
      "train loss:0.0219163861301\n",
      "train loss:0.00537916720462\n",
      "train loss:0.0141892495287\n",
      "train loss:0.0113085374132\n",
      "train loss:0.0150840934419\n",
      "train loss:0.0194453344481\n",
      "train loss:0.0292411922296\n",
      "train loss:0.014580707797\n",
      "train loss:0.00606425256546\n",
      "train loss:0.005560224272\n",
      "train loss:0.00315514844296\n",
      "train loss:0.002142507587\n",
      "train loss:0.0104245442843\n",
      "train loss:0.0150993269327\n",
      "train loss:0.0108517841531\n",
      "train loss:0.0119153063191\n",
      "train loss:0.00140863680355\n",
      "train loss:0.0121333253382\n",
      "train loss:0.0103860671454\n",
      "train loss:0.0039107595923\n",
      "train loss:0.0357043918286\n",
      "train loss:0.0383071318403\n",
      "train loss:0.00780891581576\n",
      "train loss:0.0170100286449\n",
      "=== epoch:9, train acc:0.991, test acc:0.984 ===\n",
      "train loss:0.00789723301733\n",
      "train loss:0.00558765874657\n",
      "train loss:0.00684387514315\n",
      "train loss:0.00206517231333\n",
      "train loss:0.00976405348704\n",
      "train loss:0.0134388047542\n",
      "train loss:0.00904409598536\n",
      "train loss:0.00345944040605\n",
      "train loss:0.007695661217\n",
      "train loss:0.015929131131\n",
      "train loss:0.00582272690431\n",
      "train loss:0.00297021154384\n",
      "train loss:0.00700452943896\n",
      "train loss:0.0358954988252\n",
      "train loss:0.0148604424279\n",
      "train loss:0.00696837897064\n",
      "train loss:0.00936446638771\n",
      "train loss:0.00286358270568\n",
      "train loss:0.00142615260395\n",
      "train loss:0.000676428090169\n",
      "train loss:0.00600028505028\n",
      "train loss:0.0226024159777\n",
      "train loss:0.00653542873835\n",
      "train loss:0.00187658154825\n",
      "train loss:0.125296378928\n",
      "train loss:0.00445287599894\n",
      "train loss:0.012763484944\n",
      "train loss:0.0285961102641\n",
      "train loss:0.00534467450186\n",
      "train loss:0.00111340993691\n",
      "train loss:0.00466324114554\n",
      "train loss:0.0583974356606\n",
      "train loss:0.00287718184328\n",
      "train loss:0.00633193244679\n",
      "train loss:0.00834907548568\n",
      "train loss:0.00970061456212\n",
      "train loss:0.0781254993283\n",
      "train loss:0.0168181590529\n",
      "train loss:0.00950818379438\n",
      "train loss:0.0108617390962\n",
      "train loss:0.00964441516142\n",
      "train loss:0.00248729163191\n",
      "train loss:0.0141759462578\n",
      "train loss:0.00812503715338\n",
      "train loss:0.00498265513398\n",
      "train loss:0.00404602903617\n",
      "train loss:0.0179377462738\n",
      "train loss:0.0117271171053\n",
      "train loss:0.00106673473936\n",
      "train loss:0.00292775458647\n",
      "train loss:0.0163738958444\n",
      "train loss:0.00324364655542\n",
      "train loss:0.015436175863\n",
      "train loss:0.00649371055461\n",
      "train loss:0.0127106059898\n",
      "train loss:0.000873296690169\n",
      "train loss:0.00252061553303\n",
      "train loss:0.0309615075867\n",
      "train loss:0.22217691957\n",
      "train loss:0.0265115127046\n",
      "train loss:0.00696996059558\n",
      "train loss:0.00918869812444\n",
      "train loss:0.00433647242315\n",
      "train loss:0.00348953229979\n",
      "train loss:0.0055407865354\n",
      "train loss:0.0496994195248\n",
      "train loss:0.0348636550117\n",
      "train loss:0.0175767251967\n",
      "train loss:0.00758662938306\n",
      "train loss:0.0266528081433\n",
      "train loss:0.00727376210995\n",
      "train loss:0.00872134347907\n",
      "train loss:0.0120070745392\n",
      "train loss:0.0146985725071\n",
      "train loss:0.00916144814154\n",
      "train loss:0.014465134328\n",
      "train loss:0.00964078614292\n",
      "train loss:0.0176733215111\n",
      "train loss:0.00295318553982\n",
      "train loss:0.0070628642519\n",
      "train loss:0.00461277495273\n",
      "train loss:0.00651257468973\n",
      "train loss:0.0152946387789\n",
      "train loss:0.00763915737719\n",
      "train loss:0.0125333247471\n",
      "train loss:0.0204153364643\n",
      "train loss:0.0080947343895\n",
      "train loss:0.00729637738162\n",
      "train loss:0.00823394130032\n",
      "train loss:0.0024460304858\n",
      "train loss:0.00291155697459\n",
      "train loss:0.00551246006517\n",
      "train loss:0.0142179388527\n",
      "train loss:0.00241927732241\n",
      "train loss:0.00302688607438\n",
      "train loss:0.0119963808653\n",
      "train loss:0.00510782353695\n",
      "train loss:0.00397375979912\n",
      "train loss:0.0085314543966\n",
      "train loss:0.0204484716727\n",
      "train loss:0.0291593504353\n",
      "train loss:0.00343875980808\n",
      "train loss:0.000915675862292\n",
      "train loss:0.0287865642428\n",
      "train loss:0.00581931795797\n",
      "train loss:0.0308528426004\n",
      "train loss:0.00787662550917\n",
      "train loss:0.00843972774978\n",
      "train loss:0.00315040789338\n",
      "train loss:0.00435715098856\n",
      "train loss:0.0148159481187\n",
      "train loss:0.00717058747903\n",
      "train loss:0.00875448219747\n",
      "train loss:0.00366950999337\n",
      "train loss:0.00872049813602\n",
      "train loss:0.0112490588277\n",
      "train loss:0.00148307978038\n",
      "train loss:0.00226391478473\n",
      "train loss:0.0100460697515\n",
      "train loss:0.00362876173524\n",
      "train loss:0.00861103326056\n",
      "train loss:0.0115045530044\n",
      "train loss:0.0344595109715\n",
      "train loss:0.00192936587506\n",
      "train loss:0.0119078751918\n",
      "train loss:0.0138008341966\n",
      "train loss:0.00134897656502\n",
      "train loss:0.0286233239547\n",
      "train loss:0.0144612859174\n",
      "train loss:0.00433033808708\n",
      "train loss:0.00669448051149\n",
      "train loss:0.0175389116483\n",
      "train loss:0.0338089193259\n",
      "train loss:0.00729836511371\n",
      "train loss:0.00377848330618\n",
      "train loss:0.00651221164304\n",
      "train loss:0.0183047009375\n",
      "train loss:0.00146942997358\n",
      "train loss:0.00557949365373\n",
      "train loss:0.0167929492275\n",
      "train loss:0.0175390437003\n",
      "train loss:0.0801345720569\n",
      "train loss:0.00708715557433\n",
      "train loss:0.0173601626125\n",
      "train loss:0.0100839450809\n",
      "train loss:0.0267257855137\n",
      "train loss:0.00307172619669\n",
      "train loss:0.00603257531279\n",
      "train loss:0.00282524859305\n",
      "train loss:0.00786465288242\n",
      "train loss:0.00557282178773\n",
      "train loss:0.0015126014379\n",
      "train loss:0.0163760016151\n",
      "train loss:0.00664186579264\n",
      "train loss:0.00481828760992\n",
      "train loss:0.003088586521\n",
      "train loss:0.00304156436407\n",
      "train loss:0.00950352363775\n",
      "train loss:0.00188719075236\n",
      "train loss:0.00620796805298\n",
      "train loss:0.000856943805177\n",
      "train loss:0.00298924915923\n",
      "train loss:0.000568773228861\n",
      "train loss:0.0801575313132\n",
      "train loss:0.0157733884354\n",
      "train loss:0.012199641917\n",
      "train loss:0.00812461125349\n",
      "train loss:0.00908561564464\n",
      "train loss:0.021642221476\n",
      "train loss:0.00579394591104\n",
      "train loss:0.00592983253602\n",
      "train loss:0.00893739272164\n",
      "train loss:0.00539140171363\n",
      "train loss:0.00605003207416\n",
      "train loss:0.0134463024581\n",
      "train loss:0.0064238217118\n",
      "train loss:0.0105652940082\n",
      "train loss:0.0071277348565\n",
      "train loss:0.00302538697653\n",
      "train loss:0.0387277723542\n",
      "train loss:0.0168460311409\n",
      "train loss:0.00810280136146\n",
      "train loss:0.020894816123\n",
      "train loss:0.00588928060989\n",
      "train loss:0.00752295331577\n",
      "train loss:0.0054611187504\n",
      "train loss:0.00225063080034\n",
      "train loss:0.00161400127508\n",
      "train loss:0.00716684512117\n",
      "train loss:0.0244028831782\n",
      "train loss:0.00524990510184\n",
      "train loss:0.00284318139918\n",
      "train loss:0.0237508480824\n",
      "train loss:0.00568197230039\n",
      "train loss:0.00474750269879\n",
      "train loss:0.00465818977352\n",
      "train loss:0.00892996472081\n",
      "train loss:0.00200481633315\n",
      "train loss:0.00366655085451\n",
      "train loss:0.0343998434506\n",
      "train loss:0.00460971192401\n",
      "train loss:0.0625037784816\n",
      "train loss:0.00249252625047\n",
      "train loss:0.00288729815694\n",
      "train loss:0.0210367653924\n",
      "train loss:0.00452402097476\n",
      "train loss:0.0182220394039\n",
      "train loss:0.00930170960218\n",
      "train loss:0.0207109745984\n",
      "train loss:0.00275574213724\n",
      "train loss:0.0357574768078\n",
      "train loss:0.0160892999434\n",
      "train loss:0.00924178096858\n",
      "train loss:0.00225742716773\n",
      "train loss:0.00881749374795\n",
      "train loss:0.0101985309015\n",
      "train loss:0.0012980530547\n",
      "train loss:0.00242251851785\n",
      "train loss:0.0103628174904\n",
      "train loss:0.00296687851986\n",
      "train loss:0.00266606753653\n",
      "train loss:0.00916507239193\n",
      "train loss:0.00517465491032\n",
      "train loss:0.00390530297938\n",
      "train loss:0.000214634823202\n",
      "train loss:0.0143098974365\n",
      "train loss:0.0185560740295\n",
      "train loss:0.0286243269735\n",
      "train loss:0.00395787709193\n",
      "train loss:0.00437103519971\n",
      "train loss:0.00851264885649\n",
      "train loss:0.00217816525956\n",
      "train loss:0.00190800710015\n",
      "train loss:0.00253051002652\n",
      "train loss:0.00982869604947\n",
      "train loss:0.00492051488138\n",
      "train loss:0.00516920788417\n",
      "train loss:0.00324940029615\n",
      "train loss:0.0108082932215\n",
      "train loss:0.00667664716595\n",
      "train loss:0.00302904951586\n",
      "train loss:0.00399126345041\n",
      "train loss:0.02151663492\n",
      "train loss:0.00922364265814\n",
      "train loss:0.0202847159171\n",
      "train loss:0.00550900919661\n",
      "train loss:0.0121082205516\n",
      "train loss:0.0140307586645\n",
      "train loss:0.029935328441\n",
      "train loss:0.00213833691205\n",
      "train loss:0.0145536456494\n",
      "train loss:0.00774514966108\n",
      "train loss:0.00646964623569\n",
      "train loss:0.00216879050181\n",
      "train loss:0.0220950829357\n",
      "train loss:0.0157405487584\n",
      "train loss:0.00294831078994\n",
      "train loss:0.00193852899071\n",
      "train loss:0.00135444363163\n",
      "train loss:0.0022158841947\n",
      "train loss:0.0059055913135\n",
      "train loss:0.00394103059802\n",
      "train loss:0.00729883836963\n",
      "train loss:0.00766108048593\n",
      "train loss:0.00438053270676\n",
      "train loss:0.0560076172915\n",
      "train loss:0.00484481873734\n",
      "train loss:0.00901034757028\n",
      "train loss:0.00371730543265\n",
      "train loss:0.0208635289723\n",
      "train loss:0.00545266012061\n",
      "train loss:0.00767683220827\n",
      "train loss:0.00147272071923\n",
      "train loss:0.00643078761887\n",
      "train loss:0.00578882755592\n",
      "train loss:0.00186866659969\n",
      "train loss:0.00396342130425\n",
      "train loss:0.00494341737703\n",
      "train loss:0.00492062799389\n",
      "train loss:0.00169277393218\n",
      "train loss:0.0248794021898\n",
      "train loss:0.00979942747195\n",
      "train loss:0.0156729936462\n",
      "train loss:0.0141203158414\n",
      "train loss:0.00431635961538\n",
      "train loss:0.00645362769874\n",
      "train loss:0.0109697513338\n",
      "train loss:0.0139769686243\n",
      "train loss:0.0102567155355\n",
      "train loss:0.00708752684305\n",
      "train loss:0.000601431539974\n",
      "train loss:0.00180064206504\n",
      "train loss:0.005075400868\n",
      "train loss:0.0286053388217\n",
      "train loss:0.00568549907218\n",
      "train loss:0.00427499295411\n",
      "train loss:0.00279204512039\n",
      "train loss:0.00259808262044\n",
      "train loss:0.00328195036054\n",
      "train loss:0.0198401047226\n",
      "train loss:0.00562319456911\n",
      "train loss:0.0360036788506\n",
      "train loss:0.00162320340538\n",
      "train loss:0.00555331776576\n",
      "train loss:0.00693159737907\n",
      "train loss:0.00290553464914\n",
      "train loss:0.0128814334097\n",
      "train loss:0.0103241222785\n",
      "train loss:0.039238061202\n",
      "train loss:0.00427859844465\n",
      "train loss:0.00157236355368\n",
      "train loss:0.00612989493493\n",
      "train loss:0.00606536230521\n",
      "train loss:0.023317313403\n",
      "train loss:0.01847932557\n",
      "train loss:0.00715303954249\n",
      "train loss:0.00509090519565\n",
      "train loss:0.00783042165807\n",
      "train loss:0.00229418586702\n",
      "train loss:0.00362407937475\n",
      "train loss:0.00214502439418\n",
      "train loss:0.00134453212696\n",
      "train loss:0.0025039968183\n",
      "train loss:0.00527908864695\n",
      "train loss:0.00905181672803\n",
      "train loss:0.000170415694966\n",
      "train loss:0.00143650011113\n",
      "train loss:0.00797896517016\n",
      "train loss:0.00082343452367\n",
      "train loss:0.0268958709387\n",
      "train loss:0.00825663345894\n",
      "train loss:0.0104183068873\n",
      "train loss:0.00462123238529\n",
      "train loss:0.00378579506792\n",
      "train loss:0.0146038584164\n",
      "train loss:0.00468290280717\n",
      "train loss:0.00607138412575\n",
      "train loss:0.00998995912288\n",
      "train loss:0.0066298590887\n",
      "train loss:0.00773106522969\n",
      "train loss:0.00493293252484\n",
      "train loss:0.00635182909553\n",
      "train loss:0.021681917731\n",
      "train loss:0.00687575351834\n",
      "train loss:0.0175388951459\n",
      "train loss:0.00417127992879\n",
      "train loss:0.00233892639631\n",
      "train loss:0.0252129907548\n",
      "train loss:0.00820507786423\n",
      "train loss:0.0103971193288\n",
      "train loss:0.0646658124629\n",
      "train loss:0.00155194460362\n",
      "train loss:0.00971373371452\n",
      "train loss:0.00764751651082\n",
      "train loss:0.013227776867\n",
      "train loss:0.00610833681561\n",
      "train loss:0.0391606182408\n",
      "train loss:0.00549866824992\n",
      "train loss:0.00193504248508\n",
      "train loss:0.00256062427309\n",
      "train loss:0.00610491714413\n",
      "train loss:0.0196987145322\n",
      "train loss:0.00213031750435\n",
      "train loss:0.00670639171422\n",
      "train loss:0.000538698647532\n",
      "train loss:0.02858276182\n",
      "train loss:0.0035117700994\n",
      "train loss:0.0224650981945\n",
      "train loss:0.00377137004865\n",
      "train loss:0.0168353152362\n",
      "train loss:0.00325707854585\n",
      "train loss:0.00717218614446\n",
      "train loss:0.00174327058757\n",
      "train loss:0.0132037424825\n",
      "train loss:0.00593172771361\n",
      "train loss:0.170057421326\n",
      "train loss:0.00841348845098\n",
      "train loss:0.00414405085631\n",
      "train loss:0.0861497001538\n",
      "train loss:0.00401075251597\n",
      "train loss:0.00437784067203\n",
      "train loss:0.00753052912996\n",
      "train loss:0.00289338097992\n",
      "train loss:0.00477709302283\n",
      "train loss:0.0274590270276\n",
      "train loss:0.0180744098748\n",
      "train loss:0.00564744777373\n",
      "train loss:0.0116076860302\n",
      "train loss:0.019104190412\n",
      "train loss:0.00484370666054\n",
      "train loss:0.00297171104315\n",
      "train loss:0.00590035085124\n",
      "train loss:0.00943392191925\n",
      "train loss:0.00376876231674\n",
      "train loss:0.00971224740958\n",
      "train loss:0.00166718678731\n",
      "train loss:0.00400076105382\n",
      "train loss:0.00903972632531\n",
      "train loss:0.00633906778275\n",
      "train loss:0.00617112031025\n",
      "train loss:0.00601987343488\n",
      "train loss:0.0228419240268\n",
      "train loss:0.00192946956938\n",
      "train loss:0.012488647394\n",
      "train loss:0.000397141290223\n",
      "train loss:0.00418262129088\n",
      "train loss:0.00677554796818\n",
      "train loss:0.00701086881087\n",
      "train loss:0.0082751160591\n",
      "train loss:0.0267991465462\n",
      "train loss:0.00342771938522\n",
      "train loss:0.023749250994\n",
      "train loss:0.0226014142698\n",
      "train loss:0.00410575838914\n",
      "train loss:0.00357079783032\n",
      "train loss:0.0116388752225\n",
      "train loss:0.00626239267251\n",
      "train loss:0.0130271559109\n",
      "train loss:0.00946356061769\n",
      "train loss:0.0142126659527\n",
      "train loss:0.00383421633911\n",
      "train loss:0.00835750954253\n",
      "train loss:0.00444746178963\n",
      "train loss:0.0191002025659\n",
      "train loss:0.015155339453\n",
      "train loss:0.0150638187124\n",
      "train loss:0.0620390763457\n",
      "train loss:0.00237844494823\n",
      "train loss:0.00584891364067\n",
      "train loss:0.0150246792638\n",
      "train loss:0.00564836594607\n",
      "train loss:0.00476144709234\n",
      "train loss:0.00521677149972\n",
      "train loss:0.00714176719736\n",
      "train loss:0.010196309004\n",
      "train loss:0.0127733890276\n",
      "train loss:0.00199089495237\n",
      "train loss:0.0119992948605\n",
      "train loss:0.00673303428123\n",
      "train loss:0.0177100019897\n",
      "train loss:0.00122845408223\n",
      "train loss:0.0214503883988\n",
      "train loss:0.0241113369185\n",
      "train loss:0.00628091855562\n",
      "train loss:0.022034750787\n",
      "train loss:0.00977157994383\n",
      "train loss:0.010688023445\n",
      "train loss:0.00543464322896\n",
      "train loss:0.0207419766656\n",
      "train loss:0.00273302727653\n",
      "train loss:0.0330173893675\n",
      "train loss:0.0100128018669\n",
      "train loss:0.00920408943687\n",
      "train loss:0.0228374038899\n",
      "train loss:0.0128577147772\n",
      "train loss:0.00422575835824\n",
      "train loss:0.0344912186817\n",
      "train loss:0.00550740120324\n",
      "train loss:0.00602136153678\n",
      "train loss:0.0166767108306\n",
      "train loss:0.00306333779878\n",
      "train loss:0.0176434258796\n",
      "train loss:0.0231703407711\n",
      "train loss:0.0093329320946\n",
      "train loss:0.00482670302747\n",
      "train loss:0.0101580527635\n",
      "train loss:0.0245791414136\n",
      "train loss:0.00275097105366\n",
      "train loss:0.00798315763298\n",
      "train loss:0.0025217414562\n",
      "train loss:0.00718774157569\n",
      "train loss:0.000970600417132\n",
      "train loss:0.00404380563353\n",
      "train loss:0.00464458598215\n",
      "train loss:0.00592548622568\n",
      "train loss:0.00600723245887\n",
      "train loss:0.00767686611327\n",
      "train loss:0.026338679071\n",
      "train loss:0.00394412115829\n",
      "train loss:0.00174190169241\n",
      "train loss:0.015057953577\n",
      "train loss:0.0104961524324\n",
      "train loss:0.00910220420731\n",
      "train loss:0.00242764450441\n",
      "train loss:0.00179499157844\n",
      "train loss:0.00160661287463\n",
      "train loss:0.0113225354972\n",
      "train loss:0.00504588949926\n",
      "train loss:0.00196798016511\n",
      "train loss:0.00747608835987\n",
      "train loss:0.00170654336591\n",
      "train loss:0.00346893394703\n",
      "train loss:0.000625835069213\n",
      "train loss:0.012920104863\n",
      "train loss:0.00219727931972\n",
      "train loss:0.00177634322235\n",
      "train loss:0.0149699885057\n",
      "train loss:0.00424606487372\n",
      "train loss:0.00619525164319\n",
      "train loss:0.00442555938101\n",
      "train loss:0.00264997670749\n",
      "train loss:0.00403883813752\n",
      "train loss:0.0013320739745\n",
      "train loss:0.00193289517436\n",
      "train loss:0.00584326874968\n",
      "train loss:0.00553547961072\n",
      "train loss:0.00184092605186\n",
      "train loss:0.011908990714\n",
      "train loss:0.00125824534091\n",
      "train loss:0.00413287678846\n",
      "train loss:0.017648697204\n",
      "train loss:0.00280124020671\n",
      "train loss:0.0211556047634\n",
      "train loss:0.0226610279621\n",
      "train loss:0.00927810321567\n",
      "train loss:0.00374731470652\n",
      "train loss:0.0319378813036\n",
      "train loss:0.00153865775279\n",
      "train loss:0.00144215701458\n",
      "train loss:0.0112470796265\n",
      "train loss:0.00674908068387\n",
      "train loss:0.00276556770256\n",
      "train loss:0.00344484320004\n",
      "train loss:0.00606481367743\n",
      "train loss:0.00339569192251\n",
      "train loss:0.00583264761722\n",
      "train loss:0.0149867769655\n",
      "train loss:0.00354777038734\n",
      "train loss:0.0311505260437\n",
      "train loss:0.0328779469929\n",
      "train loss:0.0045823645281\n",
      "train loss:0.00370011203148\n",
      "train loss:0.0184645571585\n",
      "train loss:0.00665551462042\n",
      "train loss:0.00606842812186\n",
      "train loss:0.00238838380698\n",
      "train loss:0.0040483489607\n",
      "train loss:0.000267220502564\n",
      "train loss:0.00435255485307\n",
      "train loss:0.00443973911528\n",
      "train loss:0.0183836164931\n",
      "train loss:0.00310582572241\n",
      "train loss:0.0103708848376\n",
      "train loss:0.0104235670365\n",
      "train loss:0.0253084875346\n",
      "train loss:0.00807665492538\n",
      "train loss:0.000898871212764\n",
      "train loss:0.00232369986348\n",
      "train loss:0.00342119931222\n",
      "train loss:0.0133424394207\n",
      "train loss:0.00359365863749\n",
      "train loss:0.000954176560266\n",
      "train loss:0.0144496941832\n",
      "train loss:0.0388434537593\n",
      "train loss:0.0107780739064\n",
      "train loss:0.023992181262\n",
      "train loss:0.0037728668218\n",
      "train loss:0.0033433128865\n",
      "train loss:0.0116701068952\n",
      "train loss:0.0137590643872\n",
      "train loss:0.00224724069717\n",
      "train loss:0.00637985573137\n",
      "train loss:0.00300422403129\n",
      "train loss:0.00682720544821\n",
      "train loss:0.032829598724\n",
      "train loss:0.00482611989596\n",
      "train loss:0.0485966843621\n",
      "train loss:0.00690173981995\n",
      "train loss:0.00672089719839\n",
      "train loss:0.0141514877849\n",
      "train loss:0.00632801369105\n",
      "train loss:0.0028803331391\n",
      "train loss:0.00493006314635\n",
      "train loss:0.00397292847519\n",
      "train loss:0.00209104494669\n",
      "train loss:0.00289745867256\n",
      "train loss:0.00082143183315\n",
      "train loss:0.0238070626777\n",
      "train loss:0.0052961169228\n",
      "train loss:0.0174963273503\n",
      "train loss:0.00361059923287\n",
      "train loss:0.0159018156165\n",
      "train loss:0.00618656041917\n",
      "train loss:0.00285078317917\n",
      "train loss:0.00468923382933\n",
      "train loss:0.00588258477909\n",
      "train loss:0.0470097107488\n",
      "train loss:0.00347628604738\n",
      "train loss:0.0129268717183\n",
      "train loss:0.0032480479535\n",
      "train loss:0.00344237257455\n",
      "train loss:0.141179912615\n",
      "train loss:0.00834912495446\n",
      "train loss:0.0534100773692\n",
      "train loss:0.0162944145988\n",
      "train loss:0.00808567251505\n",
      "train loss:0.0203459791844\n",
      "train loss:0.00333955875552\n",
      "train loss:0.0345376965171\n",
      "train loss:0.00127372753594\n",
      "=== epoch:10, train acc:0.992, test acc:0.989 ===\n",
      "train loss:0.016343792255\n",
      "train loss:0.00677672911124\n",
      "train loss:0.00657606377181\n",
      "train loss:0.00191636826789\n",
      "train loss:0.0609519759251\n",
      "train loss:0.0033339955184\n",
      "train loss:0.0110050338296\n",
      "train loss:0.0176898852056\n",
      "train loss:0.00728852665002\n",
      "train loss:0.00538568818779\n",
      "train loss:0.00309433155054\n",
      "train loss:0.00546095192643\n",
      "train loss:0.0156225463147\n",
      "train loss:0.0122342068612\n",
      "train loss:0.0199418543542\n",
      "train loss:0.00864749764006\n",
      "train loss:0.0011752824322\n",
      "train loss:0.00866845479168\n",
      "train loss:0.00627367935595\n",
      "train loss:0.0234328951426\n",
      "train loss:0.0342492722519\n",
      "train loss:0.00194624865131\n",
      "train loss:0.0118960790773\n",
      "train loss:0.00733867244907\n",
      "train loss:0.00258420435299\n",
      "train loss:0.0266393695006\n",
      "train loss:0.000836047396583\n",
      "train loss:0.00150447282997\n",
      "train loss:0.00903143554563\n",
      "train loss:0.0196535848204\n",
      "train loss:0.00950215246153\n",
      "train loss:0.00359355778474\n",
      "train loss:0.00212242973208\n",
      "train loss:0.0216130531418\n",
      "train loss:0.00598240862862\n",
      "train loss:0.0170434561989\n",
      "train loss:0.0160169206477\n",
      "train loss:0.0050338753468\n",
      "train loss:0.0108316310581\n",
      "train loss:0.00891293570043\n",
      "train loss:0.00234514805411\n",
      "train loss:0.0140035677468\n",
      "train loss:0.0135055255137\n",
      "train loss:0.00592842293134\n",
      "train loss:0.00337471693341\n",
      "train loss:0.000856595280169\n",
      "train loss:0.00336844982751\n",
      "train loss:0.00609027603991\n",
      "train loss:0.0196091357986\n",
      "train loss:0.0035763463667\n",
      "train loss:0.0142522200993\n",
      "train loss:0.0126201913953\n",
      "train loss:0.0152137012729\n",
      "train loss:0.0191194057561\n",
      "train loss:0.00665589099599\n",
      "train loss:0.0111546568069\n",
      "train loss:0.018528665081\n",
      "train loss:0.0216763981392\n",
      "train loss:0.0010953158207\n",
      "train loss:0.00473684006519\n",
      "train loss:0.00235293285622\n",
      "train loss:0.00801477482985\n",
      "train loss:0.00644230944068\n",
      "train loss:0.00825128702927\n",
      "train loss:0.0014620455839\n",
      "train loss:0.000629910293536\n",
      "train loss:0.0132136312569\n",
      "train loss:0.00942293685945\n",
      "train loss:0.00957743074475\n",
      "train loss:0.00755479304384\n",
      "train loss:0.00676372663232\n",
      "train loss:0.0126897986888\n",
      "train loss:0.0018636756803\n",
      "train loss:0.0026015405991\n",
      "train loss:0.00181475333417\n",
      "train loss:0.0142592178217\n",
      "train loss:0.0104651137801\n",
      "train loss:0.00904762436453\n",
      "train loss:0.0160172585995\n",
      "train loss:0.00179554075273\n",
      "train loss:0.0153543834355\n",
      "train loss:0.0112336579691\n",
      "train loss:0.0262204101922\n",
      "train loss:0.0026956691972\n",
      "train loss:0.0105390645244\n",
      "train loss:0.00651403208574\n",
      "train loss:0.00373937025957\n",
      "train loss:0.0131422812551\n",
      "train loss:0.0140546638818\n",
      "train loss:0.0228069208304\n",
      "train loss:0.00588901203767\n",
      "train loss:0.00723209814984\n",
      "train loss:0.0204045750749\n",
      "train loss:0.00667079769901\n",
      "train loss:0.0078260585854\n",
      "train loss:0.00676921652141\n",
      "train loss:0.0181664266693\n",
      "train loss:0.00410988785514\n",
      "train loss:0.0360686142683\n",
      "train loss:0.00212731667005\n",
      "train loss:0.00430142001062\n",
      "train loss:0.00695576714228\n",
      "train loss:0.00847818652011\n",
      "train loss:0.0020556575633\n",
      "train loss:0.00625476959249\n",
      "train loss:0.0101572372633\n",
      "train loss:0.00884465073673\n",
      "train loss:0.0135010415192\n",
      "train loss:0.0161531558928\n",
      "train loss:0.10300767603\n",
      "train loss:0.00968551637546\n",
      "train loss:0.00683330972895\n",
      "train loss:0.00335605926963\n",
      "train loss:0.00463799408808\n",
      "train loss:0.00412761498561\n",
      "train loss:0.00251218722868\n",
      "train loss:0.0198759260331\n",
      "train loss:0.00850852799588\n",
      "train loss:0.0332466256566\n",
      "train loss:0.0909880084278\n",
      "train loss:0.000366453148894\n",
      "train loss:0.0188488805368\n",
      "train loss:0.00128371313643\n",
      "train loss:0.00730822624011\n",
      "train loss:0.00921251900305\n",
      "train loss:0.0578220790577\n",
      "train loss:0.0022832372487\n",
      "train loss:0.0169006048463\n",
      "train loss:0.0184558442728\n",
      "train loss:0.0159657727094\n",
      "train loss:0.0555066837543\n",
      "train loss:0.0330757614243\n",
      "train loss:0.00511689476824\n",
      "train loss:0.00392691426416\n",
      "train loss:0.00210014218671\n",
      "train loss:0.0289025896603\n",
      "train loss:0.00696434275274\n",
      "train loss:0.0433457284737\n",
      "train loss:0.00307720386017\n",
      "train loss:0.0140595628986\n",
      "train loss:0.0168627529647\n",
      "train loss:0.00115599554118\n",
      "train loss:0.0148965009197\n",
      "train loss:0.0130783258429\n",
      "train loss:0.0104906001797\n",
      "train loss:0.00882899469197\n",
      "train loss:0.0784963834645\n",
      "train loss:0.00391855722594\n",
      "train loss:0.00989894240469\n",
      "train loss:0.0355737275282\n",
      "train loss:0.00339829453531\n",
      "train loss:0.00418991847317\n",
      "train loss:0.00271811657881\n",
      "train loss:0.0118796281602\n",
      "train loss:0.0695822233797\n",
      "train loss:0.005088808248\n",
      "train loss:0.00557392311336\n",
      "train loss:0.00161400924469\n",
      "train loss:0.0104852288305\n",
      "train loss:0.0213787791995\n",
      "train loss:0.0060108538614\n",
      "train loss:0.027514917117\n",
      "train loss:0.00446509975903\n",
      "train loss:0.004606497045\n",
      "train loss:0.00196454269917\n",
      "train loss:0.000665873733543\n",
      "train loss:0.00564934527425\n",
      "train loss:0.00947613462068\n",
      "train loss:0.00767036727168\n",
      "train loss:0.00911971761276\n",
      "train loss:0.0427593952022\n",
      "train loss:0.0021887088886\n",
      "train loss:0.0048043075415\n",
      "train loss:0.0127674310092\n",
      "train loss:0.0146807920315\n",
      "train loss:0.0767222754407\n",
      "train loss:0.0110983844038\n",
      "train loss:0.0233712847028\n",
      "train loss:0.00871686806779\n",
      "train loss:0.00187727397744\n",
      "train loss:0.00557736539331\n",
      "train loss:0.00126658071141\n",
      "train loss:0.00712096819124\n",
      "train loss:0.0109085762338\n",
      "train loss:0.032586939269\n",
      "train loss:0.00534312071022\n",
      "train loss:0.0077322300399\n",
      "train loss:0.00083895795391\n",
      "train loss:0.0103433365281\n",
      "train loss:0.00188440676178\n",
      "train loss:0.0082367647935\n",
      "train loss:0.000282781971625\n",
      "train loss:0.00475676214094\n",
      "train loss:0.00642745047384\n",
      "train loss:0.003790370613\n",
      "train loss:0.000897039003193\n",
      "train loss:0.0015440629323\n",
      "train loss:0.00710010945504\n",
      "train loss:0.00919793456468\n",
      "train loss:0.0252560867886\n",
      "train loss:0.00253354247858\n",
      "train loss:0.00224455935232\n",
      "train loss:0.000629017957175\n",
      "train loss:0.0051840703116\n",
      "train loss:0.00691239335793\n",
      "train loss:0.00590984928117\n",
      "train loss:0.00400470740776\n",
      "train loss:0.00130756926734\n",
      "train loss:0.00597940747532\n",
      "train loss:0.0155704291813\n",
      "train loss:0.0274953669378\n",
      "train loss:0.0157958144514\n",
      "train loss:0.00762359914894\n",
      "train loss:0.00438752622499\n",
      "train loss:0.00575364010869\n",
      "train loss:0.00372674996999\n",
      "train loss:0.0258274043127\n",
      "train loss:0.00453848938272\n",
      "train loss:0.00314396288985\n",
      "train loss:0.0236730858589\n",
      "train loss:0.000966550987061\n",
      "train loss:0.0915672511363\n",
      "train loss:0.00573376438431\n",
      "train loss:0.00896520077702\n",
      "train loss:0.00941393881333\n",
      "train loss:0.0131025749813\n",
      "train loss:0.00195242252827\n",
      "train loss:0.0241597990922\n",
      "train loss:0.0138429855083\n",
      "train loss:0.000904367180995\n",
      "train loss:0.00691805058578\n",
      "train loss:0.0174395063406\n",
      "train loss:0.00393574912214\n",
      "train loss:0.112853858703\n",
      "train loss:0.0176478275175\n",
      "train loss:0.00878032155318\n",
      "train loss:0.00371280689752\n",
      "train loss:0.104975671106\n",
      "train loss:0.035913300815\n",
      "train loss:0.00237787542085\n",
      "train loss:0.00276385128658\n",
      "train loss:0.0108091899423\n",
      "train loss:0.0374999865985\n",
      "train loss:0.0154280558725\n",
      "train loss:0.0120268665772\n",
      "train loss:0.0101214138887\n",
      "train loss:0.00545635587408\n",
      "train loss:0.00487712350798\n",
      "train loss:0.00318493063405\n",
      "train loss:0.00542193477692\n",
      "train loss:0.00488781417089\n",
      "train loss:0.0128315208864\n",
      "train loss:0.00626396526317\n",
      "train loss:0.00900426567803\n",
      "train loss:0.00633715643009\n",
      "train loss:0.00669188213959\n",
      "train loss:0.00949400664012\n",
      "train loss:0.0114846730878\n",
      "train loss:0.00529603836512\n",
      "train loss:0.0163120538925\n",
      "train loss:0.00799523763743\n",
      "train loss:0.0125790337577\n",
      "train loss:0.00252712242662\n",
      "train loss:0.013721544546\n",
      "train loss:0.0160910638465\n",
      "train loss:0.0047940772598\n",
      "train loss:0.00101542155576\n",
      "train loss:0.00340484181557\n",
      "train loss:0.0259343629648\n",
      "train loss:0.0275876652052\n",
      "train loss:0.00451475958015\n",
      "train loss:0.0106660857793\n",
      "train loss:0.00199973246142\n",
      "train loss:0.000958309689489\n",
      "train loss:0.00318542314233\n",
      "train loss:0.0424032137874\n",
      "train loss:0.00710512880661\n",
      "train loss:0.00800913069457\n",
      "train loss:0.00630300029036\n",
      "train loss:0.0171383255805\n",
      "train loss:0.00312232065268\n",
      "train loss:0.0053936925661\n",
      "train loss:0.00273654820145\n",
      "train loss:0.00288337786649\n",
      "train loss:0.00660090221525\n",
      "train loss:0.000649498387628\n",
      "train loss:0.00180029235625\n",
      "train loss:0.0260751020348\n",
      "train loss:0.00366998671215\n",
      "train loss:0.00557875528084\n",
      "train loss:0.00254826842806\n",
      "train loss:0.00197861872199\n",
      "train loss:0.0012683900608\n",
      "train loss:0.00427926134858\n",
      "train loss:0.00651184949345\n",
      "train loss:0.00656194108812\n",
      "train loss:0.0135757058826\n",
      "train loss:0.0365175454992\n",
      "train loss:0.0668082095649\n",
      "train loss:0.00716268391818\n",
      "train loss:0.0209146740663\n",
      "train loss:0.000622987954682\n",
      "train loss:0.00461077961701\n",
      "train loss:0.022822127815\n",
      "train loss:0.0471044861489\n",
      "train loss:0.00350632340825\n",
      "train loss:0.00936497975282\n",
      "train loss:0.000959826384755\n",
      "train loss:0.00125565423957\n",
      "train loss:0.00467703479461\n",
      "train loss:0.00182624066914\n",
      "train loss:0.0196756054312\n",
      "train loss:0.0210251614851\n",
      "train loss:0.00225753486655\n",
      "train loss:0.00464493537238\n",
      "train loss:0.00339033189345\n",
      "train loss:0.00404181278883\n",
      "train loss:0.00447807759078\n",
      "train loss:0.0112049784261\n",
      "train loss:0.00456215221252\n",
      "train loss:0.00289437476002\n",
      "train loss:0.00573469873423\n",
      "train loss:0.00127609268553\n",
      "train loss:0.0155746794369\n",
      "train loss:0.00333769424949\n",
      "train loss:0.000661516879145\n",
      "train loss:0.0317885644336\n",
      "train loss:0.00602114940032\n",
      "train loss:0.00354070619879\n",
      "train loss:0.0040669949569\n",
      "train loss:0.00418297782115\n",
      "train loss:0.00587464565967\n",
      "train loss:0.000491575783002\n",
      "train loss:0.00731597062379\n",
      "train loss:0.0116390892574\n",
      "train loss:0.00453732540798\n",
      "train loss:0.00328235780711\n",
      "train loss:0.00921082746232\n",
      "train loss:0.0177749178569\n",
      "train loss:0.00221087630201\n",
      "train loss:0.00534957411355\n",
      "train loss:0.00565366984338\n",
      "train loss:0.00544131895657\n",
      "train loss:0.00522921691454\n",
      "train loss:0.00211209268741\n",
      "train loss:0.0126990004356\n",
      "train loss:0.0114249833921\n",
      "train loss:0.0030818539007\n",
      "train loss:0.00530264894517\n",
      "train loss:0.00194494722423\n",
      "train loss:0.00372340523499\n",
      "train loss:0.00158503786518\n",
      "train loss:0.00551614695847\n",
      "train loss:0.00631694135703\n",
      "train loss:0.0128130054361\n",
      "train loss:0.00489663514454\n",
      "train loss:0.00798414554762\n",
      "train loss:0.00293063738889\n",
      "train loss:0.00813951340932\n",
      "train loss:0.0198825938545\n",
      "train loss:0.00273508527316\n",
      "train loss:0.000640277066536\n",
      "train loss:0.00125910155546\n",
      "train loss:0.00175078368166\n",
      "train loss:0.000692113014594\n",
      "train loss:0.00712089084138\n",
      "train loss:0.0091573679596\n",
      "train loss:0.000859234079918\n",
      "train loss:0.00128324121232\n",
      "train loss:0.00317005551712\n",
      "train loss:0.00720290096618\n",
      "train loss:0.00245523923436\n",
      "train loss:0.00334291154225\n",
      "train loss:0.00414203858068\n",
      "train loss:0.0822257713334\n",
      "train loss:0.00350250994098\n",
      "train loss:0.00309243686573\n",
      "train loss:0.00529502528377\n",
      "train loss:0.022416057232\n",
      "train loss:0.000899141242161\n",
      "train loss:0.0037691812456\n",
      "train loss:0.00657940606854\n",
      "train loss:0.00301486460173\n",
      "train loss:0.00735612940471\n",
      "train loss:0.0161557226039\n",
      "train loss:0.0125241204676\n",
      "train loss:0.00698961869331\n",
      "train loss:0.000381461930214\n",
      "train loss:0.0108284953286\n",
      "train loss:0.00335133764081\n",
      "train loss:0.000528794345127\n",
      "train loss:0.0112011632547\n",
      "train loss:0.00280920079993\n",
      "train loss:0.00102758703463\n",
      "train loss:0.00179563813609\n",
      "train loss:0.0150338726037\n",
      "train loss:0.016050845149\n",
      "train loss:0.00971347403468\n",
      "train loss:0.00256907071776\n",
      "train loss:0.00173448057318\n",
      "train loss:0.0197521887418\n",
      "train loss:0.00288246676066\n",
      "train loss:0.00793380047306\n",
      "train loss:0.00276838174527\n",
      "train loss:0.00814334527025\n",
      "train loss:0.00980221672864\n",
      "train loss:0.00936988298035\n",
      "train loss:0.0262927936831\n",
      "train loss:0.0065886187788\n",
      "train loss:0.0115621988035\n",
      "train loss:0.00499067894803\n",
      "train loss:0.00813061663519\n",
      "train loss:0.00580114651793\n",
      "train loss:0.00931743081913\n",
      "train loss:0.00453861139988\n",
      "train loss:0.00141334690853\n",
      "train loss:0.00692618366455\n",
      "train loss:0.00362406406742\n",
      "train loss:0.0273133300775\n",
      "train loss:0.000894760660252\n",
      "train loss:0.0184008943825\n",
      "train loss:0.00915059350177\n",
      "train loss:0.00978981479111\n",
      "train loss:0.0015099259598\n",
      "train loss:0.000501248080941\n",
      "train loss:0.00427104496853\n",
      "train loss:0.0193564345547\n",
      "train loss:0.00430541483591\n",
      "train loss:0.00475665380559\n",
      "train loss:0.00871992784612\n",
      "train loss:0.0306743767073\n",
      "train loss:0.00596160602884\n",
      "train loss:0.0123039427687\n",
      "train loss:0.0247224590542\n",
      "train loss:0.00429170623431\n",
      "train loss:0.00120264384465\n",
      "train loss:0.00155038872203\n",
      "train loss:0.0165516695855\n",
      "train loss:0.00410211357639\n",
      "train loss:0.00998369361447\n",
      "train loss:0.00676957503466\n",
      "train loss:0.0184557676588\n",
      "train loss:0.0190622041936\n",
      "train loss:0.00321175840931\n",
      "train loss:0.00319700980608\n",
      "train loss:0.00323092719987\n",
      "train loss:0.0104481574746\n",
      "train loss:0.00345331981161\n",
      "train loss:0.00371343525113\n",
      "train loss:0.000972764697833\n",
      "train loss:0.00886925018393\n",
      "train loss:0.00134351661144\n",
      "train loss:0.0296618797256\n",
      "train loss:0.0181328541635\n",
      "train loss:0.00420455896869\n",
      "train loss:0.00260346583795\n",
      "train loss:0.0112100815529\n",
      "train loss:0.00285373383811\n",
      "train loss:0.00080019761498\n",
      "train loss:0.00271078640557\n",
      "train loss:0.00271450921443\n",
      "train loss:0.00769442583756\n",
      "train loss:0.00244291487667\n",
      "train loss:0.0222460067858\n",
      "train loss:0.00643207822745\n",
      "train loss:0.00627850060941\n",
      "train loss:0.011789163836\n",
      "train loss:0.010156709291\n",
      "train loss:0.00690520594946\n",
      "train loss:0.0143245375889\n",
      "train loss:0.0100632451058\n",
      "train loss:0.00743862452452\n",
      "train loss:0.00348856790692\n",
      "train loss:0.0325879935097\n",
      "train loss:0.00487020570951\n",
      "train loss:0.00591036186339\n",
      "train loss:0.000848686709097\n",
      "train loss:0.011204848516\n",
      "train loss:0.0112815966532\n",
      "train loss:0.0074203744412\n",
      "train loss:0.0107958696363\n",
      "train loss:0.00261413066283\n",
      "train loss:0.0179080058474\n",
      "train loss:0.0111382350013\n",
      "train loss:0.00550517771164\n",
      "train loss:0.00159301090727\n",
      "train loss:0.00278304569351\n",
      "train loss:0.00464799913675\n",
      "train loss:0.00559727703468\n",
      "train loss:0.000429567722503\n",
      "train loss:0.0123220690363\n",
      "train loss:0.0102249962907\n",
      "train loss:0.0211512607313\n",
      "train loss:0.0112694784544\n",
      "train loss:0.0046356465392\n",
      "train loss:0.0103767746213\n",
      "train loss:0.0193191810758\n",
      "train loss:0.00971180877662\n",
      "train loss:0.000954229103538\n",
      "train loss:0.00405675779541\n",
      "train loss:0.025503996089\n",
      "train loss:0.0178532951364\n",
      "train loss:0.00244132141188\n",
      "train loss:0.00237717224575\n",
      "train loss:0.0119727524181\n",
      "train loss:0.00509917792012\n",
      "train loss:0.00588741351285\n",
      "train loss:0.00291044745194\n",
      "train loss:0.00460590262033\n",
      "train loss:0.0097518906853\n",
      "train loss:0.00613361591236\n",
      "train loss:0.00551861624193\n",
      "train loss:0.0104754624296\n",
      "train loss:0.00487819417857\n",
      "train loss:0.00688679896706\n",
      "train loss:0.0064623491581\n",
      "train loss:0.0059839761765\n",
      "train loss:0.00310355354429\n",
      "train loss:0.0121268704972\n",
      "train loss:0.00559496415753\n",
      "train loss:0.00974908168924\n",
      "train loss:0.0135499319312\n",
      "train loss:0.0231532708236\n",
      "train loss:0.00884981857763\n",
      "train loss:0.00581003294604\n",
      "train loss:0.0380306372209\n",
      "train loss:0.00363586373024\n",
      "train loss:0.0178407615078\n",
      "train loss:0.00311626036031\n",
      "train loss:0.00385630089389\n",
      "train loss:0.0011992905074\n",
      "train loss:0.00446588616029\n",
      "train loss:0.0207225474566\n",
      "train loss:0.00361119585557\n",
      "train loss:0.00406038437767\n",
      "train loss:0.00451122140139\n",
      "train loss:0.00310078300219\n",
      "train loss:0.00487716078247\n",
      "train loss:0.00770163391885\n",
      "train loss:0.00290385204248\n",
      "train loss:0.00576399620268\n",
      "train loss:0.00500069331072\n",
      "train loss:0.00248526207061\n",
      "train loss:0.00383085447979\n",
      "train loss:0.00734682502516\n",
      "train loss:0.00151995116578\n",
      "train loss:0.00607564547802\n",
      "train loss:0.0765697308067\n",
      "train loss:0.00043906656234\n",
      "train loss:0.00199836306595\n",
      "train loss:0.00397344206297\n",
      "train loss:0.00799942374963\n",
      "train loss:0.00599725612035\n",
      "train loss:0.0745449168428\n",
      "train loss:0.00919207173992\n",
      "train loss:0.0116638588084\n",
      "train loss:0.000492490702687\n",
      "train loss:0.00347244203157\n",
      "train loss:0.0101725680737\n",
      "train loss:0.00849887507696\n",
      "train loss:0.0091439852199\n",
      "train loss:0.00250862875559\n",
      "train loss:0.00562744825734\n",
      "train loss:0.00289675969103\n",
      "train loss:0.00471027443565\n",
      "train loss:0.0139247553579\n",
      "train loss:0.00686159755235\n",
      "train loss:0.00329712278727\n",
      "train loss:0.00107445998617\n",
      "train loss:0.013767937821\n",
      "train loss:0.0112432863326\n",
      "train loss:0.00385603753473\n",
      "train loss:0.00265063227363\n",
      "train loss:0.000260555497913\n",
      "train loss:0.00148568514744\n",
      "train loss:0.0124404378179\n",
      "train loss:0.0158033113502\n",
      "train loss:0.0209497792761\n",
      "train loss:0.00633689747776\n",
      "train loss:0.0166835036678\n",
      "train loss:0.00395995199732\n",
      "train loss:0.00941104259046\n",
      "train loss:0.00247346618888\n",
      "train loss:0.00664664337885\n",
      "train loss:0.0153998581479\n",
      "train loss:0.00464467310368\n",
      "train loss:0.00379508134923\n",
      "train loss:0.00887768483424\n",
      "train loss:0.00442011147848\n",
      "train loss:0.0045504563686\n",
      "train loss:0.00509393545243\n",
      "train loss:0.0456121467538\n",
      "train loss:0.0511969006343\n",
      "train loss:0.00925028925895\n",
      "train loss:0.00876332771057\n",
      "train loss:0.0236797526005\n",
      "train loss:0.00573767663428\n",
      "train loss:0.00254089911742\n",
      "train loss:0.00482449284294\n",
      "train loss:0.004638152291\n",
      "=== epoch:11, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.00184175615395\n",
      "train loss:0.00740330641078\n",
      "train loss:0.00128685410645\n",
      "train loss:0.00201583820283\n",
      "train loss:0.00358305311227\n",
      "train loss:0.00134828591499\n",
      "train loss:0.00299003416343\n",
      "train loss:0.00215971142285\n",
      "train loss:0.00175249377866\n",
      "train loss:0.000629945317438\n",
      "train loss:0.0401512216919\n",
      "train loss:0.00126332318291\n",
      "train loss:0.010258270624\n",
      "train loss:0.0022031515227\n",
      "train loss:0.00109484070061\n",
      "train loss:0.00328747687777\n",
      "train loss:0.00124486425881\n",
      "train loss:0.00181545157465\n",
      "train loss:0.00572615868812\n",
      "train loss:0.00780615636564\n",
      "train loss:0.00529561004603\n",
      "train loss:0.0749152298796\n",
      "train loss:0.0024891859157\n",
      "train loss:0.00859888350763\n",
      "train loss:0.010359503006\n",
      "train loss:0.00508627291924\n",
      "train loss:0.0296391069408\n",
      "train loss:0.00832637158014\n",
      "train loss:0.000850618371028\n",
      "train loss:0.00650052979481\n",
      "train loss:0.00356767866044\n",
      "train loss:0.0064479506635\n",
      "train loss:0.00181114684889\n",
      "train loss:0.030273919761\n",
      "train loss:0.000386307065653\n",
      "train loss:0.002265407476\n",
      "train loss:0.00113417119353\n",
      "train loss:0.00384982625206\n",
      "train loss:0.00610330495825\n",
      "train loss:0.00284004060962\n",
      "train loss:0.00874669292807\n",
      "train loss:0.00156383181316\n",
      "train loss:0.0109193190999\n",
      "train loss:0.00909223139775\n",
      "train loss:0.00687922383324\n",
      "train loss:0.00458677404701\n",
      "train loss:0.00185173275738\n",
      "train loss:0.00494154769611\n",
      "train loss:0.00429278079701\n",
      "train loss:0.028910655405\n",
      "train loss:0.0174304673801\n",
      "train loss:0.00315621754611\n",
      "train loss:0.0282761433516\n",
      "train loss:0.00434740435956\n",
      "train loss:0.00393513520244\n",
      "train loss:0.0272880990206\n",
      "train loss:0.00127565799463\n",
      "train loss:0.00594339766998\n",
      "train loss:0.00334086063963\n",
      "train loss:0.00184443026411\n",
      "train loss:0.00758807068605\n",
      "train loss:0.0037310762997\n",
      "train loss:0.0119463287114\n",
      "train loss:0.018540316301\n",
      "train loss:0.00941018762957\n",
      "train loss:0.0103498013072\n",
      "train loss:0.00542580039304\n",
      "train loss:0.00800988038207\n",
      "train loss:0.00374957218802\n",
      "train loss:0.0118797526735\n",
      "train loss:0.0125370358673\n",
      "train loss:0.00125758229745\n",
      "train loss:0.0141266501266\n",
      "train loss:0.00482595306668\n",
      "train loss:0.000831867196127\n",
      "train loss:0.00282815138204\n",
      "train loss:0.0128104059351\n",
      "train loss:0.00496832808415\n",
      "train loss:0.00214641037337\n",
      "train loss:0.0097551049886\n",
      "train loss:0.0156691915096\n",
      "train loss:0.0100380222865\n",
      "train loss:0.00458464425344\n",
      "train loss:0.00110880537394\n",
      "train loss:0.000995374870396\n",
      "train loss:0.0113231791387\n",
      "train loss:0.0273966922171\n",
      "train loss:0.00058508417308\n",
      "train loss:0.00628398201666\n",
      "train loss:0.00754463959048\n",
      "train loss:0.00760060365858\n",
      "train loss:0.00234753878243\n",
      "train loss:0.00363090019913\n",
      "train loss:0.0180685184794\n",
      "train loss:0.0017336900924\n",
      "train loss:0.00652266152241\n",
      "train loss:0.00225293035796\n",
      "train loss:0.00448392725738\n",
      "train loss:0.00534527221477\n",
      "train loss:0.00281773252974\n",
      "train loss:0.0106965894333\n",
      "train loss:0.00835416547839\n",
      "train loss:0.00189960825243\n",
      "train loss:0.000756882607406\n",
      "train loss:0.0257633838185\n",
      "train loss:0.000918715437132\n",
      "train loss:0.0104694283323\n",
      "train loss:0.0803682143077\n",
      "train loss:0.0555229103691\n",
      "train loss:0.00379736584232\n",
      "train loss:0.00783374255342\n",
      "train loss:0.0170975360325\n",
      "train loss:0.00248844571041\n",
      "train loss:0.000944261532804\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学習後の重み\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
